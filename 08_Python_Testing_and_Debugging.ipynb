{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d6baf7",
   "metadata": {},
   "source": [
    "# Python Testing and Debugging\n",
    "This notebook covers unit testing, logging, debugging, and assertions with real-life use cases, best practices, and code examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4726a72",
   "metadata": {},
   "source": [
    "## 1. Unit Testing\n",
    "**Definition:** Unit testing is the practice of testing small pieces of code (units) in isolation. Python's built-in `unittest` module is commonly used.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b9d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.012s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.012s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Result Summary ---\n",
      "Tests run: 4\n",
      "Errors: 0\n",
      "Failures: 0\n",
      "\n",
      "--- Complex Test Example ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "# The function we want to test\n",
    "def add(a, b):\n",
    "    \"\"\"Add two numbers and return the result.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Test case class inherits from unittest.TestCase\n",
    "class TestAdd(unittest.TestCase):\n",
    "    # Test methods must start with 'test'\n",
    "    def test_add_positive(self):\n",
    "        \"\"\"Test addition of positive numbers.\"\"\"\n",
    "        # assertEqual checks if two values are equal\n",
    "        self.assertEqual(add(2, 3), 5)\n",
    "        self.assertEqual(add(0, 5), 5)\n",
    "        \n",
    "    def test_add_negative(self):\n",
    "        \"\"\"Test addition of negative numbers.\"\"\"\n",
    "        self.assertEqual(add(-1, -1), -2)\n",
    "        self.assertEqual(add(-5, 2), -3)\n",
    "    \n",
    "    def test_add_edge_cases(self):\n",
    "        \"\"\"Test edge cases like zero and large numbers.\"\"\"\n",
    "        self.assertEqual(add(0, 0), 0)  # Zero case\n",
    "        self.assertEqual(add(1000000, 1000000), 2000000)  # Large numbers\n",
    "    \n",
    "    # More assertion methods demonstration\n",
    "    def test_assertions_demo(self):\n",
    "        \"\"\"Demonstrate various unittest assertion methods.\"\"\"\n",
    "        self.assertTrue(add(1, 1) == 2)             # Check if expression is True\n",
    "        self.assertFalse(add(1, 1) == 3)           # Check if expression is False\n",
    "        self.assertGreater(add(5, 6), 10)          # Check if first arg > second arg\n",
    "        self.assertLess(add(-5, -5), 0)            # Check if first arg < second arg\n",
    "        self.assertIn(add(1, 2), [1, 2, 3])        # Check if first arg in second arg\n",
    "        self.assertIsInstance(add(1.5, 2.5), float) # Check instance type\n",
    "\n",
    "# Create and run the test suite\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestAdd)\n",
    "result = unittest.TextTestRunner().run(suite)\n",
    "\n",
    "print(\"\\n--- Test Result Summary ---\")\n",
    "print(f\"Tests run: {result.testsRun}\")\n",
    "print(f\"Errors: {len(result.errors)}\")\n",
    "print(f\"Failures: {len(result.failures)}\")\n",
    "\n",
    "# Example of a more complex test case\n",
    "print(\"\\n--- Complex Test Example ---\")\n",
    "\n",
    "# A more complex function to test\n",
    "def calculate_statistics(numbers):\n",
    "    \"\"\"Calculate min, max, and average for a list of numbers.\"\"\"\n",
    "    if not numbers:  # Handle empty list case\n",
    "        return {'min': None, 'max': None, 'avg': None}\n",
    "    \n",
    "    return {\n",
    "        'min': min(numbers),\n",
    "        'max': max(numbers),\n",
    "        'avg': sum(numbers) / len(numbers)\n",
    "    }\n",
    "\n",
    "# Test case for the statistics function\n",
    "class TestStatistics(unittest.TestCase):\n",
    "    def test_normal_case(self):\n",
    "        stats = calculate_statistics([1, 2, 3, 4, 5])\n",
    "        self.assertEqual(stats['min'], 1)\n",
    "        self.assertEqual(stats['max'], 5)\n",
    "        self.assertEqual(stats['avg'], 3.0)\n",
    "    \n",
    "    def test_empty_list(self):\n",
    "        stats = calculate_statistics([])\n",
    "        self.assertIsNone(stats['min'])\n",
    "        self.assertIsNone(stats['max'])\n",
    "        self.assertIsNone(stats['avg'])\n",
    "\n",
    "# Run the statistics test\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestStatistics)\n",
    "unittest.TextTestRunner().run(suite)\n",
    "\n",
    "# Expected output:\n",
    "# ...\n",
    "# ----------------------------------------------------------------------\n",
    "# Ran 3 tests in 0.001s\n",
    "#\n",
    "# OK\n",
    "#\n",
    "# --- Test Result Summary ---\n",
    "# Tests run: 3\n",
    "# Errors: 0\n",
    "# Failures: 0\n",
    "#\n",
    "# --- Complex Test Example ---\n",
    "# ..\n",
    "# ----------------------------------------------------------------------\n",
    "# Ran 2 tests in 0.001s\n",
    "#\n",
    "# OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155828c8",
   "metadata": {},
   "source": [
    "**Output:**\n",
    ". .\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in ...\n",
    "OK\n",
    "\n",
    "**Real-life use case:** Ensuring that a financial calculation function always returns correct results.\n",
    "\n",
    "**Common mistakes:** Not testing edge cases or only testing happy paths.\n",
    "\n",
    "**Best practices:** Write tests for all critical code paths and automate test execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f3e70",
   "metadata": {},
   "source": [
    "## 2. Logging\n",
    "**Definition:** Logging is used to record events and errors during program execution. The `logging` module is flexible and configurable.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0943c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 22:37:06 - calculator - INFO - Division result: 5.0\n",
      "2025-05-13 22:37:06 - calculator - ERROR - Division by zero: 5/0\n",
      "2025-05-13 22:37:06 - calculator - DEBUG - Dividing 20 by 4\n",
      "2025-05-13 22:37:06 - calculator - INFO - Division result: 5.0\n",
      "2025-05-13 22:37:06 - data_processor - INFO - Processing data batch #1234\n",
      "2025-05-13 22:37:06 - calculator - DEBUG - Dividing 10 by 0\n",
      "2025-05-13 22:37:06 - calculator - ERROR - Division by zero: 10/0\n",
      "2025-05-13 22:37:06 - calculator - DEBUG - This is a DEBUG message - detailed information for diagnosis\n",
      "2025-05-13 22:37:06 - calculator - INFO - This is an INFO message - confirmation that things are working\n",
      "2025-05-13 22:37:06 - calculator - WARNING - This is a WARNING message - potential issue or problem\n",
      "2025-05-13 22:37:06 - calculator - ERROR - This is an ERROR message - something failed to work properly\n",
      "2025-05-13 22:37:06 - calculator - CRITICAL - This is a CRITICAL message - program may not continue\n",
      "2025-05-13 22:37:06 - calculator - ERROR - Division by zero: 5/0\n",
      "2025-05-13 22:37:06 - calculator - DEBUG - Dividing 20 by 4\n",
      "2025-05-13 22:37:06 - calculator - INFO - Division result: 5.0\n",
      "2025-05-13 22:37:06 - data_processor - INFO - Processing data batch #1234\n",
      "2025-05-13 22:37:06 - calculator - DEBUG - Dividing 10 by 0\n",
      "2025-05-13 22:37:06 - calculator - ERROR - Division by zero: 10/0\n",
      "2025-05-13 22:37:06 - calculator - DEBUG - This is a DEBUG message - detailed information for diagnosis\n",
      "2025-05-13 22:37:06 - calculator - INFO - This is an INFO message - confirmation that things are working\n",
      "2025-05-13 22:37:06 - calculator - WARNING - This is a WARNING message - potential issue or problem\n",
      "2025-05-13 22:37:06 - calculator - ERROR - This is an ERROR message - something failed to work properly\n",
      "2025-05-13 22:37:06 - calculator - CRITICAL - This is a CRITICAL message - program may not continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic logging examples:\n",
      "\n",
      "Changing log level to DEBUG to see more details:\n",
      "\n",
      "Logging to a file (simulated):\n",
      "\n",
      "Contents that would be in app.log:\n",
      "2023-08-22 15:30:45 - calculator - ERROR - Division by zero: 10/0\n",
      "\n",
      "Different logging levels:\n",
      "This is a DEBUG message - detailed information for diagnosis\n",
      "This is an INFO message - confirmation that things are working\n",
      "This is a WARNING message - potential issue or problem\n",
      "This is an ERROR message - something failed to work properly\n",
      "This is a CRITICAL message - program may not continue\n",
      "\n",
      "\n",
      "Logging best practices:\n",
      "1. Use the appropriate log level for different situations\n",
      "2. Include contextual information in log messages\n",
      "3. Configure logging at the start of your application\n",
      "4. Use different handlers for different outputs\n",
      "5. Structure logs for easy filtering and analysis\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# Configure basic logging to show INFO level and above\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# The main logger object\n",
    "logger = logging.getLogger('calculator')\n",
    "\n",
    "def divide(a, b):\n",
    "    \"\"\"Divide a by b and log the result.\"\"\"\n",
    "    try:\n",
    "        logger.debug(f'Dividing {a} by {b}')  # Debug message (won't show by default)\n",
    "        result = a / b\n",
    "        logger.info(f'Division result: {result}')  # Info message\n",
    "        return result\n",
    "    except ZeroDivisionError:\n",
    "        logger.error(f'Division by zero: {a}/{b}')  # Error message\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.critical(f'Unexpected error: {str(e)}')  # Critical message\n",
    "        return None\n",
    "\n",
    "# Basic logging examples\n",
    "print(\"Basic logging examples:\")\n",
    "divide(10, 2)   # Normal case - should log info message\n",
    "divide(5, 0)    # Error case - should log error message\n",
    "\n",
    "# Changing log level dynamically\n",
    "print(\"\\nChanging log level to DEBUG to see more details:\")\n",
    "logger.setLevel(logging.DEBUG)  # Show all log levels including DEBUG\n",
    "divide(20, 4)   # Now debug messages will show too\n",
    "\n",
    "# Creating a custom logger for a different component\n",
    "data_logger = logging.getLogger('data_processor')\n",
    "data_logger.info(\"Processing data batch #1234\")\n",
    "\n",
    "# Logging to a file\n",
    "print(\"\\nLogging to a file (simulated):\")\n",
    "file_handler = logging.FileHandler('app.log', mode='w')  # Would create a real file\n",
    "file_handler.setLevel(logging.WARNING)  # Only WARNING and above go to file\n",
    "file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_format)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "divide(10, 0)  # Error will now be logged both to console and to file\n",
    "\n",
    "# Simulating reading from log file\n",
    "print(\"\\nContents that would be in app.log:\")\n",
    "print(\"2023-08-22 15:30:45 - calculator - ERROR - Division by zero: 10/0\")\n",
    "\n",
    "# Different log levels demonstration\n",
    "print(\"\\nDifferent logging levels:\")\n",
    "# Capture log output for demonstration\n",
    "log_capture = StringIO()\n",
    "ch = logging.StreamHandler(log_capture)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.debug(\"This is a DEBUG message - detailed information for diagnosis\")\n",
    "logger.info(\"This is an INFO message - confirmation that things are working\")\n",
    "logger.warning(\"This is a WARNING message - potential issue or problem\")\n",
    "logger.error(\"This is an ERROR message - something failed to work properly\")\n",
    "logger.critical(\"This is a CRITICAL message - program may not continue\")\n",
    "\n",
    "print(log_capture.getvalue())\n",
    "\n",
    "# Best practices\n",
    "print(\"\\nLogging best practices:\")\n",
    "print(\"1. Use the appropriate log level for different situations\")\n",
    "print(\"2. Include contextual information in log messages\")\n",
    "print(\"3. Configure logging at the start of your application\")\n",
    "print(\"4. Use different handlers for different outputs\")\n",
    "print(\"5. Structure logs for easy filtering and analysis\")\n",
    "\n",
    "# Expected output:\n",
    "# Basic logging examples:\n",
    "# 2023-08-22 15:28:23 - calculator - INFO - Division result: 5.0\n",
    "# 2023-08-22 15:28:23 - calculator - ERROR - Division by zero: 5/0\n",
    "#\n",
    "# Changing log level to DEBUG to see more details:\n",
    "# 2023-08-22 15:28:23 - calculator - DEBUG - Dividing 20 by 4\n",
    "# 2023-08-22 15:28:23 - calculator - INFO - Division result: 5.0\n",
    "# 2023-08-22 15:28:23 - data_processor - INFO - Processing data batch #1234\n",
    "#\n",
    "# Logging to a file (simulated):\n",
    "# 2023-08-22 15:28:23 - calculator - ERROR - Division by zero: 10/0\n",
    "#\n",
    "# Contents that would be in app.log:\n",
    "# 2023-08-22 15:30:45 - calculator - ERROR - Division by zero: 10/0\n",
    "#\n",
    "# Different logging levels:\n",
    "# This is a DEBUG message - detailed information for diagnosis\n",
    "# This is an INFO message - confirmation that things are working\n",
    "# This is a WARNING message - potential issue or problem\n",
    "# This is an ERROR message - something failed to work properly\n",
    "# This is a CRITICAL message - program may not continue\n",
    "#\n",
    "# Logging best practices:\n",
    "# 1. Use the appropriate log level for different situations\n",
    "# 2. Include contextual information in log messages\n",
    "# 3. Configure logging at the start of your application\n",
    "# 4. Use different handlers for different outputs\n",
    "# 5. Structure logs for easy filtering and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380367f",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "INFO:root:Result: 5.0\n",
    "ERROR:root:Attempted division by zero\n",
    "\n",
    "**Real-life use case:** Logging errors in a web server to troubleshoot issues.\n",
    "\n",
    "**Common mistakes:** Using print statements instead of logging or not setting log levels.\n",
    "\n",
    "**Best practices:** Use logging for all production code and configure log levels appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316d2be",
   "metadata": {},
   "source": [
    "## 3. Debugging\n",
    "**Definition:** Debugging is the process of finding and fixing errors in code. The built-in `pdb` module provides an interactive debugger.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021f2396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using print statements for debugging:\n",
      "Input: [2, 4, 6, 8]\n",
      "After adding 2: total = 2\n",
      "After adding 4: total = 6\n",
      "After adding 6: total = 12\n",
      "After adding 8: total = 20\n",
      "Final result: 5.0\n",
      "\n",
      "Using Python debugger (pdb):\n",
      "When using pdb, you would typically use commands like:\n",
      "- n (next) - execute current line and move to next line\n",
      "- s (step) - step into a function call\n",
      "- c (continue) - continue execution until next breakpoint\n",
      "- p expression (print) - evaluate and print an expression\n",
      "- l (list) - show current line in context\n",
      "- q (quit) - quit debugger and execution\n",
      "Result from buggy_function: 15\n",
      "\n",
      "Using try/except for debugging:\n",
      "Success: 10 / 2 = 5.0\n",
      "Error occurred: ZeroDivisionError: division by zero\n",
      "Error occurred in division_function(10, 0)\n",
      "\n",
      "Other debugging tools in Python:\n",
      "1. VSCode's built-in debugger - Set breakpoints and inspect variables graphically\n",
      "2. PyCharm debugger - Professional IDE with robust debugging tools\n",
      "3. IPython/Jupyter - Use %debug magic to start debugger after an exception occurs\n",
      "4. pdbpp - Enhanced version of pdb with syntax highlighting and tab completion\n",
      "5. logging module - For logging-based debugging in production\n",
      "\n",
      "Debugging tips for data science:\n",
      "1. Visualize intermediate results using plots\n",
      "2. Inspect data shape and types frequently\n",
      "3. Test algorithms on small subsets before full dataset\n",
      "4. Check for NaN values that can cause unexpected behavior\n",
      "5. Use domain knowledge to validate if results make sense\n",
      "Data shape: (5,), dtype: float64\n",
      "NaN values: 0\n",
      "Infinite values: 0\n",
      "Min: 1.0, Max: 5.0, Mean: 3.00\n",
      "Processed data: [ 2.  4.  6.  8. 10.]\n",
      "Data shape: (5,), dtype: float64\n",
      "NaN values: 0\n",
      "Infinite values: 0\n",
      "Min: 1.0, Max: 5.0, Mean: 3.00\n",
      "Processed data: [ 2.  4.  6.  8. 10.]\n"
     ]
    }
   ],
   "source": [
    "# Debugging in Python\n",
    "\n",
    "# Sample function with a bug\n",
    "def calculate_average(numbers):\n",
    "    \"\"\"Calculate the average of a list of numbers.\"\"\"\n",
    "    total = 0\n",
    "    for num in numbers:\n",
    "        # Bug: we're not actually adding the numbers to total\n",
    "        # total + num  # This line has a bug - it calculates but doesn't store the result\n",
    "        \n",
    "        # Fixed version would be:\n",
    "        total += num\n",
    "        \n",
    "    return total / len(numbers) if numbers else 0\n",
    "\n",
    "# Simple debugging using print statements\n",
    "print(\"Using print statements for debugging:\")\n",
    "def debug_with_print(numbers):\n",
    "    print(f\"Input: {numbers}\")\n",
    "    total = 0\n",
    "    for i, num in enumerate(numbers):\n",
    "        total += num\n",
    "        print(f\"After adding {num}: total = {total}\")\n",
    "    result = total / len(numbers) if numbers else 0\n",
    "    print(f\"Final result: {result}\")\n",
    "    return result\n",
    "\n",
    "debug_with_print([2, 4, 6, 8])\n",
    "\n",
    "# Using Python debugger (pdb)\n",
    "print(\"\\nUsing Python debugger (pdb):\")\n",
    "print(\"When using pdb, you would typically use commands like:\")\n",
    "print(\"- n (next) - execute current line and move to next line\")\n",
    "print(\"- s (step) - step into a function call\")\n",
    "print(\"- c (continue) - continue execution until next breakpoint\")\n",
    "print(\"- p expression (print) - evaluate and print an expression\")\n",
    "print(\"- l (list) - show current line in context\")\n",
    "print(\"- q (quit) - quit debugger and execution\")\n",
    "\n",
    "# Here's how you would insert a breakpoint in your code\n",
    "def buggy_function(x):\n",
    "    y = x + 10\n",
    "    # Uncomment the next line to start the debugger at this point\n",
    "    # import pdb; pdb.set_trace()  # Python 3.6 and earlier\n",
    "    # or use this in Python 3.7+:\n",
    "    # breakpoint()  # More modern way to insert a breakpoint\n",
    "    return y\n",
    "\n",
    "result = buggy_function(5)\n",
    "print(f\"Result from buggy_function: {result}\")\n",
    "\n",
    "# Using try/except for debugging \n",
    "print(\"\\nUsing try/except for debugging:\")\n",
    "def division_function(a, b):\n",
    "    try:\n",
    "        result = a / b\n",
    "        print(f\"Success: {a} / {b} = {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {type(e).__name__}: {str(e)}\")\n",
    "        print(f\"Error occurred in division_function({a}, {b})\")\n",
    "        # In a real scenario, you might want to re-raise the exception\n",
    "        # raise\n",
    "        return None\n",
    "\n",
    "division_function(10, 2)  # Should work fine\n",
    "division_function(10, 0)  # Should catch the error\n",
    "\n",
    "# Using Python's built-in debugging tools\n",
    "print(\"\\nOther debugging tools in Python:\")\n",
    "print(\"1. VSCode's built-in debugger - Set breakpoints and inspect variables graphically\")\n",
    "print(\"2. PyCharm debugger - Professional IDE with robust debugging tools\")\n",
    "print(\"3. IPython/Jupyter - Use %debug magic to start debugger after an exception occurs\")\n",
    "print(\"4. pdbpp - Enhanced version of pdb with syntax highlighting and tab completion\")\n",
    "print(\"5. logging module - For logging-based debugging in production\")\n",
    "\n",
    "# For data science specific debugging\n",
    "print(\"\\nDebugging tips for data science:\")\n",
    "print(\"1. Visualize intermediate results using plots\")\n",
    "print(\"2. Inspect data shape and types frequently\")\n",
    "print(\"3. Test algorithms on small subsets before full dataset\")\n",
    "print(\"4. Check for NaN values that can cause unexpected behavior\")\n",
    "print(\"5. Use domain knowledge to validate if results make sense\")\n",
    "\n",
    "# Example of data science debugging\n",
    "import numpy as np\n",
    "\n",
    "def process_data(data):\n",
    "    # Print shape and data types - useful for debugging\n",
    "    print(f\"Data shape: {data.shape}, dtype: {data.dtype}\")\n",
    "    \n",
    "    # Check for problematic values\n",
    "    print(f\"NaN values: {np.isnan(data).sum()}\")\n",
    "    print(f\"Infinite values: {np.isinf(data).sum()}\")\n",
    "    \n",
    "    # Data summary - useful to see if values are reasonable\n",
    "    print(f\"Min: {np.min(data)}, Max: {np.max(data)}, Mean: {np.mean(data):.2f}\")\n",
    "    \n",
    "    # Continue with processing...\n",
    "    return data * 2\n",
    "\n",
    "# Sample data\n",
    "sample_data = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "processed = process_data(sample_data)\n",
    "print(f\"Processed data: {processed}\")\n",
    "\n",
    "# Expected output:\n",
    "# Using print statements for debugging:\n",
    "# Input: [2, 4, 6, 8]\n",
    "# After adding 2: total = 2\n",
    "# After adding 4: total = 6\n",
    "# After adding 6: total = 12\n",
    "# After adding 8: total = 20\n",
    "# Final result: 5.0\n",
    "#\n",
    "# Using Python debugger (pdb):\n",
    "# When using pdb, you would typically use commands like:\n",
    "# - n (next) - execute current line and move to next line\n",
    "# - s (step) - step into a function call\n",
    "# - c (continue) - continue execution until next breakpoint\n",
    "# - p expression (print) - evaluate and print an expression\n",
    "# - l (list) - show current line in context\n",
    "# - q (quit) - quit debugger and execution\n",
    "# Result from buggy_function: 15\n",
    "#\n",
    "# Using try/except for debugging:\n",
    "# Success: 10 / 2 = 5.0\n",
    "# Error occurred: ZeroDivisionError: division by zero\n",
    "# Error occurred in division_function(10, 0)\n",
    "#\n",
    "# Other debugging tools in Python:\n",
    "# 1. VSCode's built-in debugger - Set breakpoints and inspect variables graphically\n",
    "# 2. PyCharm debugger - Professional IDE with robust debugging tools\n",
    "# 3. IPython/Jupyter - Use %debug magic to start debugger after an exception occurs\n",
    "# 4. pdbpp - Enhanced version of pdb with syntax highlighting and tab completion\n",
    "# 5. logging module - For logging-based debugging in production\n",
    "#\n",
    "# Debugging tips for data science:\n",
    "# 1. Visualize intermediate results using plots\n",
    "# 2. Inspect data shape and types frequently\n",
    "# 3. Test algorithms on small subsets before full dataset\n",
    "# 4. Check for NaN values that can cause unexpected behavior\n",
    "# 5. Use domain knowledge to validate if results make sense\n",
    "# Data shape: (5,), dtype: float64\n",
    "# NaN values: 0\n",
    "# Infinite values: 0\n",
    "# Min: 1.0, Max: 5.0, Mean: 3.00\n",
    "# Processed data: [ 2.  4.  6.  8. 10.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87168d11",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "15\n",
    "\n",
    "**Real-life use case:** Stepping through code to find the cause of a bug in a data processing pipeline.\n",
    "\n",
    "**Common mistakes:** Not using a debugger and relying only on print statements.\n",
    "\n",
    "**Best practices:** Use a debugger for complex bugs and to inspect program state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af2852",
   "metadata": {},
   "source": [
    "## 4. Assertions\n",
    "**Definition:** Assertions are used to check if a condition is true. If not, an AssertionError is raised. Useful for catching bugs early.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17046efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with positive number:\n",
      "5\n",
      "\n",
      "If we tried with negative number: get_positive_number(-2)\n",
      "It would raise: AssertionError: Number must be positive\n",
      "\n",
      "Advanced assertion examples:\n",
      "Average grade: 90.0\n",
      "\n",
      "Invalid inputs would cause:\n",
      "calculate_average([]) → AssertionError: Cannot calculate average of empty list\n",
      "calculate_average([85, 105, 90]) → AssertionError: Grades must be between 0 and 100\n",
      "\n",
      "Assertions vs. explicit validation:\n",
      "Processed 3 items\n",
      "Processed 3 items\n",
      "\n",
      "When to use assertions vs. exceptions:\n",
      "1. Assertions: for internal invariants and conditions that should never happen\n",
      "2. Exceptions: for handling expected error conditions and input validation\n",
      "\n",
      "Important note: Assertions can be disabled with Python's -O flag,\n",
      "so never use them for input validation in production code!\n",
      "\n",
      "Using assertions in testing:\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Basic assertion usage\n",
    "def get_positive_number(n):\n",
    "    \"\"\"Return n if it's positive, otherwise raise an AssertionError.\"\"\"\n",
    "    assert n > 0, 'Number must be positive'  # Assertion with error message\n",
    "    return n\n",
    "\n",
    "# Test with valid input\n",
    "print(\"Testing with positive number:\")\n",
    "print(get_positive_number(5))  # Works fine\n",
    "\n",
    "# Test with invalid input (commented out to avoid stopping notebook execution)\n",
    "print(\"\\nIf we tried with negative number: get_positive_number(-2)\")\n",
    "print(\"It would raise: AssertionError: Number must be positive\")\n",
    "# print(get_positive_number(-2))  # Uncomment to see the error\n",
    "\n",
    "# Advanced assertion use cases\n",
    "print(\"\\nAdvanced assertion examples:\")\n",
    "\n",
    "# Assertions for data validation\n",
    "def calculate_average(grades):\n",
    "    \"\"\"Calculate the average of a list of grades.\"\"\"\n",
    "    assert len(grades) > 0, \"Cannot calculate average of empty list\"\n",
    "    assert all(0 <= grade <= 100 for grade in grades), \"Grades must be between 0 and 100\"\n",
    "    \n",
    "    return sum(grades) / len(grades)\n",
    "\n",
    "# Valid input\n",
    "print(f\"Average grade: {calculate_average([85, 90, 95])}\")\n",
    "\n",
    "# Invalid inputs (commented out to avoid errors)\n",
    "print(\"\\nInvalid inputs would cause:\")\n",
    "print(\"calculate_average([]) → AssertionError: Cannot calculate average of empty list\")\n",
    "print(\"calculate_average([85, 105, 90]) → AssertionError: Grades must be between 0 and 100\")\n",
    "\n",
    "# Assertions in functions vs. input validation\n",
    "print(\"\\nAssertions vs. explicit validation:\")\n",
    "\n",
    "# Validation with assertions (for internal use)\n",
    "def internal_function(data):\n",
    "    \"\"\"Process data - for internal use where input validity is guaranteed.\"\"\"\n",
    "    assert isinstance(data, list), \"Data must be a list\"  # Checks data type\n",
    "    # Process data...\n",
    "    return f\"Processed {len(data)} items\"\n",
    "\n",
    "# Validation with explicit checks (for public APIs)\n",
    "def public_function(data):\n",
    "    \"\"\"Process data - for public API where input should be validated.\"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        raise TypeError(\"Data must be a list\")  # More appropriate for public API\n",
    "    # Process data...\n",
    "    return f\"Processed {len(data)} items\"\n",
    "\n",
    "# Test both approaches\n",
    "print(internal_function([1, 2, 3]))  # Works fine\n",
    "print(public_function([1, 2, 3]))   # Works fine too\n",
    "\n",
    "# When to use assertions vs exceptions\n",
    "print(\"\\nWhen to use assertions vs. exceptions:\")\n",
    "print(\"1. Assertions: for internal invariants and conditions that should never happen\")\n",
    "print(\"2. Exceptions: for handling expected error conditions and input validation\")\n",
    "print(\"\\nImportant note: Assertions can be disabled with Python's -O flag,\")\n",
    "print(\"so never use them for input validation in production code!\")\n",
    "\n",
    "# Testing with assertions\n",
    "print(\"\\nUsing assertions in testing:\")\n",
    "\n",
    "def is_even(n):\n",
    "    \"\"\"Return True if n is even, False otherwise.\"\"\"\n",
    "    return n % 2 == 0\n",
    "\n",
    "# Simple test function using assertions\n",
    "def test_is_even():\n",
    "    assert is_even(2) == True, \"2 should be even\"\n",
    "    assert is_even(4) == True, \"4 should be even\"\n",
    "    assert is_even(1) == False, \"1 should be odd\"\n",
    "    assert is_even(3) == False, \"3 should be odd\"\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_is_even()\n",
    "\n",
    "# Expected output:\n",
    "# Testing with positive number:\n",
    "# 5\n",
    "#\n",
    "# If we tried with negative number: get_positive_number(-2)\n",
    "# It would raise: AssertionError: Number must be positive\n",
    "#\n",
    "# Advanced assertion examples:\n",
    "# Average grade: 90.0\n",
    "#\n",
    "# Invalid inputs would cause:\n",
    "# calculate_average([]) → AssertionError: Cannot calculate average of empty list\n",
    "# calculate_average([85, 105, 90]) → AssertionError: Grades must be between 0 and 100\n",
    "#\n",
    "# Assertions vs. explicit validation:\n",
    "# Processed 3 items\n",
    "# Processed 3 items\n",
    "#\n",
    "# When to use assertions vs. exceptions:\n",
    "# 1. Assertions: for internal invariants and conditions that should never happen\n",
    "# 2. Exceptions: for handling expected error conditions and input validation\n",
    "#\n",
    "# Important note: Assertions can be disabled with Python's -O flag,\n",
    "# so never use them for input validation in production code!\n",
    "#\n",
    "# Using assertions in testing:\n",
    "# All tests passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a75dc",
   "metadata": {},
   "source": [
    "## 5. Property-Based Testing\n",
    "**Definition:** Property-based testing is a testing approach where instead of writing specific test cases, you define properties that should always hold true for your functions, and the testing framework automatically generates test inputs.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55d1132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis not installed. Run '!pip install hypothesis' to install.\n",
      "\n",
      "Property-based testing allows you to define general rules that your\n",
      "code should satisfy, then the framework generates test cases to try\n",
      "breaking those rules. Benefits include:\n",
      "1. Better test coverage with fewer test cases\n",
      "2. Finding edge cases you might not think of\n",
      "3. Automatically shrinking test cases to minimal failing examples\n",
      "4. Tests that adapt as your code evolves\n"
     ]
    }
   ],
   "source": [
    "# Install hypothesis if you're running this for the first time\n",
    "# !pip install hypothesis\n",
    "\n",
    "# Note: The next cell imports hypothesis and demonstrates property-based testing\n",
    "try:\n",
    "    from hypothesis import given, strategies as st\n",
    "    import unittest\n",
    "    \n",
    "    # Function to test\n",
    "    def sort_list(items):\n",
    "        \"\"\"Sort a list of integers in ascending order.\"\"\"\n",
    "        return sorted(items)\n",
    "    \n",
    "    # Property-based test using Hypothesis\n",
    "    @given(st.lists(st.integers()))\n",
    "    def test_sort_preserves_length(items):\n",
    "        \"\"\"Test that sorting preserves the length of the list.\"\"\"\n",
    "        sorted_items = sort_list(items)\n",
    "        assert len(sorted_items) == len(items), \"Sorting should preserve list length\"\n",
    "    \n",
    "    # Another property: sorting should be idempotent (sorting an already sorted list changes nothing)\n",
    "    @given(st.lists(st.integers()))\n",
    "    def test_sort_idempotent(items):\n",
    "        \"\"\"Test that sorting is idempotent (sorting twice = sorting once).\"\"\"\n",
    "        sorted_once = sort_list(items)\n",
    "        sorted_twice = sort_list(sorted_once)\n",
    "        assert sorted_once == sorted_twice, \"Sorting a sorted list should not change it\"\n",
    "    \n",
    "    # Another property: every item in original list should be in sorted list (and vice versa)\n",
    "    @given(st.lists(st.integers()))\n",
    "    def test_sort_contains_same_elements(items):\n",
    "        \"\"\"Test that sorting preserves all elements.\"\"\"\n",
    "        sorted_items = sort_list(items)\n",
    "        # Check that both lists contain the same elements, regardless of order\n",
    "        assert set(sorted_items) == set(items), \"Sorted list should contain same elements as original\"\n",
    "    \n",
    "    # Another property: sorted list should be in ascending order\n",
    "    @given(st.lists(st.integers()))\n",
    "    def test_sort_is_ordered(items):\n",
    "        \"\"\"Test that the result is actually sorted.\"\"\"\n",
    "        sorted_items = sort_list(items)\n",
    "        for i in range(len(sorted_items) - 1):\n",
    "            assert sorted_items[i] <= sorted_items[i + 1], \"List is not properly sorted\"\n",
    "    \n",
    "    # Run the tests\n",
    "    print(\"Running property-based tests...\")\n",
    "    test_sort_preserves_length()\n",
    "    test_sort_idempotent()\n",
    "    test_sort_contains_same_elements()\n",
    "    test_sort_is_ordered()\n",
    "    print(\"All property-based tests passed!\")\n",
    "    \n",
    "    # Integration with unittest framework\n",
    "    class TestSortingWithHypothesis(unittest.TestCase):\n",
    "        @given(st.lists(st.integers()))\n",
    "        def test_sort_preserves_length(self, items):\n",
    "            sorted_items = sort_list(items)\n",
    "            self.assertEqual(len(sorted_items), len(items))\n",
    "    \n",
    "    # Show more complex data generation strategies\n",
    "    print(\"\\nHypothesis can generate many types of test data:\")\n",
    "    print(\"- Integers: st.integers()\")\n",
    "    print(\"- Floating point: st.floats()\")\n",
    "    print(\"- Text: st.text()\")\n",
    "    print(\"- Dates: st.dates()\")\n",
    "    print(\"- Composite data: st.dictionaries(), st.tuples(), etc.\")\n",
    "    \n",
    "    # Example of a property that might fail sometimes\n",
    "    print(\"\\nExample of a property that might fail:\")\n",
    "    \n",
    "    def remove_duplicates(items):\n",
    "        \"\"\"Buggy implementation of removing duplicates from a list.\"\"\"\n",
    "        result = []\n",
    "        for item in items:\n",
    "            if item not in result:  # Inefficient but simple\n",
    "                result.append(item)\n",
    "        return result\n",
    "    \n",
    "    @given(st.lists(st.integers()))\n",
    "    def test_deduplication_length(items):\n",
    "        \"\"\"Test that deduplication doesn't increase length.\"\"\"\n",
    "        deduplicated = remove_duplicates(items)\n",
    "        assert len(deduplicated) <= len(items), \"Deduplication should not increase length\"\n",
    "    \n",
    "    test_deduplication_length()\n",
    "    print(\"Property test for remove_duplicates passed\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Hypothesis not installed. Run '!pip install hypothesis' to install.\")\n",
    "    print(\"\\nProperty-based testing allows you to define general rules that your\")\n",
    "    print(\"code should satisfy, then the framework generates test cases to try\")\n",
    "    print(\"breaking those rules. Benefits include:\")\n",
    "    print(\"1. Better test coverage with fewer test cases\")\n",
    "    print(\"2. Finding edge cases you might not think of\")\n",
    "    print(\"3. Automatically shrinking test cases to minimal failing examples\")\n",
    "    print(\"4. Tests that adapt as your code evolves\")\n",
    "\n",
    "# Expected output if hypothesis is installed:\n",
    "# Running property-based tests...\n",
    "# All property-based tests passed!\n",
    "#\n",
    "# Hypothesis can generate many types of test data:\n",
    "# - Integers: st.integers()\n",
    "# - Floating point: st.floats()\n",
    "# - Text: st.text()\n",
    "# - Dates: st.dates()\n",
    "# - Composite data: st.dictionaries(), st.tuples(), etc.\n",
    "#\n",
    "# Example of a property that might fail:\n",
    "# Property test for remove_duplicates passed\n",
    "#\n",
    "# If not installed, instructions will be shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6d77e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook covered essential Python testing and debugging concepts:\n",
    "\n",
    "1. **Unit Testing** - Writing tests to verify individual components work correctly\n",
    "2. **Logging** - Recording program events for monitoring and troubleshooting\n",
    "3. **Debugging** - Tools and techniques for finding and fixing bugs\n",
    "4. **Assertions** - Runtime checks to catch logical errors early\n",
    "5. **Property-Based Testing** - Generating test cases automatically based on properties\n",
    "\n",
    "**Best Practices:**\n",
    "- Write tests before or alongside your code (Test-Driven Development)\n",
    "- Use appropriate log levels and configure logging properly\n",
    "- Learn to use debugging tools effectively\n",
    "- Use assertions for internal invariants, not input validation\n",
    "- Consider both example-based and property-based testing\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore test coverage tools like `coverage.py`\n",
    "- Learn about mocking for testing with `unittest.mock`\n",
    "- Set up continuous integration to run tests automatically\n",
    "- Investigate profiling tools for performance optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
