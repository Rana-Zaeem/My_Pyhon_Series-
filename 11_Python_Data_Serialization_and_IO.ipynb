{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41de0771",
   "metadata": {},
   "source": [
    "# Python Data Serialization and I/O\n",
    "This notebook covers data serialization and input/output (I/O) in Python, including pickle, CSV, XML, Excel, images, and PDFs, with real-life use cases, best practices, and code examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1983067",
   "metadata": {},
   "source": [
    "## 1. Pickle (Object Serialization)\n",
    "**Definition:** Pickle is used to serialize and deserialize Python objects. Useful for saving models or data structures.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Basic pickle example\n",
    "# Create a Python dictionary\n",
    "data = {'a': 1, 'b': 2, 'c': [3, 4, 5], 'd': {'nested': 'dictionary'}}\n",
    "\n",
    "# Serialize the data to a file\n",
    "print(\"Pickling data to file...\")\n",
    "with open('data.pkl', 'wb') as f:  # 'wb' mode for writing binary data\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# Deserialize the data from the file\n",
    "print(\"Unpickling data from file...\")\n",
    "with open('data.pkl', 'rb') as f:  # 'rb' mode for reading binary data\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "# Check if the loaded data matches the original\n",
    "print(f\"Original data: {data}\")\n",
    "print(f\"Loaded data: {loaded_data}\")\n",
    "print(f\"Data matches: {data == loaded_data}\")\n",
    "\n",
    "# Pickling multiple objects\n",
    "print(\"\\nPickling multiple objects...\")\n",
    "data1 = [1, 2, 3, 4]\n",
    "data2 = \"Hello, world!\"\n",
    "data3 = {\"key\": \"value\"}\n",
    "\n",
    "with open('multiple.pkl', 'wb') as f:\n",
    "    pickle.dump(data1, f)\n",
    "    pickle.dump(data2, f)\n",
    "    pickle.dump(data3, f)\n",
    "\n",
    "with open('multiple.pkl', 'rb') as f:\n",
    "    loaded1 = pickle.load(f)\n",
    "    loaded2 = pickle.load(f)\n",
    "    loaded3 = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded objects: {loaded1}, {loaded2}, {loaded3}\")\n",
    "\n",
    "# Pickling more complex objects (like NumPy arrays)\n",
    "print(\"\\nPickling NumPy arrays...\")\n",
    "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"Original array:\\n{array}\")\n",
    "\n",
    "with open('array.pkl', 'wb') as f:\n",
    "    pickle.dump(array, f)\n",
    "\n",
    "with open('array.pkl', 'rb') as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded array:\\n{loaded_array}\")\n",
    "print(f\"Arrays equal: {np.array_equal(array, loaded_array)}\")\n",
    "\n",
    "# Custom objects can also be pickled\n",
    "print(\"\\nPickling custom objects...\")\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "    \n",
    "    def greet(self):\n",
    "        return f\"Hello, my name is {self.name} and I am {self.age} years old.\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Person):\n",
    "            return False\n",
    "        return self.name == other.name and self.age == other.age\n",
    "\n",
    "# Create an instance\n",
    "person = Person(\"Alice\", 30)\n",
    "print(f\"Original greeting: {person.greet()}\")\n",
    "\n",
    "# Pickle the object\n",
    "with open('person.pkl', 'wb') as f:\n",
    "    pickle.dump(person, f)\n",
    "\n",
    "# Unpickle the object\n",
    "with open('person.pkl', 'rb') as f:\n",
    "    loaded_person = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded greeting: {loaded_person.greet()}\")\n",
    "print(f\"Objects equal: {person == loaded_person}\")\n",
    "\n",
    "# Performance comparison (pickle vs manual serialization)\n",
    "print(\"\\nPerformance comparison:\")\n",
    "\n",
    "# Generate a large dictionary\n",
    "large_dict = {i: f\"value_{i}\" for i in range(10000)}\n",
    "\n",
    "# Measure time for pickle\n",
    "start_time = time.time()\n",
    "with open('large.pkl', 'wb') as f:\n",
    "    pickle.dump(large_dict, f)\n",
    "with open('large.pkl', 'rb') as f:\n",
    "    _ = pickle.load(f)\n",
    "pickle_time = time.time() - start_time\n",
    "print(f\"Pickle time: {pickle_time:.4f} seconds\")\n",
    "\n",
    "# Measure time for manual JSON serialization\n",
    "start_time = time.time()\n",
    "import json\n",
    "with open('large.json', 'w') as f:\n",
    "    json.dump(large_dict, f)\n",
    "with open('large.json', 'r') as f:\n",
    "    _ = json.load(f)\n",
    "json_time = time.time() - start_time\n",
    "print(f\"JSON time: {json_time:.4f} seconds\")\n",
    "\n",
    "# Different pickle protocols\n",
    "print(\"\\nPickle protocols:\")\n",
    "for protocol in range(pickle.HIGHEST_PROTOCOL + 1):\n",
    "    filename = f\"protocol_{protocol}.pkl\"\n",
    "    start_time = time.time()\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(large_dict, f, protocol=protocol)\n",
    "    end_time = time.time()\n",
    "    filesize = os.path.getsize(filename)\n",
    "    print(f\"Protocol {protocol}: {end_time - start_time:.4f} seconds, {filesize} bytes\")\n",
    "\n",
    "# Security warning\n",
    "print(\"\\nSECURITY WARNING: Never unpickle data from untrusted sources!\")\n",
    "print(\"Pickle can execute arbitrary code during unpickling.\")\n",
    "\n",
    "# Clean up created files\n",
    "for file in ['data.pkl', 'multiple.pkl', 'array.pkl', 'person.pkl', 'large.pkl', 'large.json'] + \\\n",
    "           [f\"protocol_{i}.pkl\" for i in range(pickle.HIGHEST_PROTOCOL + 1)]:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "# Expected output:\n",
    "# Pickling data to file...\n",
    "# Unpickling data from file...\n",
    "# Original data: {'a': 1, 'b': 2, 'c': [3, 4, 5], 'd': {'nested': 'dictionary'}}\n",
    "# Loaded data: {'a': 1, 'b': 2, 'c': [3, 4, 5], 'd': {'nested': 'dictionary'}}\n",
    "# Data matches: True\n",
    "#\n",
    "# Pickling multiple objects...\n",
    "# Loaded objects: [1, 2, 3, 4], Hello, world!, {'key': 'value'}\n",
    "#\n",
    "# Pickling NumPy arrays...\n",
    "# Original array:\n",
    "# [[1 2 3]\n",
    "#  [4 5 6]]\n",
    "# Loaded array:\n",
    "# [[1 2 3]\n",
    "#  [4 5 6]]\n",
    "# Arrays equal: True\n",
    "#\n",
    "# Pickling custom objects...\n",
    "# Original greeting: Hello, my name is Alice and I am 30 years old.\n",
    "# Loaded greeting: Hello, my name is Alice and I am 30 years old.\n",
    "# Objects equal: True\n",
    "#\n",
    "# Performance comparison:\n",
    "# Pickle time: 0.1234 seconds\n",
    "# JSON time: 0.0678 seconds\n",
    "#\n",
    "# Pickle protocols:\n",
    "# Protocol 0: 0.1234 seconds, 160000 bytes\n",
    "# Protocol 1: 0.0987 seconds, 125000 bytes\n",
    "# Protocol 2: 0.0754 seconds, 110000 bytes\n",
    "# Protocol 3: 0.0612 seconds, 100000 bytes\n",
    "# Protocol 4: 0.0534 seconds, 90000 bytes\n",
    "# Protocol 5: 0.0523 seconds, 85000 bytes\n",
    "#\n",
    "# SECURITY WARNING: Never unpickle data from untrusted sources!\n",
    "# Pickle can execute arbitrary code during unpickling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1c579",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "{'a': 1, 'b': 2}\n",
    "\n",
    "**Real-life use case:** Saving trained machine learning models for later use.\n",
    "\n",
    "**Common mistakes:** Pickle files are not secure against code execution attacks. Never unpickle data from untrusted sources.\n",
    "\n",
    "**Best practices:** Use pickle only for trusted data and consider alternatives for cross-language compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03c7b2",
   "metadata": {},
   "source": [
    "## 2. CSV Files\n",
    "**Definition:** CSV (Comma-Separated Values) is a common format for tabular data.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15070658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Basic CSV writing example\n",
    "print(\"Basic CSV writing example:\")\n",
    "\n",
    "# Create a CSV file\n",
    "with open('example.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['name', 'age', 'city'])\n",
    "    # Write data rows\n",
    "    writer.writerow(['Alice', 30, 'New York'])\n",
    "    writer.writerow(['Bob', 25, 'San Francisco'])\n",
    "    writer.writerow(['Charlie', 35, 'Chicago'])\n",
    "\n",
    "# Basic CSV reading example\n",
    "print(\"\\nBasic CSV reading example:\")\n",
    "with open('example.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            print(f\"Header: {row}\")\n",
    "        else:\n",
    "            print(f\"Data row {i}: {row}\")\n",
    "\n",
    "# Using DictReader and DictWriter for more readable code\n",
    "print(\"\\nUsing DictReader and DictWriter:\")\n",
    "\n",
    "# Create a CSV file with DictWriter\n",
    "with open('dict_example.csv', 'w', newline='') as f:\n",
    "    fieldnames = ['id', 'name', 'department', 'salary']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # Write the header row\n",
    "    writer.writerow({'id': 1, 'name': 'John', 'department': 'IT', 'salary': 75000})\n",
    "    writer.writerow({'id': 2, 'name': 'Jane', 'department': 'HR', 'salary': 65000})\n",
    "    writer.writerow({'id': 3, 'name': 'Bob', 'department': 'Sales', 'salary': 80000})\n",
    "\n",
    "# Read CSV with DictReader\n",
    "with open('dict_example.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    print(\"Employee data:\")\n",
    "    for row in reader:\n",
    "        print(f\"  ID: {row['id']}, Name: {row['name']}, Dept: {row['department']}, Salary: ${row['salary']}\")\n",
    "\n",
    "# Handling different delimiters\n",
    "print(\"\\nHandling different delimiters:\")\n",
    "\n",
    "# Write a TSV (Tab-Separated Values) file\n",
    "with open('tab_example.tsv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['Name', 'Country', 'Profession'])\n",
    "    writer.writerow(['Maria', 'Brazil', 'Engineer'])\n",
    "    writer.writerow(['Ahmed', 'Egypt', 'Doctor'])\n",
    "\n",
    "# Read TSV file\n",
    "with open('tab_example.tsv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    print(\"Tab-separated data:\")\n",
    "    for row in reader:\n",
    "        print(f\"  {' | '.join(row)}\")\n",
    "\n",
    "# Handling quotes and special characters\n",
    "print(\"\\nHandling quotes and special characters:\")\n",
    "\n",
    "# Create data with commas and quotes\n",
    "complex_data = [\n",
    "    ['ID', 'Description', 'Notes'],\n",
    "    [1, 'Product, with comma', 'Customer said \"excellent quality\"'],\n",
    "    [2, 'Another, item', 'Multiple\\nlines\\nof text']\n",
    "]\n",
    "\n",
    "# Write to CSV with appropriate quoting\n",
    "with open('complex.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerows(complex_data)\n",
    "\n",
    "# Read back with proper handling\n",
    "with open('complex.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    print(\"Complex data with special characters:\")\n",
    "    for row in reader:\n",
    "        print(f\"  {row}\")\n",
    "\n",
    "# Different quoting styles\n",
    "print(\"\\nDifferent quoting styles:\")\n",
    "quoting_styles = {\n",
    "    'QUOTE_MINIMAL': csv.QUOTE_MINIMAL,     # Quote fields only if needed (default)\n",
    "    'QUOTE_ALL': csv.QUOTE_ALL,             # Quote all fields\n",
    "    'QUOTE_NONNUMERIC': csv.QUOTE_NONNUMERIC, # Quote all non-numeric fields\n",
    "    'QUOTE_NONE': csv.QUOTE_NONE            # Never quote fields\n",
    "}\n",
    "\n",
    "sample_data = [['Name', 'Age', 'Comment'], ['Alice', 30, 'Good, student']]\n",
    "\n",
    "for name, style in quoting_styles.items():\n",
    "    output = io.StringIO()\n",
    "    writer = csv.writer(output, quoting=style)\n",
    "    writer.writerows(sample_data)\n",
    "    print(f\"  {name}: {output.getvalue().strip()}\")\n",
    "\n",
    "# Handling encoding issues\n",
    "print(\"\\nHandling encoding issues:\")\n",
    "print(\"When working with CSV files that contain non-ASCII characters:\")\n",
    "print(\"with open('data.csv', 'r', encoding='utf-8') as f:  # Specify encoding\")\n",
    "print(\"    reader = csv.reader(f)\")\n",
    "print(\"    # etc...\")\n",
    "\n",
    "# Working with large CSV files\n",
    "print(\"\\nWorking with large CSV files:\")\n",
    "print(\"For large files, read in chunks to avoid memory issues:\")\n",
    "print(\"\"\"def process_large_csv(filename, chunk_size=1000):\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)  # Read the header\n",
    "        \n",
    "        chunk = []\n",
    "        for i, row in enumerate(reader):\n",
    "            chunk.append(row)\n",
    "            \n",
    "            # Process each chunk\n",
    "            if (i + 1) % chunk_size == 0:\n",
    "                process_chunk(chunk, header)\n",
    "                chunk = []\n",
    "                \n",
    "        # Process the last chunk if it exists\n",
    "        if chunk:\n",
    "            process_chunk(chunk, header)\n",
    "\"\"\")\n",
    "\n",
    "# Using pandas with CSV\n",
    "print(\"\\nUsing pandas with CSV:\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'age': [30, 25, 35, 28],\n",
    "    'city': ['New York', 'San Francisco', 'Chicago', 'Boston'],\n",
    "    'score': [85.5, 92.0, 78.5, 90.0]\n",
    "})\n",
    "\n",
    "# Write to CSV\n",
    "df.to_csv('pandas_example.csv', index=False)\n",
    "\n",
    "# Read from CSV\n",
    "df_read = pd.read_csv('pandas_example.csv')\n",
    "print(\"DataFrame from CSV:\")\n",
    "print(df_read.head())\n",
    "\n",
    "# Pandas additional options\n",
    "print(\"\\nPandas additional options:\")\n",
    "print(\"Writing with specific options:\")\n",
    "print(\"df.to_csv('output.csv', index=False, sep='|', na_rep='NULL')\")\n",
    "\n",
    "print(\"\\nReading with specific options:\")\n",
    "print(\"pd.read_csv('input.csv', usecols=['name', 'age'], nrows=100, skiprows=1)\")\n",
    "\n",
    "# Best practices\n",
    "print(\"\\nCSV best practices:\")\n",
    "best_practices = [\n",
    "    \"1. Always specify newline='' when opening files to avoid platform-specific issues\",\n",
    "    \"2. Specify encoding (usually utf-8) when working with international characters\",\n",
    "    \"3. Use DictReader/DictWriter for more readable code with named columns\",\n",
    "    \"4. Consider using pandas for complex CSV operations in data science\",\n",
    "    \"5. Use appropriate quoting settings for data with special characters\",\n",
    "    \"6. Process large files in chunks to avoid memory issues\",\n",
    "    \"7. Include error handling for malformed CSV data\",\n",
    "    \"8. Always close file handles (or use 'with' statements)\"\n",
    "]\n",
    "\n",
    "for practice in best_practices:\n",
    "    print(practice)\n",
    "\n",
    "# Clean up created files\n",
    "for file in ['example.csv', 'dict_example.csv', 'tab_example.tsv', 'complex.csv', 'pandas_example.csv']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "# Expected output:\n",
    "# Basic CSV writing example:\n",
    "#\n",
    "# Basic CSV reading example:\n",
    "# Header: ['name', 'age', 'city']\n",
    "# Data row 1: ['Alice', '30', 'New York']\n",
    "# Data row 2: ['Bob', '25', 'San Francisco']\n",
    "# Data row 3: ['Charlie', '35', 'Chicago']\n",
    "#\n",
    "# Using DictReader and DictWriter:\n",
    "# Employee data:\n",
    "#   ID: 1, Name: John, Dept: IT, Salary: $75000\n",
    "#   ID: 2, Name: Jane, Dept: HR, Salary: $65000\n",
    "#   ID: 3, Name: Bob, Dept: Sales, Salary: $80000\n",
    "#\n",
    "# Handling different delimiters:\n",
    "# Tab-separated data:\n",
    "#   Name | Country | Profession\n",
    "#   Maria | Brazil | Engineer\n",
    "#   Ahmed | Egypt | Doctor\n",
    "#\n",
    "# Handling quotes and special characters:\n",
    "# Complex data with special characters:\n",
    "#   ['ID', 'Description', 'Notes']\n",
    "#   ['1', 'Product, with comma', 'Customer said \"excellent quality\"']\n",
    "#   ['2', 'Another, item', 'Multiple\\nlines\\nof text']\n",
    "#\n",
    "# Different quoting styles:\n",
    "#   QUOTE_MINIMAL: Name,Age,Comment\\nAlice,30,\"Good, student\"\n",
    "#   QUOTE_ALL: \"Name\",\"Age\",\"Comment\"\\n\"Alice\",\"30\",\"Good, student\"\n",
    "#   QUOTE_NONNUMERIC: \"Name\",Age,\"Comment\"\\n\"Alice\",30,\"Good, student\"\n",
    "#   QUOTE_NONE: Name,Age,Comment\\nAlice,30,Good, student\n",
    "#\n",
    "# Handling encoding issues:\n",
    "# When working with CSV files that contain non-ASCII characters:\n",
    "# with open('data.csv', 'r', encoding='utf-8') as f:  # Specify encoding\n",
    "#     reader = csv.reader(f)\n",
    "#     # etc...\n",
    "#\n",
    "# Working with large CSV files:\n",
    "# For large files, read in chunks to avoid memory issues:\n",
    "# <code example for processing large files>\n",
    "#\n",
    "# Using pandas with CSV:\n",
    "# DataFrame from CSV:\n",
    "#    name  age          city  score\n",
    "# 0  Alice   30      New York   85.5\n",
    "# 1    Bob   25  San Francisco   92.0\n",
    "# 2  Charlie   35       Chicago   78.5\n",
    "# 3   Diana   28        Boston   90.0\n",
    "#\n",
    "# Pandas additional options:\n",
    "# Writing with specific options:\n",
    "# df.to_csv('output.csv', index=False, sep='|', na_rep='NULL')\n",
    "#\n",
    "# Reading with specific options:\n",
    "# pd.read_csv('input.csv', usecols=['name', 'age'], nrows=100, skiprows=1)\n",
    "#\n",
    "# CSV best practices:\n",
    "# 1. Always specify newline='' when opening files to avoid platform-specific issues\n",
    "# <more best practices...>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a77b54",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "['name', 'age']\n",
    "['Alice', '30']\n",
    "['Bob', '25']\n",
    "\n",
    "**Real-life use case:** Importing/exporting data between Excel and Python.\n",
    "\n",
    "**Common mistakes:** Not handling newlines or encoding issues.\n",
    "\n",
    "**Best practices:** Always specify newline='' and encoding when working with CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b79ad0",
   "metadata": {},
   "source": [
    "## 3. XML Files\n",
    "**Definition:** XML (eXtensible Markup Language) is used for structured data exchange.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ba609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import io\n",
    "from pprint import pprint\n",
    "\n",
    "# Basic XML parsing example\n",
    "print(\"Basic XML parsing example:\")\n",
    "\n",
    "# Create a simple XML string\n",
    "xml_data = '''\n",
    "<root>\n",
    "  <person id=\"1\">\n",
    "    <name>Alice</name>\n",
    "    <age>30</age>\n",
    "    <skills>\n",
    "      <skill>Python</skill>\n",
    "      <skill>Data Science</skill>\n",
    "    </skills>\n",
    "  </person>\n",
    "  <person id=\"2\">\n",
    "    <name>Bob</name>\n",
    "    <age>25</age>\n",
    "    <skills>\n",
    "      <skill>Java</skill>\n",
    "      <skill>DevOps</skill>\n",
    "    </skills>\n",
    "  </person>\n",
    "</root>\n",
    "'''\n",
    "\n",
    "# Parse XML from string\n",
    "root = ET.fromstring(xml_data)\n",
    "\n",
    "# Find all person elements\n",
    "print(\"People in the XML:\")\n",
    "for person in root.findall('person'):\n",
    "    # Get attribute\n",
    "    person_id = person.get('id')\n",
    "    \n",
    "    # Get child element text\n",
    "    name = person.find('name').text\n",
    "    age = person.find('age').text\n",
    "    \n",
    "    # Get multiple child elements\n",
    "    skills = [skill.text for skill in person.find('skills').findall('skill')]\n",
    "    \n",
    "    print(f\"  Person ID: {person_id}\")\n",
    "    print(f\"    Name: {name}\")\n",
    "    print(f\"    Age: {age}\")\n",
    "    print(f\"    Skills: {', '.join(skills)}\")\n",
    "\n",
    "# Creating XML with ElementTree\n",
    "print(\"\\nCreating XML with ElementTree:\")\n",
    "\n",
    "# Create root element\n",
    "new_root = ET.Element('employees')\n",
    "\n",
    "# Create first employee element\n",
    "emp1 = ET.SubElement(new_root, 'employee')\n",
    "emp1.set('id', '1')  # Set attribute\n",
    "\n",
    "ET.SubElement(emp1, 'name').text = 'John Doe'\n",
    "ET.SubElement(emp1, 'position').text = 'Manager'\n",
    "ET.SubElement(emp1, 'department').text = 'IT'\n",
    "\n",
    "# Create second employee element\n",
    "emp2 = ET.SubElement(new_root, 'employee')\n",
    "emp2.set('id', '2')\n",
    "\n",
    "ET.SubElement(emp2, 'name').text = 'Jane Smith'\n",
    "ET.SubElement(emp2, 'position').text = 'Developer'\n",
    "ET.SubElement(emp2, 'department').text = 'IT'\n",
    "\n",
    "# Convert to XML string with proper indentation\n",
    "output = io.StringIO()\n",
    "ET.ElementTree(new_root).write(output, encoding='unicode', xml_declaration=True, method='xml')\n",
    "\n",
    "# Add manual indentation for readability\n",
    "def indent_xml(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for elem in elem:\n",
    "            indent_xml(elem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i\n",
    "\n",
    "indent_xml(new_root)\n",
    "xml_str = ET.tostring(new_root, encoding='unicode')\n",
    "print(xml_str)\n",
    "\n",
    "# Working with XML files\n",
    "print(\"\\nWorking with XML files:\")\n",
    "\n",
    "# Write XML to file\n",
    "tree = ET.ElementTree(new_root)\n",
    "tree.write('employees.xml')\n",
    "\n",
    "# Read XML from file\n",
    "print(\"Reading XML from file:\")\n",
    "tree = ET.parse('employees.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "print(f\"Root tag: {root.tag}\")\n",
    "print(f\"Number of employees: {len(root)}\")\n",
    "\n",
    "# Finding elements with XPath\n",
    "print(\"\\nFinding elements with XPath:\")\n",
    "\n",
    "# Parse original XML data again for XPath examples\n",
    "root = ET.fromstring(xml_data)\n",
    "\n",
    "# Examples of XPath expressions\n",
    "xpath_examples = [\n",
    "    (\".//name\", \"All name elements\"),\n",
    "    (\"./person[@id='1']\", \"Person with id=1\"),\n",
    "    (\".//skill\", \"All skill elements\"),\n",
    "    (\"./person[age='25']\", \"Person with age=25\"),\n",
    "]\n",
    "\n",
    "for xpath, description in xpath_examples:\n",
    "    elements = root.findall(xpath)\n",
    "    print(f\"{description} ({xpath}):\")\n",
    "    for elem in elements:\n",
    "        if elem.text:  # Element with text\n",
    "            print(f\"  {elem.tag}: {elem.text}\")\n",
    "        else:  # Container element\n",
    "            attrs = ' '.join([f\"{k}='{v}'\" for k, v in elem.attrib.items()])\n",
    "            print(f\"  <{elem.tag} {attrs}>\")\n",
    "\n",
    "# Handling large XML files efficiently\n",
    "print(\"\\nHandling large XML files efficiently:\")\n",
    "print(\"Using iterparse to process large XML files without loading everything into memory:\")\n",
    "\n",
    "# Example code (not executed)\n",
    "large_xml_code = '''\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def process_large_xml(filename):\n",
    "    # Context object for keeping track of what we've seen\n",
    "    context = {}\n",
    "    \n",
    "    # Get an iterable for XML elements\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'start':\n",
    "            # Do something when we first encounter an element\n",
    "            pass\n",
    "        elif event == 'end':\n",
    "            # Process element after all children have been processed\n",
    "            if elem.tag == 'person':\n",
    "                process_person(elem, context)\n",
    "                # Clear element to free memory\n",
    "                elem.clear()\n",
    "'''\n",
    "print(large_xml_code)\n",
    "\n",
    "# Handling namespaces in XML\n",
    "print(\"\\nHandling namespaces in XML:\")\n",
    "\n",
    "# Example XML with namespaces\n",
    "xml_with_ns = '''\n",
    "<root xmlns=\"http://default-namespace.org\" \n",
    "      xmlns:ns1=\"http://example.org/ns1\" \n",
    "      xmlns:ns2=\"http://example.org/ns2\">\n",
    "  <ns1:item id=\"1\">Default namespace item</ns1:item>\n",
    "  <ns2:item id=\"2\">Another namespaced item</ns2:item>\n",
    "</root>\n",
    "'''\n",
    "\n",
    "# Parse XML with namespaces\n",
    "root = ET.fromstring(xml_with_ns)\n",
    "\n",
    "# Define namespace map\n",
    "namespaces = {\n",
    "    'default': 'http://default-namespace.org',\n",
    "    'ns1': 'http://example.org/ns1',\n",
    "    'ns2': 'http://example.org/ns2'\n",
    "}\n",
    "\n",
    "print(\"Finding elements with namespaces:\")\n",
    "# Find elements in specific namespace\n",
    "ns1_items = root.findall('.//{http://example.org/ns1}item')\n",
    "print(f\"Items in ns1 namespace: {len(ns1_items)}\")\n",
    "for item in ns1_items:\n",
    "    print(f\"  ID: {item.get('id')}, Text: {item.text}\")\n",
    "\n",
    "# Using namespace map with find/findall\n",
    "print(\"\\nUsing namespace map:\")\n",
    "ns2_items = root.findall('.//ns2:item', namespaces)\n",
    "print(f\"Items in ns2 namespace: {len(ns2_items)}\")\n",
    "for item in ns2_items:\n",
    "    print(f\"  ID: {item.get('id')}, Text: {item.text}\")\n",
    "\n",
    "# Alternative XML libraries in Python\n",
    "print(\"\\nAlternative XML libraries in Python:\")\n",
    "alternatives = {\n",
    "    \"lxml\": \"Faster and more feature-rich XML processing, compatible with ElementTree API\",\n",
    "    \"BeautifulSoup\": \"More forgiving XML/HTML parser, good for web scraping\",\n",
    "    \"xmltodict\": \"Converts XML to Python dictionaries for easier handling\"\n",
    "}\n",
    "for lib, desc in alternatives.items():\n",
    "    print(f\"- {lib}: {desc}\")\n",
    "\n",
    "# Clean up files created\n",
    "if os.path.exists('employees.xml'):\n",
    "    os.remove('employees.xml')\n",
    "\n",
    "# Expected output (abbreviated):\n",
    "# Basic XML parsing example:\n",
    "# People in the XML:\n",
    "#   Person ID: 1\n",
    "#     Name: Alice\n",
    "#     Age: 30\n",
    "#     Skills: Python, Data Science\n",
    "#   Person ID: 2\n",
    "#     Name: Bob\n",
    "#     Age: 25\n",
    "#     Skills: Java, DevOps\n",
    "#\n",
    "# Creating XML with ElementTree:\n",
    "# <employees>\n",
    "#   <employee id=\"1\">\n",
    "#     <name>John Doe</name>\n",
    "#     <position>Manager</position>\n",
    "#     <department>IT</department>\n",
    "#   </employee>\n",
    "#   <employee id=\"2\">\n",
    "#     <name>Jane Smith</name>\n",
    "#     <position>Developer</position>\n",
    "#     <department>IT</department>\n",
    "#   </employee>\n",
    "# </employees>\n",
    "#\n",
    "# Working with XML files:\n",
    "# Reading XML from file:\n",
    "# Root tag: employees\n",
    "# Number of employees: 2\n",
    "#\n",
    "# Finding elements with XPath:\n",
    "# All name elements (.//name):\n",
    "#   name: Alice\n",
    "#   name: Bob\n",
    "# Person with id=1 (./person[@id='1']):\n",
    "#   <person id='1'>\n",
    "# All skill elements (.//skill):\n",
    "#   skill: Python\n",
    "#   skill: Data Science\n",
    "#   skill: Java\n",
    "#   skill: DevOps\n",
    "# Person with age=25 (./person[age='25']):\n",
    "#   <person id='2'>\n",
    "#\n",
    "# Handling large XML files efficiently:\n",
    "# Using iterparse to process large XML files without loading everything into memory:\n",
    "# <code example>\n",
    "#\n",
    "# Handling namespaces in XML:\n",
    "# Finding elements with namespaces:\n",
    "# Items in ns1 namespace: 1\n",
    "#   ID: 1, Text: Default namespace item\n",
    "#\n",
    "# Using namespace map:\n",
    "# Items in ns2 namespace: 1\n",
    "#   ID: 2, Text: Another namespaced item\n",
    "#\n",
    "# Alternative XML libraries in Python:\n",
    "# - lxml: Faster and more feature-rich XML processing, compatible with ElementTree API\n",
    "# - BeautifulSoup: More forgiving XML/HTML parser, good for web scraping\n",
    "# - xmltodict: Converts XML to Python dictionaries for easier handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa20da",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "A\n",
    "B\n",
    "\n",
    "**Real-life use case:** Reading configuration files or data from web services.\n",
    "\n",
    "**Common mistakes:** Not handling namespaces or large files efficiently.\n",
    "\n",
    "**Best practices:** Use iterparse for large XML files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d3434",
   "metadata": {},
   "source": [
    "## 4. Excel Files\n",
    "**Definition:** Excel files are widely used for data storage and analysis. Use `pandas` for easy reading/writing.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Basic Excel writing with pandas\n",
    "print(\"Basic Excel writing with pandas:\")\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Evan'],\n",
    "    'age': [30, 25, 35, 28, 42],\n",
    "    'department': ['IT', 'HR', 'Finance', 'IT', 'Marketing'],\n",
    "    'salary': [75000, 65000, 80000, 70000, 85000],\n",
    "    'hire_date': ['2020-01-15', '2021-03-10', '2019-07-22', '2020-11-05', '2018-05-30']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "df['hire_date'] = pd.to_datetime(df['hire_date'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Write to Excel file\n",
    "print(\"\\nWriting DataFrame to Excel...\")\n",
    "df.to_excel('example.xlsx', index=False)\n",
    "\n",
    "# Read from Excel file\n",
    "print(\"Reading DataFrame from Excel...\")\n",
    "df2 = pd.read_excel('example.xlsx')\n",
    "print(df2.head())\n",
    "\n",
    "# Working with multiple sheets\n",
    "print(\"\\nWorking with multiple sheets:\")\n",
    "\n",
    "# Create another DataFrame\n",
    "projects = pd.DataFrame({\n",
    "    'project_id': ['P001', 'P002', 'P003', 'P004'],\n",
    "    'project_name': ['Website Redesign', 'Database Migration', 'Mobile App', 'Cloud Integration'],\n",
    "    'budget': [50000, 75000, 100000, 60000],\n",
    "    'deadline': ['2023-12-31', '2023-10-15', '2024-03-01', '2023-11-30']\n",
    "})\n",
    "\n",
    "# Write multiple DataFrames to different sheets\n",
    "with pd.ExcelWriter('company_data.xlsx') as writer:\n",
    "    df.to_excel(writer, sheet_name='Employees', index=False)\n",
    "    projects.to_excel(writer, sheet_name='Projects', index=False)\n",
    "\n",
    "# Read specific sheet from Excel\n",
    "employees = pd.read_excel('company_data.xlsx', sheet_name='Employees')\n",
    "print(\"Employees sheet:\")\n",
    "print(employees.head(3))  # Show first 3 rows\n",
    "\n",
    "projects = pd.read_excel('company_data.xlsx', sheet_name='Projects')\n",
    "print(\"\\nProjects sheet:\")\n",
    "print(projects.head(3))  # Show first 3 rows\n",
    "\n",
    "# List all sheets in an Excel file\n",
    "print(\"\\nListing all sheets in Excel file:\")\n",
    "xl = pd.ExcelFile('company_data.xlsx')\n",
    "print(f\"Sheets in file: {xl.sheet_names}\")\n",
    "\n",
    "# Formatting Excel output\n",
    "print(\"\\nFormatting Excel output:\")\n",
    "\n",
    "# Create a more complete example (won't run for real in this notebook, just demonstration)\n",
    "formatting_code = '''\n",
    "# Create a new Excel file with formatting\n",
    "with pd.ExcelWriter('formatted_report.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Write DataFrame to sheet\n",
    "    df.to_excel(writer, sheet_name='Report', index=False)\n",
    "    \n",
    "    # Get the xlsxwriter workbook and worksheet objects\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Report']\n",
    "    \n",
    "    # Add formats\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    currency_format = workbook.add_format({\n",
    "        'num_format': '$#,##0'\n",
    "    })\n",
    "    \n",
    "    date_format = workbook.add_format({\n",
    "        'num_format': 'yyyy-mm-dd'\n",
    "    })\n",
    "    \n",
    "    # Apply formats to specific columns\n",
    "    worksheet.set_column('A:A', 15)  # Width of name column\n",
    "    worksheet.set_column('D:D', 12, currency_format)  # Apply currency format to salary\n",
    "    worksheet.set_column('E:E', 12, date_format)  # Apply date format to hire_date\n",
    "    \n",
    "    # Apply header format to the header row\n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "        \n",
    "    # Create a chart\n",
    "    chart = workbook.add_chart({'type': 'column'})\n",
    "    \n",
    "    # Configure the chart\n",
    "    chart.add_series({\n",
    "        'name': 'Salaries',\n",
    "        'categories': ['Report', 1, 0, 5, 0],  # Names (A2:A6)\n",
    "        'values': ['Report', 1, 3, 5, 3],      # Salary values (D2:D6)\n",
    "    })\n",
    "    \n",
    "    chart.set_title({'name': 'Employee Salaries'})\n",
    "    chart.set_x_axis({'name': 'Employee'})\n",
    "    chart.set_y_axis({'name': 'Salary ($)', 'major_gridlines': {'visible': False}})\n",
    "    \n",
    "    # Insert the chart into the worksheet\n",
    "    worksheet.insert_chart('G2', chart)\n",
    "'''\n",
    "print(formatting_code)\n",
    "\n",
    "# Using openpyxl directly for more control\n",
    "print(\"\\nUsing openpyxl directly for more control:\")\n",
    "openpyxl_code = '''\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Create a new workbook and select the active sheet\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Employee Data\"\n",
    "\n",
    "# Add headers\n",
    "headers = [\"Name\", \"Age\", \"Department\", \"Salary\", \"Hire Date\"]\n",
    "for col_num, header in enumerate(headers, 1):\n",
    "    cell = ws.cell(row=1, column=col_num)\n",
    "    cell.value = header\n",
    "    cell.font = Font(bold=True)\n",
    "    cell.fill = PatternFill(\"solid\", fgColor=\"A9D08E\")\n",
    "    cell.alignment = Alignment(horizontal=\"center\")\n",
    "\n",
    "# Add data\n",
    "data = [\n",
    "    [\"Alice\", 30, \"IT\", 75000, \"2020-01-15\"],\n",
    "    [\"Bob\", 25, \"HR\", 65000, \"2021-03-10\"],\n",
    "    # ... more data ...\n",
    "]\n",
    "\n",
    "for row_num, row_data in enumerate(data, 2):\n",
    "    for col_num, cell_value in enumerate(row_data, 1):\n",
    "        cell = ws.cell(row=row_num, column=col_num)\n",
    "        cell.value = cell_value\n",
    "\n",
    "# Set column widths\n",
    "for col in ws.columns:\n",
    "    column = col[0].column_letter\n",
    "    ws.column_dimensions[column].width = 15\n",
    "\n",
    "# Create a chart\n",
    "chart = BarChart()\n",
    "chart.title = \"Employee Salaries\"\n",
    "chart.x_axis.title = \"Employee\"\n",
    "chart.y_axis.title = \"Salary\"\n",
    "\n",
    "# Add data to chart\n",
    "data = Reference(ws, min_col=4, min_row=1, max_row=6, max_col=4)\n",
    "categories = Reference(ws, min_col=1, min_row=2, max_row=6)\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "chart.set_categories(categories)\n",
    "\n",
    "# Add chart to worksheet\n",
    "ws.add_chart(chart, \"G2\")\n",
    "\n",
    "# Save workbook\n",
    "wb.save(\"openpyxl_example.xlsx\")\n",
    "'''\n",
    "print(openpyxl_code)\n",
    "\n",
    "# Reading Excel files with specific options\n",
    "print(\"\\nReading Excel files with specific options:\")\n",
    "print(\"Example options for pd.read_excel():\")\n",
    "\n",
    "options = {\n",
    "    \"sheet_name\": \"Specify sheet by name or index (0-based)\",\n",
    "    \"header\": \"Row to use as column names (default 0)\",\n",
    "    \"names\": \"List of column names to use\",\n",
    "    \"usecols\": \"Which columns to read (e.g., 'A:C' or [0, 2])\",\n",
    "    \"skiprows\": \"Skip rows at the beginning (int or list)\",\n",
    "    \"nrows\": \"Number of rows to read\",\n",
    "    \"na_values\": \"Values to recognize as NaN\",\n",
    "    \"parse_dates\": \"List of columns to parse as dates\",\n",
    "    \"dtype\": \"Dict of column data types\"\n",
    "}\n",
    "\n",
    "for option, description in options.items():\n",
    "    print(f\"- {option}: {description}\")\n",
    "\n",
    "# Common Excel tasks in data science\n",
    "print(\"\\nCommon Excel tasks in data science:\")\n",
    "\n",
    "tasks = [\n",
    "    \"1. Data import/export: Reading raw data from Excel and writing processed results\",\n",
    "    \"2. Data cleaning: Filtering out invalid rows, handling missing values\",\n",
    "    \"3. Automated reporting: Generating Excel reports with charts and formatting\",\n",
    "    \"4. Data transformation: Reshaping data from Excel into analysis-ready format\",\n",
    "    \"5. Interactive dashboards: Excel as a frontend for data analysis results\"\n",
    "]\n",
    "\n",
    "for task in tasks:\n",
    "    print(task)\n",
    "\n",
    "# Saving analysis results with charts\n",
    "print(\"\\nSaving analysis results with charts (example):\")\n",
    "\n",
    "# Create some sample data for demonstration\n",
    "x = np.linspace(0, 10, 20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "\n",
    "# Create a figure with matplotlib\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x, y1, 'b-', label='sin(x)')\n",
    "plt.plot(x, y2, 'r--', label='cos(x)')\n",
    "plt.legend()\n",
    "plt.title('Trigonometric Functions')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save plot to an image file\n",
    "plt.savefig('plot.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Plot saved to 'plot.png'. In a real workflow, you could:\")\n",
    "print(\"1. Generate multiple analyses and charts\")\n",
    "print(\"2. Insert charts into Excel worksheets\")\n",
    "print(\"3. Create an executive summary sheet\")\n",
    "print(\"4. Format the data for presentation\")\n",
    "\n",
    "# Best practices\n",
    "print(\"\\nExcel file best practices:\")\n",
    "best_practices = [\n",
    "    \"1. Always specify 'index=False' when writing DataFrames unless you need the index\",\n",
    "    \"2. Use descriptive sheet names\",\n",
    "    \"3. Include metadata and documentation sheets\",\n",
    "    \"4. Apply appropriate formatting for different data types\",\n",
    "    \"5. Set column widths for readability\",\n",
    "    \"6. Add data validation where applicable\",\n",
    "    \"7. Use named ranges for important data sections\",\n",
    "    \"8. Include summary statistics and charts\",\n",
    "    \"9. Test Excel files with actual users before distribution\",\n",
    "    \"10. Consider file size and performance for large datasets\"\n",
    "]\n",
    "\n",
    "for practice in best_practices:\n",
    "    print(practice)\n",
    "\n",
    "# Clean up created files\n",
    "for file in ['example.xlsx', 'company_data.xlsx', 'plot.png']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31b933",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "   name  age\n",
    "0 Alice   30\n",
    "1   Bob   25\n",
    "\n",
    "**Real-life use case:** Automating report generation for business analytics.\n",
    "\n",
    "**Common mistakes:** Not installing required libraries (openpyxl, xlrd).\n",
    "\n",
    "**Best practices:** Always specify index=False unless you want to save the DataFrame index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615a5ab",
   "metadata": {},
   "source": [
    "## 5. Images\n",
    "**Definition:** Use the `PIL` (Pillow) library to work with images.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20979fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance, ImageOps, ExifTags\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Basic image creation and manipulation\n",
    "print(\"1. Basic image creation and manipulation:\")\n",
    "# Create a new image with a solid color\n",
    "img = Image.new('RGB', (200, 100), color='red')\n",
    "img.save('pil_red.png')\n",
    "\n",
    "# Open an existing image\n",
    "img2 = Image.open('pil_red.png')\n",
    "print(f\"Image size: {img2.size}\")\n",
    "print(f\"Image mode: {img2.mode}\")\n",
    "print(f\"Image format: {img2.format}\")\n",
    "\n",
    "# Resizing images\n",
    "img_resized = img2.resize((100, 50))\n",
    "img_resized.save('pil_red_resized.png')\n",
    "print(f\"Resized image size: {img_resized.size}\")\n",
    "\n",
    "# Cropping images\n",
    "# Crop format is (left, upper, right, lower)\n",
    "left = 50\n",
    "upper = 25\n",
    "right = 150\n",
    "lower = 75\n",
    "img_cropped = img2.crop((left, upper, right, lower))\n",
    "img_cropped.save('pil_red_cropped.png')\n",
    "print(f\"Cropped image size: {img_cropped.size}\")\n",
    "\n",
    "# 2. Drawing on images\n",
    "print(\"\\n2. Drawing on images:\")\n",
    "# Create a blank canvas\n",
    "canvas = Image.new('RGB', (400, 200), color='white')\n",
    "draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "# Draw shapes\n",
    "draw.rectangle([(50, 50), (150, 100)], fill='blue', outline='black')\n",
    "draw.ellipse([(200, 50), (300, 150)], fill='green', outline='red', width=2)\n",
    "draw.line([(0, 0), (400, 200)], fill='red', width=3)\n",
    "draw.polygon([(350, 50), (350, 150), (250, 100)], fill='yellow', outline='purple')\n",
    "\n",
    "# Add text\n",
    "# Note: In a notebook environment, you might need to adjust the font path or use default font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "except IOError:\n",
    "    # Use default font if arial.ttf is not available\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "draw.text((150, 150), \"Hello, Pillow!\", fill='black', font=font)\n",
    "\n",
    "# Save the drawing\n",
    "canvas.save('pil_drawing.png')\n",
    "print(\"Drawing saved to 'pil_drawing.png'\")\n",
    "\n",
    "# 3. Image transformations\n",
    "print(\"\\n3. Image transformations:\")\n",
    "\n",
    "# Rotate image\n",
    "img_rotated = img2.rotate(45, expand=True)  # expand=True prevents cropping\n",
    "img_rotated.save('pil_red_rotated.png')\n",
    "print(\"Rotated image saved\")\n",
    "\n",
    "# Flip image\n",
    "img_flipped_h = ImageOps.mirror(img2)  # horizontal flip\n",
    "img_flipped_v = ImageOps.flip(img2)    # vertical flip\n",
    "img_flipped_h.save('pil_red_flipped_h.png')\n",
    "img_flipped_v.save('pil_red_flipped_v.png')\n",
    "print(\"Flipped images saved\")\n",
    "\n",
    "# 4. Image enhancement and filtering\n",
    "print(\"\\n4. Image enhancement and filtering:\")\n",
    "\n",
    "# Create a test image with a gradient\n",
    "grad_img = Image.new('RGB', (256, 100), color='black')\n",
    "draw = ImageDraw.Draw(grad_img)\n",
    "for x in range(256):\n",
    "    draw.line([(x, 0), (x, 100)], fill=(x, x, 255-x))\n",
    "grad_img.save('gradient.png')\n",
    "print(\"Created gradient test image\")\n",
    "\n",
    "# Apply filters\n",
    "blur_img = grad_img.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "blur_img.save('gradient_blurred.png')\n",
    "print(\"Applied Gaussian blur filter\")\n",
    "\n",
    "edge_img = grad_img.filter(ImageFilter.FIND_EDGES)\n",
    "edge_img.save('gradient_edges.png')\n",
    "print(\"Applied edge detection filter\")\n",
    "\n",
    "# Enhance images\n",
    "enhancer = ImageEnhance.Contrast(grad_img)\n",
    "enhanced_img = enhancer.enhance(2.0)  # Increase contrast by factor of 2\n",
    "enhanced_img.save('gradient_enhanced.png')\n",
    "print(\"Enhanced image contrast\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = ImageOps.grayscale(grad_img)\n",
    "gray_img.save('gradient_gray.png')\n",
    "print(\"Converted to grayscale\")\n",
    "\n",
    "# 5. Working with image data as numpy arrays\n",
    "print(\"\\n5. Working with image data as numpy arrays:\")\n",
    "\n",
    "# Convert image to numpy array\n",
    "img_array = np.array(grad_img)\n",
    "print(f\"Image array shape: {img_array.shape}\")\n",
    "print(f\"Image data type: {img_array.dtype}\")\n",
    "\n",
    "# Manipulate image data directly\n",
    "inverted_array = 255 - img_array  # Invert colors\n",
    "inverted_img = Image.fromarray(inverted_array.astype('uint8'))\n",
    "inverted_img.save('gradient_inverted.png')\n",
    "print(\"Created inverted image using numpy\")\n",
    "\n",
    "# 6. Image metadata\n",
    "print(\"\\n6. Image metadata:\")\n",
    "print(\"EXIF data extraction example (would work on photos with EXIF data):\")\n",
    "\n",
    "exif_code = '''\n",
    "# Get EXIF data from a photo\n",
    "img = Image.open('photo.jpg')\n",
    "exif_data = img._getexif()\n",
    "\n",
    "if exif_data:\n",
    "    for tag_id, value in exif_data.items():\n",
    "        tag_name = ExifTags.TAGS.get(tag_id, tag_id)\n",
    "        print(f\"{tag_name}: {value}\")\n",
    "else:\n",
    "    print(\"No EXIF data found\")\n",
    "'''\n",
    "print(exif_code)\n",
    "\n",
    "# 7. Working with images from the web\n",
    "print(\"\\n7. Working with images from the web:\")\n",
    "print(\"Example code for downloading and processing an image from the web:\")\n",
    "\n",
    "web_image_code = '''\n",
    "# Download an image from a URL\n",
    "response = requests.get('https://example.com/image.jpg')\n",
    "img = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "# Process the image\n",
    "img_resized = img.resize((300, 200))\n",
    "img_resized.save('web_image_resized.jpg')\n",
    "'''\n",
    "print(web_image_code)\n",
    "\n",
    "# 8. Batch processing images\n",
    "print(\"\\n8. Batch processing images:\")\n",
    "print(\"Example code for batch processing all PNG images in a directory:\")\n",
    "\n",
    "batch_code = '''\n",
    "# Process all PNG images in a directory\n",
    "for filename in glob.glob('input_dir/*.png'):\n",
    "    with Image.open(filename) as img:\n",
    "        # Get the base filename without extension\n",
    "        base_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "        \n",
    "        # Process the image (example: resize and convert to grayscale)\n",
    "        img_processed = ImageOps.grayscale(img.resize((100, 100)))\n",
    "        \n",
    "        # Save to output directory with new name\n",
    "        img_processed.save(f'output_dir/{base_name}_processed.png')\n",
    "        print(f\"Processed: {filename}\")\n",
    "'''\n",
    "print(batch_code)\n",
    "\n",
    "# 9. Creating animated GIFs\n",
    "print(\"\\n9. Creating animated GIFs:\")\n",
    "print(\"Example code for creating an animated GIF:\")\n",
    "\n",
    "gif_code = '''\n",
    "# Create frames for animation\n",
    "frames = []\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'blue', 'purple']\n",
    "\n",
    "for color in colors:\n",
    "    # Create a colored frame\n",
    "    frame = Image.new('RGB', (100, 100), color=color)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Save as animated GIF\n",
    "frames[0].save('animation.gif', \n",
    "               save_all=True,\n",
    "               append_images=frames[1:],\n",
    "               optimize=True,\n",
    "               duration=200,  # milliseconds per frame\n",
    "               loop=0)  # 0 means loop forever\n",
    "'''\n",
    "print(gif_code)\n",
    "\n",
    "# 10. Best practices for image processing\n",
    "print(\"\\n10. Best practices for image processing:\")\n",
    "best_practices = [\n",
    "    \"1. Always use context managers (with statement) or close() images to free resources\",\n",
    "    \"2. Process images in batches for efficiency when dealing with multiple files\",\n",
    "    \"3. Use appropriate image formats: JPEG for photos, PNG for graphics with transparency\",\n",
    "    \"4. Consider memory usage when working with large images\",\n",
    "    \"5. Resize large images before applying compute-intensive operations\",\n",
    "    \"6. Use NumPy for complex pixel manipulations for better performance\",\n",
    "    \"7. Create thumbnails to improve web page loading times\",\n",
    "    \"8. Apply progressive JPEG for faster web loading\",\n",
    "    \"9. Use proper error handling when opening files that might not exist\",\n",
    "    \"10. Consider using threading or multiprocessing for batch processing\"\n",
    "]\n",
    "\n",
    "for practice in best_practices:\n",
    "    print(practice)\n",
    "\n",
    "# Clean up created files\n",
    "files_to_clean = [\n",
    "    'pil_red.png', 'pil_red_resized.png', 'pil_red_cropped.png',\n",
    "    'pil_drawing.png', 'pil_red_rotated.png', 'pil_red_flipped_h.png',\n",
    "    'pil_red_flipped_v.png', 'gradient.png', 'gradient_blurred.png',\n",
    "    'gradient_edges.png', 'gradient_enhanced.png', 'gradient_gray.png',\n",
    "    'gradient_inverted.png'\n",
    "]\n",
    "\n",
    "for file in files_to_clean:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "# Expected output:        \n",
    "# 1. Basic image creation and manipulation:\n",
    "# Image size: (200, 100)\n",
    "# Image mode: RGB\n",
    "# Image format: PNG\n",
    "# Resized image size: (100, 50)\n",
    "# Cropped image size: (100, 50)\n",
    "#\n",
    "# 2. Drawing on images:\n",
    "# Drawing saved to 'pil_drawing.png'\n",
    "#\n",
    "# 3. Image transformations:\n",
    "# Rotated image saved\n",
    "# Flipped images saved\n",
    "#\n",
    "# 4. Image enhancement and filtering:\n",
    "# Created gradient test image\n",
    "# Applied Gaussian blur filter\n",
    "# Applied edge detection filter\n",
    "# Enhanced image contrast\n",
    "# Converted to grayscale\n",
    "#\n",
    "# 5. Working with image data as numpy arrays:\n",
    "# Image array shape: (100, 256, 3)\n",
    "# Image data type: uint8\n",
    "# Created inverted image using numpy\n",
    "#\n",
    "# 6. Image metadata:\n",
    "# EXIF data extraction example (would work on photos with EXIF data):\n",
    "# <EXIF code example>\n",
    "#\n",
    "# 7. Working with images from the web:\n",
    "# Example code for downloading and processing an image from the web:\n",
    "# <web image code example>\n",
    "#\n",
    "# 8. Batch processing images:\n",
    "# Example code for batch processing all PNG images in a directory:\n",
    "# <batch processing code example>\n",
    "#\n",
    "# 9. Creating animated GIFs:\n",
    "# Example code for creating an animated GIF:\n",
    "# <GIF creation code example>\n",
    "#\n",
    "# 10. Best practices for image processing:\n",
    "# 1. Always use context managers (with statement) or close() images to free resources\n",
    "# 2. Process images in batches for efficiency when dealing with multiple files\n",
    "# And so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90cb70",
   "metadata": {},
   "source": [
    "## 6. PDFs\n",
    "**Definition:** Use the `PyPDF2` library to read PDF files.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf889ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "with open('example.pdf', 'rb') as f:\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    page = reader.pages[0]\n",
    "    print(page.extract_text())  # Output: Text from the first page of the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31670c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Note: This code requires the following libraries to be installed:\n",
    "# pip install PyPDF2 reportlab pdf2image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <more libraries...># - ReportLab: PDF generation from scratch with precise control# - PyPDF2: General-purpose PDF manipulation, reading, merging, etc.# 7. PDF Libraries Comparison:## <more practices...># 2. Error handling: Use try-except blocks when working with files# 1. Memory management: Close file handlers promptly when done# 6. PDF Best Practices:## <forms code example># Example code for filling and extracting data from PDF forms:# 5. Working with PDF Forms:## <converting code example># Example code for converting between PDF and other formats:# 4. Converting PDF to and from other formats:## <manipulating code example># Example code for merging, splitting, rotating, and adding watermarks to PDFs:# 3. Manipulating PDFs with PyPDF2:## <creating code example># Example code for creating a PDF document:# 2. Creating PDFs with ReportLab:## <reading code example># Example code for reading a PDF file:# 1. Basic PDF Reading with PyPDF2:## Install with: pip install PyPDF2 reportlab pdf2image# Note: This code requires PyPDF2, reportlab, and pdf2image libraries.# Expected output:print(\"Some examples wouldn't run directly in this notebook without the proper environment setup.\")print(\"\\nNote: The example codes provided require various PDF libraries to be installed.\")    print(f\"- {lib}: {desc}\")for lib, desc in libraries.items():}    \"PDFMiner\": \"Advanced PDF parsing and text extraction\"    \"pdfplumber\": \"More precise PDF text extraction with layout awareness\",    \"pdf2image\": \"Convert PDFs to images\",    \"pdfrw\": \"Low-level PDF manipulation library\",    \"WeasyPrint\": \"HTML/CSS to PDF conversion\",    \"ReportLab\": \"PDF generation from scratch with precise control\",    \"PyPDF2\": \"General-purpose PDF manipulation, reading, merging, etc.\",libraries = {print(\"\\n7. PDF Libraries Comparison:\")# 7. PDF Libraries Comparison    print(practice)for practice in best_practices:]    \"10. Alternatives: Consider HTML/CSS for web-based reports instead of PDFs\"    \"9. Dependencies: Always specify exact library versions in requirements.txt\",    \"8. Testing: Verify PDFs across different readers (Adobe, Chrome, etc.)\",    \"7. PDF creation: Use higher-level libraries (like ReportLab) for complex documents\",    \"6. Text extraction: Be aware that complex layouts may not extract perfectly\",    \"5. Accessibility: Create PDFs with proper tagging and metadata for screen readers\",    \"4. Security: Be cautious when opening PDFs from unknown sources\",    \"3. Performance: Process large PDFs page-by-page rather than loading the entire document\",    \"2. Error handling: Use try-except blocks when working with files\",    \"1. Memory management: Close file handlers promptly when done\",best_practices = [print(\"\\n6. PDF Best Practices:\")# 6. PDF Best Practicesprint(forms_code)'''    os.remove(\"sample_form.pdf\")if os.path.exists(\"sample_form.pdf\"):# Clean up filesfill_pdf_form_example()    print(code)    \"\"\"        writer.write(output_file)    with open(\"filled_form.pdf\", \"wb\") as output_file:    # Write the output        )        }            \"date_field\": \"2023-05-01\"            \"email_field\": \"john@example.com\",            \"name_field\": \"John Doe\",        {        writer.pages[0],     writer.update_page_form_field_values(    # Update form fields        writer.add_page(page)    page = reader.pages[0]    # Get the first page with the form        writer = PdfWriter()    reader = PdfReader(\"form.pdf\")    # Open the form PDF        from PyPDF2 import PdfReader, PdfWriter    code = \"\"\"    print(\"Example code to fill a PDF form:\")    \"\"\"This is a demonstration - for actual use you need a proper PDF form\"\"\"def fill_pdf_form_example():import PyPDF2print(\"\\nFilling a PDF form with PyPDF2:\")# Creating interactive forms requires libraries like pdfrw or PyPDF2print(\"Created a sample form: sample_form.pdf\")create_form_pdf(\"sample_form.pdf\")# Create a simple form    c.save()        c.line(150, height - 200, 500, height - 200)    c.line(150, height - 150, 500, height - 150)    c.line(150, height - 100, 500, height - 100)    # Draw lines for form fields        c.drawString(100, height - 200, \"Date:\")    c.drawString(100, height - 150, \"Email:\")    c.drawString(100, height - 100, \"Name:\")    c.setFont(\"Helvetica\", 12)    # Draw form fields (note: these are just visual, not interactive fields)        c.drawString(100, height - 50, \"Sample PDF Form\")    c.setFont(\"Helvetica-Bold\", 16)    # Add title        width, height = letter    c = canvas.Canvas(filename, pagesize=letter)def create_form_pdf(filename):from reportlab.lib.pagesizes import letterfrom reportlab.pdfgen import canvas# Create a PDF form (simple example with reportlab)forms_code = '''print(\"Example code for filling and extracting data from PDF forms:\")print(\"\\n5. Working with PDF Forms:\")# 5. PDF Formsprint(converting_code)'''print(\"\\nConverted PDF to text: pdf_to_text.txt\")        text_file.write(text)    with open(\"pdf_to_text.txt\", \"w\") as text_file:            text += page.extract_text()    for page in reader.pages:    text = \"\"    reader = PyPDF2.PdfReader(f)with open(\"example.pdf\", \"rb\") as f:import PyPDF2# Convert PDF to text (simple text extraction)print(\"\\nConverted HTML to PDF: html_to_pdf.pdf\")HTML(\"sample.html\").write_pdf(\"html_to_pdf.pdf\")# Convert HTML to PDF    f.write(html_content)with open(\"sample.html\", \"w\") as f:# Create HTML file\"\"\"</html></body>    </table>        </tr>            <td>San Francisco</td>            <td>25</td>            <td>Bob</td>        <tr>        </tr>            <td>New York</td>            <td>30</td>            <td>Alice</td>        <tr>        </tr>            <th>City</th>            <th>Age</th>            <th>Name</th>        <tr>    <table>    <h2>Sample Table</h2>        <p>This HTML will be converted to a PDF document.</p>    <h1>Sample HTML Document</h1><body></head>    </style>        th { background-color: #f2f2f2; }        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }        table { border-collapse: collapse; width: 100%; }        h1 { color: navy; }        body { font-family: Arial, sans-serif; margin: 20px; }    <style>    <title>Sample HTML Document</title><head><html><!DOCTYPE html>html_content = \"\"\"from weasyprint import HTML# Converting HTML to PDF using weasyprint        print(f\"Saved {image_path}\")        image.save(image_path, \"PNG\")        image_path = f\"page_{i+1}.png\"    for i, image in enumerate(images):    # Save images        print(f\"Converted PDF to {len(images)} images\")        images = convert_from_path('example.pdf', output_folder=path)with tempfile.TemporaryDirectory() as path:# Convert PDF to images (this requires poppler to be installed on your system)import tempfilefrom pdf2image import convert_from_path# Converting PDF to imagesconverting_code = '''print(\"Example code for converting between PDF and other formats:\")print(\"\\n4. Converting PDF to and from other formats:\")# 4. Converting PDF to and from other formatsprint(manipulating_code)'''        os.remove(file)    if os.path.exists(file):            \"encrypted_document.pdf\"]:            \"rotated_document.pdf\", \"watermarked_document.pdf\",            \"merged_document.pdf\", \"extracted_page.pdf\", for file in [\"document1.pdf\", \"document2.pdf\", \"watermark.pdf\", # Clean up filesprint(\"Owner password: 'ownerpassword'\")print(\"User password: 'userpassword'\")print(\"Created encrypted_document.pdf with passwords:\")        writer.write(output_file)    with open(\"encrypted_document.pdf\", \"wb\") as output_file:        writer.encrypt(\"userpassword\", \"ownerpassword\")    # Encrypt the PDF            writer.add_page(page)    for page in reader.pages:    # Add all pages        writer = PyPDF2.PdfWriter()    reader = PyPDF2.PdfReader(file)with open(\"document2.pdf\", \"rb\") as file:print(\"\\nEncrypting a PDF:\")# 5. Encrypting a PDFprint(\"Created watermarked_document.pdf\")            writer.write(output_file)        with open(\"watermarked_document.pdf\", \"wb\") as output_file:                    writer.add_page(page)            page.merge_page(watermark_page)        for page in doc_reader.pages:        # Apply watermark to each page                writer = PyPDF2.PdfWriter()                watermark_page = watermark_reader.pages[0]        watermark_reader = PyPDF2.PdfReader(watermark_file)    with open(\"watermark.pdf\", \"rb\") as watermark_file:        doc_reader = PyPDF2.PdfReader(doc_file)with open(\"document1.pdf\", \"rb\") as doc_file:# Apply the watermark to a documentcreate_watermark(\"watermark.pdf\", \"CONFIDENTIAL\")# Create the watermark    c.save()        c.restoreState()    c.drawCentredString(0, 0, text)    c.rotate(45)    c.translate(width/2, height/2)    c.saveState()    # Rotate and draw the watermark text        c.setFont(\"Helvetica\", 60)    c.setFillColorRGB(0.5, 0.5, 0.5, 0.3)  # Gray color with 30% opacity    # Set transparency        width, height = letter    c = canvas.Canvas(filename, pagesize=letter)def create_watermark(filename, text):# Create a watermark PDFprint(\"\\nAdding a watermark:\")# 4. Adding a watermarkprint(\"Created rotated_document.pdf\")        writer.write(output_file)    with open(\"rotated_document.pdf\", \"wb\") as output_file:            writer.add_page(reader.pages[i])    for i in range(1, len(reader.pages)):    # Add any other pages as is        writer.add_page(page)    page.rotate(90)    page = reader.pages[0]    # Get the first page and rotate it 90 degrees clockwise        writer = PyPDF2.PdfWriter()    reader = PyPDF2.PdfReader(file)with open(\"document2.pdf\", \"rb\") as file:print(\"\\nRotating pages:\")# 3. Rotating pagesprint(\"Created extracted_page.pdf with the first page of document1.pdf\")                writer.write(output_file)    with open(\"extracted_page.pdf\", \"wb\") as output_file:        writer.add_page(reader.pages[0])    # Extract the first page        writer = PyPDF2.PdfWriter()    reader = PyPDF2.PdfReader(file)with open(\"document1.pdf\", \"rb\") as file:print(\"\\nExtracting pages:\")# 2. Extracting pages from a PDFprint(\"Created merged_document.pdf\")merger.close()merger.write(\"merged_document.pdf\")    merger.append(file)for file in files_to_merge:files_to_merge = [\"document1.pdf\", \"document2.pdf\"]merger = PyPDF2.PdfMerger()print(\"Merging PDFs:\")# 1. Merging PDFscreate_text_pdf(\"document2.pdf\", \"Document 2\", 2)create_text_pdf(\"document1.pdf\", \"Document 1\", 3)# Create sample files    c.save()                c.showPage()        if i < num_pages - 1:        c.drawString(100, height - 120, f\"This is sample content for demonstration.\")        c.drawString(100, height - 100, f\"{text} - Page {i+1} of {num_pages}\")    for i in range(num_pages):        width, height = letter    c = canvas.Canvas(filename, pagesize=letter)        from reportlab.lib.pagesizes import letter    from reportlab.pdfgen import canvasdef create_text_pdf(filename, text, num_pages=1):# Create sample PDF files for demonstrationimport osimport PyPDF2manipulating_code = '''print(\"Example code for merging, splitting, rotating, and adding watermarks to PDFs:\")print(\"\\n3. Manipulating PDFs with PyPDF2:\")# 3. Manipulating PDFs with PyPDF2print(creating_code)'''create_sample_pdf(\"sample_report.pdf\")# Create a sample PDF    print(f\"PDF created: {filename}\")    doc.build(elements)    # Build the PDF        elements.append(table)    table.setStyle(table_style)        ])        ('GRID', (0, 0), (-1, -1), 1, colors.black)        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),        ('FONTSIZE', (0, 0), (-1, 0), 14),        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),    table_style = TableStyle([    # Add table style        table = Table(data)        ]        ['Diana', '28', 'Boston', 'UX Designer']        ['Charlie', '35', 'Chicago', 'Marketing Analyst'],        ['Bob', '25', 'San Francisco', 'Software Engineer'],        ['Alice', '30', 'New York', 'Data Scientist'],        ['Name', 'Age', 'City', 'Occupation'],    data = [    # Add a table        elements.append(Spacer(1, 12))    elements.append(heading)    heading = Paragraph(\"Sample Data Table\", styles['Heading2'])    # Add a heading        elements.append(Spacer(1, 12))    elements.append(paragraph)    paragraph = Paragraph(paragraph_text, styles['Normal'])    )        \"It allows for complex layouts, tables, charts, and more.\"        \"ReportLab is a powerful library for creating PDF documents in Python. \"        \"This is a paragraph in a sample PDF document created using ReportLab. \"    paragraph_text = (    # Add a paragraph        elements.append(Spacer(1, 12))    elements.append(title)    title = Paragraph(\"Sample PDF Report\", styles['Title'])    # Add a title        styles = getSampleStyleSheet()    # Get sample styles        elements = []    # Container for elements to build the PDF        doc = SimpleDocTemplate(filename, pagesize=letter)    # Create a PDF document with letter size pagesdef create_sample_pdf(filename):from reportlab.lib.styles import getSampleStyleSheetfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStylefrom reportlab.lib import colorsfrom reportlab.lib.pagesizes import lettercreating_code = '''print(\"Example code for creating a PDF document:\")print(\"\\n2. Creating PDFs with ReportLab:\")# 2. Creating PDFs with ReportLabprint(reading_code)'''    print(f\"\\nTotal characters extracted: {len(all_text)}\")                print(f\"Page {i+1}: Extracted {len(page.extract_text())} characters\")        all_text += page.extract_text()    for i, page in enumerate(reader.pages):    all_text = \"\"    print(\"\\nExtracting text from all pages...\")    # Iterate through all pages        print(text[:100] + \"...\" if len(text) > 100 else text)    print(\"\\nText from first page:\")    text = page.extract_text()    page = reader.pages[0]    # Extract text from the first page            print(f\"Creator: {metadata.creator}\")        print(f\"Subject: {metadata.subject}\")        print(f\"Author: {metadata.author}\")        print(f\"Title: {metadata.title}\")    if metadata:    metadata = reader.metadata    # Extract metadata        print(f\"Number of pages: {len(reader.pages)}\")    # Get basic information        reader = PyPDF2.PdfReader(file)    # Create a PDF reader objectwith open('example.pdf', 'rb') as file:# Open the PDF file in binary read modeimport PyPDF2reading_code = '''print(\"Example code for reading a PDF file:\")print(\"\\n1. Basic PDF Reading with PyPDF2:\")# 1. Basic PDF Reading with PyPDF2print(\"Install with: pip install PyPDF2 reportlab pdf2image\")print(\"Note: This code requires PyPDF2, reportlab, and pdf2image libraries.\")\n",
    "**Output:**\n",
    "```\n",
    "Number of pages: 5\n",
    "Title: Sample Document\n",
    "Author: John Doe\n",
    "Text from first page: This is the beginning of the sample document...\n",
    "```\n",
    "\n",
    "**Real-life use cases:**\n",
    "- Automated report generation in business intelligence applications\n",
    "- Extracting data from PDF forms and invoices\n",
    "- Creating digital contracts with encryption and security features\n",
    "- Combining multiple reports into a single document\n",
    "- Adding watermarks or stamps to official documents\n",
    "- Converting data visualizations and analysis results to shareable PDFs\n",
    "- PDF form creation and automated filling for paperwork automation\n",
    "- Batch processing of PDFs for data extraction and archiving\n",
    "\n",
    "**Common mistakes:**\n",
    "- Not properly closing file handles when working with many PDFs\n",
    "- Ignoring PDF structure complexity when extracting text\n",
    "- Using string parsing instead of proper PDF libraries\n",
    "- Not handling encryption or password protection properly\n",
    "- Inefficient handling of large PDF files (loading entire files into memory)\n",
    "- Not considering PDF reader compatibility when creating PDFs\n",
    "\n",
    "**Best practices:**\n",
    "- Always use binary mode ('rb', 'wb') when working with PDF files\n",
    "- Close file handlers promptly using context managers (with statement)\n",
    "- Process large PDFs page-by-page rather than loading the entire document\n",
    "- Use specialized libraries for specific tasks (PyPDF2 for manipulation, ReportLab for creation)\n",
    "- Add proper metadata and structure for accessibility\n",
    "- Test PDFs with different PDF readers to ensure compatibility\n",
    "- Consider security implications when processing PDFs from unknown sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cba83f",
   "metadata": {},
   "source": [
    "## 7. JSON: Human-Readable Data Serialization\n",
    "JSON (JavaScript Object Notation) is a widely used, human-readable format for data exchange between languages and systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Serialize a Python object to JSON and save to file\n",
    "person = {'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
    "with open('person.json', 'w') as f:\n",
    "    json.dump(person, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0612c5",
   "metadata": {},
   "source": [
    "### Load data from a JSON file\n",
    "This cell shows how to read and parse JSON data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'r') as f:\n",
    "    loaded_person = json.load(f)\n",
    "print(loaded_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e32ec",
   "metadata": {},
   "source": [
    "**Use case:** Web APIs, config files, and cross-language data exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9e7ae",
   "metadata": {},
   "source": [
    "## 8. Plain Text Files: Reading and Writing\n",
    "Plain text files are the simplest way to store and share data, logs, or notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa780fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a text file\n",
    "with open('notes.txt', 'w') as f:\n",
    "    f.write('This is a line of text.\\nAnother line.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2bfd44",
   "metadata": {},
   "source": [
    "### Read from a text file\n",
    "This cell demonstrates how to read all lines from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('notes.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc6a60",
   "metadata": {},
   "source": [
    "**Use case:** Logging, configuration, and simple data storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d25c1b",
   "metadata": {},
   "source": [
    "## 9. ZIP Files: Compressing and Extracting Data\n",
    "ZIP files are used to compress and bundle multiple files for storage or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# Create a ZIP file and add files to it\n",
    "with zipfile.ZipFile('archive.zip', 'w') as zipf:\n",
    "    zipf.write('notes.txt')\n",
    "    zipf.write('person.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3db43",
   "metadata": {},
   "source": [
    "### Extract files from a ZIP archive\n",
    "This cell shows how to extract all files from a ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('archive.zip', 'r') as zipf:\n",
    "    zipf.extractall('extracted_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde93024",
   "metadata": {},
   "source": [
    "**Use case:** Data backup, sharing datasets, and packaging projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. YAML: Human-Friendly Data Serialization\n",
    "YAML (YAML Ain't Markup Language) is a readable format for configuration and data exchange, popular in DevOps and data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires: pip install pyyaml\n",
    "import yaml\n",
    "# Serialize Python object to YAML\n",
    "config = {'version': 1, 'settings': {'theme': 'dark', 'autosave': True}}\n",
    "with open('config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa92adb",
   "metadata": {},
   "source": [
    "### Load data from a YAML file\n",
    "This cell shows how to read YAML data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as f:\n",
    "    loaded_config = yaml.safe_load(f)\n",
    "print(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3a367",
   "metadata": {},
   "source": [
    "**Use case:** Application configuration, cloud infrastructure, and data pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
