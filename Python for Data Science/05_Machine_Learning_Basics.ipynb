{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b9b06e",
   "metadata": {},
   "source": [
    "# Machine Learning Basics in Python\n",
    "\n",
    "This notebook introduces the foundational concepts of machine learning (ML) using Python. You'll learn about supervised and unsupervised learning, model training, evaluation, and practical applications using scikit-learn.\n",
    "\n",
    "## Topics Covered:\n",
    "1. What is Machine Learning?\n",
    "2. Types of Machine Learning\n",
    "3. The Machine Learning Workflow\n",
    "4. Data Preparation\n",
    "5. Supervised Learning: Classification\n",
    "6. Supervised Learning: Regression\n",
    "7. Unsupervised Learning: Clustering\n",
    "8. Model Evaluation and Metrics\n",
    "9. Real-Life Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8749815",
   "metadata": {},
   "source": [
    "## 1. What is Machine Learning?\n",
    "\n",
    "Machine learning is a field of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed for each task.\n",
    "\n",
    "**Real-life use case:** Email spam filters use machine learning to classify emails as spam or not spam based on patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282487c",
   "metadata": {},
   "source": [
    "## 2. Types of Machine Learning\n",
    "\n",
    "- **Supervised Learning:** The model learns from labeled data (e.g., classification, regression).\n",
    "- **Unsupervised Learning:** The model finds patterns in unlabeled data (e.g., clustering, dimensionality reduction).\n",
    "- **Reinforcement Learning:** The model learns by interacting with an environment and receiving feedback (rewards or penalties).\n",
    "\n",
    "**Real-life use case:** Customer segmentation (unsupervised) and credit scoring (supervised)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399a430",
   "metadata": {},
   "source": [
    "## 3. The Machine Learning Workflow\n",
    "\n",
    "1. Define the problem\n",
    "2. Collect and prepare data\n",
    "3. Choose a model\n",
    "4. Train the model\n",
    "5. Evaluate the model\n",
    "6. Tune and improve\n",
    "7. Deploy and monitor\n",
    "\n",
    "**Real-life use case:** Predicting house prices using historical sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9334ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, load_boston, make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec6db3",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "Data cleaning and preprocessing are crucial for building effective ML models. This includes handling missing values, encoding categorical variables, and feature scaling.\n",
    "\n",
    "**Real-life use case:** Preparing customer data for churn prediction by filling missing values and normalizing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and prepare the Iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print('Missing values:', df.isnull().sum().sum())\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[iris.feature_names])\n",
    "print('Scaled features shape:', X_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b04e5",
   "metadata": {},
   "source": [
    "## 5. Supervised Learning: Classification\n",
    "\n",
    "Classification is about predicting a categorical label. Example: Predicting if an email is spam or not.\n",
    "\n",
    "**Real-life use case:** Diagnosing diseases (e.g., predicting if a tumor is malignant or benign)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X = X_scaled\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\n",
    "', classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3deacf",
   "metadata": {},
   "source": [
    "## 6. Supervised Learning: Regression\n",
    "\n",
    "Regression predicts a continuous value. Example: Predicting house prices.\n",
    "\n",
    "**Real-life use case:** Forecasting sales revenue for the next quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb295d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Linear regression on Boston housing data (deprecated, so we simulate data)\n",
    "from sklearn.datasets import make_regression\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=3, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Evaluate regression\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Regression: Actual vs Predicted')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75175697",
   "metadata": {},
   "source": [
    "## 7. Unsupervised Learning: Clustering\n",
    "\n",
    "Clustering groups similar data points together without labels. Example: Customer segmentation.\n",
    "\n",
    "**Real-life use case:** Grouping customers by purchasing behavior for targeted marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f23f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: KMeans clustering\n",
    "X_blobs, y_blobs = make_blobs(n_samples=200, centers=3, n_features=2, random_state=42)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_blobs)\n",
    "\n",
    "plt.scatter(X_blobs[:, 0], X_blobs[:, 1], c=clusters, cmap='viridis', alpha=0.7)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', s=100)\n",
    "plt.title('KMeans Clustering Example')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62861389",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Metrics\n",
    "\n",
    "Evaluating model performance is crucial. Common metrics include accuracy, precision, recall, F1-score (for classification), and mean squared error (for regression).\n",
    "\n",
    "**Real-life use case:** Comparing different models to select the best one for predicting loan defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare Decision Tree and Logistic Regression on Iris\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print('Decision Tree Accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "print('Logistic Regression Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce1001",
   "metadata": {},
   "source": [
    "## 9. Real-Life Use Cases\n",
    "\n",
    "- **Healthcare:** Predicting disease risk from patient data\n",
    "- **Finance:** Detecting fraudulent transactions\n",
    "- **Retail:** Recommending products to customers\n",
    "- **Transportation:** Predicting traffic congestion\n",
    "- **Agriculture:** Forecasting crop yields using weather and soil data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175aadc",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "1. Try a different classifier (e.g., DecisionTree, SVC) on the Iris dataset and compare results.\n",
    "2. Use a real dataset (e.g., from UCI or Kaggle) and build a regression model.\n",
    "3. Perform clustering on a dataset of your choice and visualize the clusters.\n",
    "4. Experiment with feature scaling and observe its effect on model performance.\n",
    "5. Explore model evaluation metrics beyond accuracy (e.g., ROC-AUC, confusion matrix)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
