{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ddfccb",
   "metadata": {},
   "source": [
    "# Data Manipulation with Pandas\n",
    "\n",
    "This notebook covers essential data manipulation techniques using the pandas library in Python. Pandas is one of the most powerful and flexible tools for data analysis and manipulation in Python.\n",
    "\n",
    "## Topics Covered:\n",
    "1. Introduction to pandas and basic data structures\n",
    "2. Reading and writing data\n",
    "3. Data inspection and cleaning\n",
    "4. Filtering, selecting, and indexing data\n",
    "5. Data transformation and aggregation\n",
    "6. Handling missing data\n",
    "7. Merging, joining, and concatenating dataframes\n",
    "8. Working with time series data\n",
    "9. Practical exercises\n",
    "\n",
    "Each section includes real-life use cases to demonstrate practical applications of these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88147f",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pandas and Basic Data Structures\n",
    "\n",
    "Pandas provides two primary data structures:\n",
    "- **Series**: One-dimensional array-like object containing a sequence of values with associated labels (index)\n",
    "- **DataFrame**: Two-dimensional tabular data structure with labeled axes (rows and columns)\n",
    "\n",
    "### Real-Life Use Case: Customer Analytics\n",
    "\n",
    "Imagine you work for an e-commerce company and need to analyze customer data. You'd use a DataFrame to store information about each customer (rows) with various attributes like purchase history, demographics, and engagement metrics (columns). Series objects might represent individual metrics like customer lifetime value or days since last purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29e790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display settings for better readability\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56b0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series:\n",
      "a    10\n",
      "b    20\n",
      "c    30\n",
      "d    40\n",
      "dtype: int64\n",
      "\n",
      "Index: Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "Values: [10 20 30 40]\n"
     ]
    }
   ],
   "source": [
    "# Creating a Series\n",
    "s = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "print(\"Pandas Series:\")\n",
    "print(s)\n",
    "print(\"\\nIndex:\", s.index)\n",
    "print(\"Values:\", s.values)\n",
    "\n",
    "# Output:\n",
    "# Pandas Series:\n",
    "# a    10\n",
    "# b    20\n",
    "# c    30\n",
    "# d    40\n",
    "# dtype: int64\n",
    "#\n",
    "# Index: Index(['a', 'b', 'c', 'd'], dtype='object')\n",
    "# Values: [10 20 30 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2adc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28</td>\n",
       "      <td>New York</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna</td>\n",
       "      <td>34</td>\n",
       "      <td>Paris</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter</td>\n",
       "      <td>29</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linda</td>\n",
       "      <td>42</td>\n",
       "      <td>London</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age      City  Salary\n",
       "0   John   28  New York   65000\n",
       "1   Anna   34     Paris   70000\n",
       "2  Peter   29    Berlin   62000\n",
       "3  Linda   42    London   85000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Age': [28, 34, 29, 42],\n",
    "    'City': ['New York', 'Paris', 'Berlin', 'London'],\n",
    "    'Salary': [65000, 70000, 62000, 85000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\")\n",
    "df\n",
    "\n",
    "# Output:\n",
    "#    Name  Age      City  Salary\n",
    "# 0  John   28  New York   65000\n",
    "# 1  Anna   34     Paris   70000\n",
    "# 2 Peter   29    Berlin   62000\n",
    "# 3 Linda   42    London   85000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f748d",
   "metadata": {},
   "source": [
    "## 2. Reading and Writing Data\n",
    "\n",
    "Pandas can read data from various file formats including CSV, Excel, SQL databases, JSON, and more.\n",
    "\n",
    "### Real-Life Use Case: Financial Data Analysis\n",
    "\n",
    "In financial analysis, you often need to import data from multiple sources. For example, you might download historical stock price CSVs from Yahoo Finance, import transaction records from Excel spreadsheets, and pull economic indicators from an API in JSON format. Pandas provides a consistent interface for importing and exporting all these formats, allowing you to focus on the analysis rather than dealing with the complexities of different file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ab7b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to CSV file\n"
     ]
    }
   ],
   "source": [
    "# Creating a sample DataFrame to save\n",
    "sample_df = pd.DataFrame({\n",
    "    'A': np.random.rand(5),          # Random float values\n",
    "    'B': np.random.randint(0, 10, 5), # Random integers between 0-9\n",
    "    'C': ['foo', 'bar', 'baz', 'qux', 'quux'],  # Text values\n",
    "    'D': pd.date_range('2023-01-01', periods=5)  # Date range\n",
    "})\n",
    "\n",
    "# Saving to CSV\n",
    "sample_df.to_csv('sample_data.csv', index=False)\n",
    "print(\"Data saved to CSV file\")  # Output: Data saved to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ea6a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from CSV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554919</td>\n",
       "      <td>1</td>\n",
       "      <td>foo</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798723</td>\n",
       "      <td>3</td>\n",
       "      <td>bar</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.387432</td>\n",
       "      <td>9</td>\n",
       "      <td>baz</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043309</td>\n",
       "      <td>0</td>\n",
       "      <td>qux</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120993</td>\n",
       "      <td>7</td>\n",
       "      <td>quux</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A  B     C           D\n",
       "0  0.554919  1   foo  2023-01-01\n",
       "1  0.798723  3   bar  2023-01-02\n",
       "2  0.387432  9   baz  2023-01-03\n",
       "3  0.043309  0   qux  2023-01-04\n",
       "4  0.120993  7  quux  2023-01-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading from CSV\n",
    "df_from_csv = pd.read_csv('sample_data.csv')\n",
    "print(\"Data loaded from CSV:\")\n",
    "df_from_csv\n",
    "\n",
    "# Output: (exact values will vary due to random generation)\n",
    "#           A  B     C           D\n",
    "# 0  0.374540  9   foo  2023-01-01\n",
    "# 1  0.950714  3   bar  2023-01-02\n",
    "# 2  0.731994  5   baz  2023-01-03\n",
    "# 3  0.598658  3   qux  2023-01-04\n",
    "# 4  0.156019  4  quux  2023-01-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5988469d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>C</td>\n",
       "      <td>Tool</td>\n",
       "      <td>32</td>\n",
       "      <td>1469</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>D</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>39</td>\n",
       "      <td>2086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>49</td>\n",
       "      <td>246</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>Device</td>\n",
       "      <td>32</td>\n",
       "      <td>3319</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>4</td>\n",
       "      <td>3011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Store Product  Units_Sold  Revenue  Customer_Satisfaction\n",
       "0 2023-01-01     C    Tool          32     1469                      5\n",
       "1 2023-01-02     D  Gadget          39     2086                      1\n",
       "2 2023-01-03     A  Gadget          49      246                      3\n",
       "3 2023-01-04     C  Device          32     3319                      2\n",
       "4 2023-01-05     C  Gadget           4     3011                      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a more realistic sample dataset\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=100)\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Store': np.random.choice(['A', 'B', 'C', 'D'], 100),\n",
    "    'Product': np.random.choice(['Widget', 'Gadget', 'Tool', 'Device'], 100),\n",
    "    'Units_Sold': np.random.randint(1, 50, 100),\n",
    "    'Revenue': np.random.randint(100, 5000, 100),\n",
    "    'Customer_Satisfaction': np.random.randint(1, 6, 100)\n",
    "})\n",
    "\n",
    "# Save this dataset for future use\n",
    "sales_data.to_csv('sales_data.csv', index=False)\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385dc8a3",
   "metadata": {},
   "source": [
    "## 3. Data Inspection and Cleaning\n",
    "\n",
    "Before analyzing data, it's important to inspect and clean it by checking its structure, identifying missing values, and handling duplicates.\n",
    "\n",
    "### Real-Life Use Case: Healthcare Data Management\n",
    "\n",
    "In healthcare organizations, patient data is often collected from various departments and systems, leading to inconsistencies, missing values, and duplicates. Clean data is essential for accurate diagnoses, treatment planning, and billing. Data scientists working with electronic health records (EHR) must carefully inspect and clean the data to ensure patient information is accurate and complete before using it for operational analytics or predictive modeling. For example, identifying and addressing missing lab results or duplicate patient records can significantly impact healthcare outcomes and financial reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88dc52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (100, 6)\n",
      "\n",
      "Column names: ['Date', 'Store', 'Product', 'Units_Sold', 'Revenue', 'Customer_Satisfaction']\n",
      "\n",
      "Data types:\n",
      "Date                     object\n",
      "Store                    object\n",
      "Product                  object\n",
      "Units_Sold                int64\n",
      "Revenue                   int64\n",
      "Customer_Satisfaction     int64\n",
      "dtype: object\n",
      "\n",
      "Summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>D</td>\n",
       "      <td>Tool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>2630.850000</td>\n",
       "      <td>2.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.760718</td>\n",
       "      <td>1442.454673</td>\n",
       "      <td>1.456299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>1336.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2661.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3836.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4993.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Store Product  Units_Sold      Revenue  \\\n",
       "count          100   100     100  100.000000   100.000000   \n",
       "unique         100     4       4         NaN          NaN   \n",
       "top     2023-01-01     D    Tool         NaN          NaN   \n",
       "freq             1    30      30         NaN          NaN   \n",
       "mean           NaN   NaN     NaN   25.400000  2630.850000   \n",
       "std            NaN   NaN     NaN   14.760718  1442.454673   \n",
       "min            NaN   NaN     NaN    1.000000   116.000000   \n",
       "25%            NaN   NaN     NaN   11.750000  1336.750000   \n",
       "50%            NaN   NaN     NaN   28.000000  2661.000000   \n",
       "75%            NaN   NaN     NaN   37.000000  3836.500000   \n",
       "max            NaN   NaN     NaN   49.000000  4993.000000   \n",
       "\n",
       "        Customer_Satisfaction  \n",
       "count              100.000000  \n",
       "unique                    NaN  \n",
       "top                       NaN  \n",
       "freq                      NaN  \n",
       "mean                 2.980000  \n",
       "std                  1.456299  \n",
       "min                  1.000000  \n",
       "25%                  2.000000  \n",
       "50%                  3.000000  \n",
       "75%                  4.000000  \n",
       "max                  5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sales data\n",
    "df = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Basic information about the DataFrame\n",
    "print(\"Shape (rows, columns):\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e59c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Date                     0\n",
      "Store                    0\n",
      "Product                  0\n",
      "Units_Sold               0\n",
      "Revenue                  0\n",
      "Customer_Satisfaction    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in the modified dataset:\n",
      "Date                     0\n",
      "Store                    0\n",
      "Product                  0\n",
      "Units_Sold               0\n",
      "Revenue                  9\n",
      "Customer_Satisfaction    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Let's introduce some missing values for demonstration\n",
    "df_with_missing = df.copy()\n",
    "df_with_missing.loc[np.random.choice(df.index, 10), 'Revenue'] = np.nan\n",
    "df_with_missing.loc[np.random.choice(df.index, 5), 'Customer_Satisfaction'] = np.nan\n",
    "\n",
    "print(\"\\nMissing values in the modified dataset:\")\n",
    "print(df_with_missing.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65a0c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (100, 6)\n",
      "After filling: (100, 6)\n",
      "After dropping: (87, 6)\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "# Method 1: Fill missing values with mean/median/mode\n",
    "df_filled = df_with_missing.copy()\n",
    "df_filled['Revenue'] = df_filled['Revenue'].fillna(df_filled['Revenue'].mean())\n",
    "df_filled['Customer_Satisfaction'] = df_filled['Customer_Satisfaction'].fillna(\n",
    "    df_filled['Customer_Satisfaction'].median())\n",
    "\n",
    "# Method 2: Drop rows with missing values\n",
    "df_dropped = df_with_missing.dropna()\n",
    "\n",
    "print(f\"Original shape: {df_with_missing.shape}\")\n",
    "print(f\"After filling: {df_filled.shape}\")\n",
    "print(f\"After dropping: {df_dropped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2b8b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5\n",
      "Shape after removing duplicates: (100, 6)\n"
     ]
    }
   ],
   "source": [
    "# Detecting and handling duplicates\n",
    "# Let's introduce some duplicates\n",
    "df_with_duplicates = pd.concat([df, df.iloc[:5]], ignore_index=True)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_count = df_with_duplicates.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_unique = df_with_duplicates.drop_duplicates()\n",
    "print(f\"Shape after removing duplicates: {df_unique.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce9ff6",
   "metadata": {},
   "source": [
    "## 4. Filtering, Selecting, and Indexing Data\n",
    "\n",
    "Pandas provides powerful ways to select, filter, and access data within DataFrames.\n",
    "\n",
    "### Real-Life Use Case: Marketing Campaign Analysis\n",
    "\n",
    "A marketing team needs to segment customers and target specific campaigns. Using pandas filtering capabilities, they can quickly isolate high-value customers (e.g., `df[df['lifetime_value'] > 10000]`), identify inactive users (e.g., `df[df['days_since_last_purchase'] > 90]`), or target specific demographics (e.g., `df[(df['age'] > 25) & (df['age'] < 40) & (df['location'] == 'New York')]`). These filtered segments form the basis for tailored marketing strategies and personalized communications, significantly improving campaign performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a36ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting a single column as Series:\n",
      "0    1469\n",
      "1    2086\n",
      "2     246\n",
      "3    3319\n",
      "4    3011\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      "Selecting multiple columns as DataFrame:\n",
      "  Store Product  Revenue\n",
      "0     C    Tool     1469\n",
      "1     D  Gadget     2086\n",
      "2     A  Gadget      246\n",
      "3     C  Device     3319\n",
      "4     C  Gadget     3011\n",
      "\n",
      "0    1469\n",
      "1    2086\n",
      "2     246\n",
      "3    3319\n",
      "4    3011\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      "Selecting multiple columns as DataFrame:\n",
      "  Store Product  Revenue\n",
      "0     C    Tool     1469\n",
      "1     D  Gadget     2086\n",
      "2     A  Gadget      246\n",
      "3     C  Device     3319\n",
      "4     C  Gadget     3011\n"
     ]
    }
   ],
   "source": [
    "# Basic column selection\n",
    "print(\"Selecting a single column as Series:\")\n",
    "print(df['Revenue'].head())\n",
    "\n",
    "print(\"\\nSelecting multiple columns as DataFrame:\")\n",
    "print(df[['Store', 'Product', 'Revenue']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb59392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows using iloc:\n",
      "         Date Store Product  Units_Sold  Revenue  Customer_Satisfaction\n",
      "0  2023-01-01     C    Tool          32     1469                      5\n",
      "1  2023-01-02     D  Gadget          39     2086                      1\n",
      "2  2023-01-03     A  Gadget          49      246                      3\n",
      "3  2023-01-04     C  Device          32     3319                      2\n",
      "4  2023-01-05     C  Gadget           4     3011                      1\n",
      "\n",
      "Rows 10-15:\n",
      "          Date Store Product  Units_Sold  Revenue  Customer_Satisfaction\n",
      "10  2023-01-11     C  Device          15     2485                      3\n",
      "11  2023-01-12     C    Tool          43     3019                      2\n",
      "12  2023-01-13     C  Device          29     4836                      2\n",
      "13  2023-01-14     C  Gadget          36     1902                      2\n",
      "14  2023-01-15     D    Tool          13     4161                      1\n",
      "15  2023-01-16     A  Device          32     3469                      1\n",
      "\n",
      "Specific rows and columns using iloc:\n",
      "  Store  Units_Sold  Revenue\n",
      "0     C          32     1469\n",
      "1     D          39     2086\n",
      "2     A          49      246\n"
     ]
    }
   ],
   "source": [
    "# Row selection using iloc (position-based) and loc (label-based)\n",
    "print(\"First 5 rows using iloc:\")\n",
    "print(df.iloc[:5])\n",
    "\n",
    "print(\"\\nRows 10-15:\")\n",
    "print(df.iloc[10:16])\n",
    "\n",
    "print(\"\\nSpecific rows and columns using iloc:\")\n",
    "print(df.iloc[0:3, [1, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bada4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High revenue transactions:\n",
      "          Date Store Product  Units_Sold  Revenue  Customer_Satisfaction\n",
      "12  2023-01-13     C  Device          29     4836                      2\n",
      "14  2023-01-15     D    Tool          13     4161                      1\n",
      "22  2023-01-23     B  Gadget           6     4648                      2\n",
      "24  2023-01-25     D  Widget          28     4190                      5\n",
      "30  2023-01-31     A  Device          28     4599                      4\n",
      "..         ...   ...     ...         ...      ...                    ...\n",
      "74  2023-03-16     A  Device           2     4993                      4\n",
      "76  2023-03-18     D    Tool          26     4648                      1\n",
      "79  2023-03-21     D    Tool          32     4854                      1\n",
      "80  2023-03-22     C  Widget           4     4742                      2\n",
      "93  2023-04-04     B    Tool           9     4376                      1\n",
      "\n",
      "[23 rows x 6 columns]\n",
      "\n",
      "Store A Widget sales:\n",
      "          Date Store Product  Units_Sold  Revenue  Customer_Satisfaction\n",
      "21  2023-01-22     A  Widget          45     3823                      3\n",
      "31  2023-02-01     A  Widget          25     3291                      1\n",
      "35  2023-02-05     A  Widget          27     4782                      2\n",
      "37  2023-02-07     A  Widget          41     1545                      3\n"
     ]
    }
   ],
   "source": [
    "# Filtering data based on conditions\n",
    "# Filter stores with high revenue\n",
    "high_revenue = df[df['Revenue'] > 4000]\n",
    "print(\"High revenue transactions:\")\n",
    "print(high_revenue)\n",
    "\n",
    "# Filter specific store and product combinations\n",
    "store_a_widgets = df[(df['Store'] == 'A') & (df['Product'] == 'Widget')]\n",
    "print(\"\\nStore A Widget sales:\")\n",
    "print(store_a_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8174c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High satisfaction and high volume sales:\n",
      "          Date Store Product  Units_Sold  Revenue  Customer_Satisfaction\n",
      "0   2023-01-01     C    Tool          32     1469                      5\n",
      "25  2023-01-26     B  Device          44     2156                      4\n",
      "32  2023-02-02     D  Widget          39     1796                      4\n",
      "44  2023-02-14     D  Device          37     2300                      4\n",
      "47  2023-02-17     C    Tool          44     3877                      4\n",
      "50  2023-02-20     C    Tool          32     3891                      5\n",
      "51  2023-02-21     B    Tool          32     1056                      4\n",
      "53  2023-02-23     D    Tool          41      260                      4\n",
      "54  2023-02-24     C  Widget          49     4593                      5\n",
      "55  2023-02-25     D  Gadget          49     1400                      4\n",
      "57  2023-02-27     A  Gadget          39     1627                      4\n",
      "60  2023-03-02     C    Tool          49     4835                      5\n",
      "62  2023-03-04     A  Device          49     2835                      4\n",
      "70  2023-03-12     B  Device          32      662                      5\n",
      "75  2023-03-17     B  Gadget          44     1059                      5\n",
      "83  2023-03-25     D    Tool          38     1343                      5\n",
      "86  2023-03-28     B  Gadget          34     1169                      5\n",
      "92  2023-04-03     B  Widget          33      401                      5\n",
      "99  2023-04-10     A    Tool          36     2400                      5\n"
     ]
    }
   ],
   "source": [
    "# Using query method for more readable filtering\n",
    "high_satisfaction = df.query('Customer_Satisfaction >= 4 & Units_Sold > 30')\n",
    "print(\"High satisfaction and high volume sales:\")\n",
    "print(high_satisfaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cad60",
   "metadata": {},
   "source": [
    "## 5. Data Transformation and Aggregation\n",
    "\n",
    "Pandas provides various methods for transforming, grouping, and aggregating data.\n",
    "\n",
    "### Real-Life Use Case: Retail Sales Analysis\n",
    "\n",
    "A national retail chain needs to understand sales performance across different stores, regions, and product categories. Using pandas aggregation functions, analysts can quickly summarize total sales by region (`df.groupby('region')['sales'].sum()`), calculate average daily transactions per store (`df.groupby(['store', 'date'])['transactions'].mean()`), or identify the top-selling products in each category (`df.groupby(['category', 'product'])['units_sold'].sum().groupby(level=0).nlargest(3)`). These insights help management make informed decisions about inventory management, store staffing, and marketing resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8169f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "      <th>Revenue_per_Unit</th>\n",
       "      <th>Is_High_Value</th>\n",
       "      <th>Satisfaction_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>C</td>\n",
       "      <td>Tool</td>\n",
       "      <td>32</td>\n",
       "      <td>1469</td>\n",
       "      <td>5</td>\n",
       "      <td>45.906250</td>\n",
       "      <td>False</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>D</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>39</td>\n",
       "      <td>2086</td>\n",
       "      <td>1</td>\n",
       "      <td>53.487179</td>\n",
       "      <td>False</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>49</td>\n",
       "      <td>246</td>\n",
       "      <td>3</td>\n",
       "      <td>5.020408</td>\n",
       "      <td>False</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>Device</td>\n",
       "      <td>32</td>\n",
       "      <td>3319</td>\n",
       "      <td>2</td>\n",
       "      <td>103.718750</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>4</td>\n",
       "      <td>3011</td>\n",
       "      <td>1</td>\n",
       "      <td>752.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Store Product  Units_Sold  Revenue  Customer_Satisfaction  \\\n",
       "0  2023-01-01     C    Tool          32     1469                      5   \n",
       "1  2023-01-02     D  Gadget          39     2086                      1   \n",
       "2  2023-01-03     A  Gadget          49      246                      3   \n",
       "3  2023-01-04     C  Device          32     3319                      2   \n",
       "4  2023-01-05     C  Gadget           4     3011                      1   \n",
       "\n",
       "   Revenue_per_Unit  Is_High_Value Satisfaction_Category  \n",
       "0         45.906250          False                  High  \n",
       "1         53.487179          False                   Low  \n",
       "2          5.020408          False                Medium  \n",
       "3        103.718750           True                Medium  \n",
       "4        752.750000           True                   Low  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding new columns\n",
    "df['Revenue_per_Unit'] = df['Revenue'] / df['Units_Sold']\n",
    "df['Is_High_Value'] = df['Revenue'] > df['Revenue'].median()\n",
    "\n",
    "# Apply a custom function to a column\n",
    "def categorize_satisfaction(score):\n",
    "    if score >= 4:\n",
    "        return 'High'\n",
    "    elif score >= 2:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "df['Satisfaction_Category'] = df['Customer_Satisfaction'].apply(categorize_satisfaction)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "242bb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Revenue</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>57950</td>\n",
       "      <td>2897.500000</td>\n",
       "      <td>508</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>59997</td>\n",
       "      <td>2307.576923</td>\n",
       "      <td>658</td>\n",
       "      <td>3.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>72044</td>\n",
       "      <td>3001.833333</td>\n",
       "      <td>610</td>\n",
       "      <td>2.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>73094</td>\n",
       "      <td>2436.466667</td>\n",
       "      <td>764</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Revenue              Units_Sold Customer_Satisfaction\n",
       "          sum         mean        sum                  mean\n",
       "Store                                                      \n",
       "A       57950  2897.500000        508              3.250000\n",
       "B       59997  2307.576923        658              3.115385\n",
       "C       72044  3001.833333        610              2.958333\n",
       "D       73094  2436.466667        764              2.700000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by operations\n",
    "store_summary = df.groupby('Store').agg({\n",
    "    'Revenue': ['sum', 'mean'], \n",
    "    'Units_Sold': 'sum',\n",
    "    'Customer_Satisfaction': 'mean'\n",
    "})\n",
    "\n",
    "print(\"Store summary:\")\n",
    "store_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10132612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product and store summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Product</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Device</td>\n",
       "      <td>25735</td>\n",
       "      <td>154</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>3932</td>\n",
       "      <td>142</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Tool</td>\n",
       "      <td>14842</td>\n",
       "      <td>74</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Widget</td>\n",
       "      <td>13441</td>\n",
       "      <td>138</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>Device</td>\n",
       "      <td>11283</td>\n",
       "      <td>179</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>18911</td>\n",
       "      <td>221</td>\n",
       "      <td>3.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>Tool</td>\n",
       "      <td>13020</td>\n",
       "      <td>93</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>Widget</td>\n",
       "      <td>16783</td>\n",
       "      <td>165</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>Device</td>\n",
       "      <td>10993</td>\n",
       "      <td>82</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>9043</td>\n",
       "      <td>128</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C</td>\n",
       "      <td>Tool</td>\n",
       "      <td>17091</td>\n",
       "      <td>200</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C</td>\n",
       "      <td>Widget</td>\n",
       "      <td>34917</td>\n",
       "      <td>200</td>\n",
       "      <td>2.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D</td>\n",
       "      <td>Device</td>\n",
       "      <td>12008</td>\n",
       "      <td>120</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>6043</td>\n",
       "      <td>140</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D</td>\n",
       "      <td>Tool</td>\n",
       "      <td>46947</td>\n",
       "      <td>417</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D</td>\n",
       "      <td>Widget</td>\n",
       "      <td>8096</td>\n",
       "      <td>87</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store Product  Revenue  Units_Sold  Customer_Satisfaction\n",
       "0      A  Device    25735         154               3.142857\n",
       "1      A  Gadget     3932         142               3.500000\n",
       "2      A    Tool    14842          74               4.000000\n",
       "3      A  Widget    13441         138               2.250000\n",
       "4      B  Device    11283         179               2.500000\n",
       "5      B  Gadget    18911         221               3.625000\n",
       "6      B    Tool    13020          93               3.200000\n",
       "7      B  Widget    16783         165               3.000000\n",
       "8      C  Device    10993          82               3.000000\n",
       "9      C  Gadget     9043         128               2.000000\n",
       "10     C    Tool    17091         200               4.200000\n",
       "11     C  Widget    34917         200               2.727273\n",
       "12     D  Device    12008         120               3.285714\n",
       "13     D  Gadget     6043         140               2.500000\n",
       "14     D    Tool    46947         417               2.400000\n",
       "15     D  Widget     8096          87               3.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-level groupby\n",
    "product_store_summary = df.groupby(['Store', 'Product']).agg({\n",
    "    'Revenue': 'sum',\n",
    "    'Units_Sold': 'sum',\n",
    "    'Customer_Satisfaction': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Product and store summary:\")\n",
    "product_store_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24448c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot table of revenue and units sold by store and product:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Revenue</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Units_Sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <th>Device</th>\n",
       "      <th>Gadget</th>\n",
       "      <th>Tool</th>\n",
       "      <th>Widget</th>\n",
       "      <th>Device</th>\n",
       "      <th>Gadget</th>\n",
       "      <th>Tool</th>\n",
       "      <th>Widget</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>25735</td>\n",
       "      <td>3932</td>\n",
       "      <td>14842</td>\n",
       "      <td>13441</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>11283</td>\n",
       "      <td>18911</td>\n",
       "      <td>13020</td>\n",
       "      <td>16783</td>\n",
       "      <td>179</td>\n",
       "      <td>221</td>\n",
       "      <td>93</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>10993</td>\n",
       "      <td>9043</td>\n",
       "      <td>17091</td>\n",
       "      <td>34917</td>\n",
       "      <td>82</td>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>12008</td>\n",
       "      <td>6043</td>\n",
       "      <td>46947</td>\n",
       "      <td>8096</td>\n",
       "      <td>120</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Revenue                      Units_Sold                   \n",
       "Product  Device Gadget   Tool Widget     Device Gadget Tool Widget\n",
       "Store                                                             \n",
       "A         25735   3932  14842  13441        154    142   74    138\n",
       "B         11283  18911  13020  16783        179    221   93    165\n",
       "C         10993   9043  17091  34917         82    128  200    200\n",
       "D         12008   6043  46947   8096        120    140  417     87"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot tables\n",
    "pivot_table = df.pivot_table(\n",
    "    values=['Revenue', 'Units_Sold'],\n",
    "    index='Store',\n",
    "    columns='Product',\n",
    "    aggfunc={'Revenue': 'sum', 'Units_Sold': 'sum'}\n",
    ")\n",
    "\n",
    "print(\"Pivot table of revenue and units sold by store and product:\")\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32b362",
   "metadata": {},
   "source": [
    "## 6. Handling Missing Data\n",
    "\n",
    "Let's explore more advanced techniques for handling missing data.\n",
    "\n",
    "### Real-Life Use Case: Environmental Sensor Data\n",
    "\n",
    "Environmental scientists deploy networks of sensors to monitor air quality, temperature, humidity, and other metrics. These sensors occasionally fail or experience connectivity issues, resulting in gaps in the data. When analyzing trends or building predictive models, these gaps must be addressed. Using pandas, scientists can apply domain-appropriate techniques such as linear interpolation for temperature readings, forward-filling for slowly changing metrics like humidity, or more sophisticated techniques like time-series-based imputation for complex relationships. Proper handling of missing sensor data ensures more accurate environmental modeling and reliable alerting systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb853c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset with missing values:\n",
      "     A    B    C  D\n",
      "0  1.0  NaN  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  NaN  3.0  3.0  3\n",
      "3  4.0  4.0  NaN  4\n",
      "4  5.0  5.0  NaN  5\n",
      "\n",
      "Missing value count by column:\n",
      "A    1\n",
      "B    1\n",
      "C    2\n",
      "D    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset with various missing patterns\n",
    "df_missing = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5],\n",
    "    'C': [1, 2, 3, np.nan, np.nan],\n",
    "    'D': [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "print(\"Original dataset with missing values:\")\n",
    "print(df_missing)\n",
    "print(\"\\nMissing value count by column:\")\n",
    "print(df_missing.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78583442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled with constant value:\n",
      "     A    B    C  D\n",
      "0  1.0  0.0  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  0.0  3.0  3.0  3\n",
      "3  4.0  4.0  0.0  4\n",
      "4  5.0  5.0  0.0  5\n",
      "\n",
      "Filled with different values per column:\n",
      "     A     B    C  D\n",
      "0  1.0  10.0  1.0  1\n",
      "1  2.0   2.0  2.0  2\n",
      "2  0.0   3.0  3.0  3\n",
      "3  4.0   4.0 -1.0  4\n",
      "4  5.0   5.0 -1.0  5\n",
      "\n",
      "Forward fill:\n",
      "     A    B    C  D\n",
      "0  1.0  NaN  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  2.0  3.0  3.0  3\n",
      "3  4.0  4.0  3.0  4\n",
      "4  5.0  5.0  3.0  5\n",
      "\n",
      "Backward fill:\n",
      "     A    B    C  D\n",
      "0  1.0  2.0  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  4.0  3.0  3.0  3\n",
      "3  4.0  4.0  NaN  4\n",
      "4  5.0  5.0  NaN  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mb\\AppData\\Local\\Temp\\ipykernel_4456\\1837009022.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffill = df_missing.fillna(method='ffill')\n",
      "C:\\Users\\mb\\AppData\\Local\\Temp\\ipykernel_4456\\1837009022.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_bfill = df_missing.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# Different imputation strategies\n",
    "\n",
    "# 1. Fill with a constant value\n",
    "df_fill_const = df_missing.fillna(0)\n",
    "print(\"Filled with constant value:\")\n",
    "print(df_fill_const)\n",
    "\n",
    "# 2. Fill with different values for each column\n",
    "df_fill_dict = df_missing.fillna({'A': 0, 'B': 10, 'C': -1})\n",
    "print(\"\\nFilled with different values per column:\")\n",
    "print(df_fill_dict)\n",
    "\n",
    "# 3. Forward fill (propagate last valid observation forward)\n",
    "df_ffill = df_missing.fillna(method='ffill')\n",
    "print(\"\\nForward fill:\")\n",
    "print(df_ffill)\n",
    "\n",
    "# 4. Backward fill (use next valid observation to fill gap)\n",
    "df_bfill = df_missing.fillna(method='bfill')\n",
    "print(\"\\nBackward fill:\")\n",
    "print(df_bfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4888a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear interpolation:\n",
      "     A    B    C  D\n",
      "0  1.0  NaN  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  3.0  3.0  3.0  3\n",
      "3  4.0  4.0  3.0  4\n",
      "4  5.0  5.0  3.0  5\n"
     ]
    }
   ],
   "source": [
    "# Interpolation methods\n",
    "df_interp = df_missing.interpolate(method='linear')\n",
    "print(\"Linear interpolation:\")\n",
    "print(df_interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a533d44",
   "metadata": {},
   "source": [
    "## 7. Merging, Joining, and Concatenating DataFrames\n",
    "\n",
    "Pandas provides various ways to combine multiple DataFrames together.\n",
    "\n",
    "### Real-Life Use Case: Supply Chain Management\n",
    "\n",
    "In supply chain management, data is often siloed across different systems. A manufacturing company might have separate datasets for inventory levels, production schedules, supplier information, transportation logistics, and customer orders. To optimize operations, these datasets need to be combined. Using pandas, analysts can join supplier data with inventory levels, merge production schedules with materials availability, and link shipping data with customer orders. These combined datasets enable end-to-end visibility, allowing managers to identify bottlenecks, optimize inventory levels, reduce lead times, and improve overall supply chain efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "960b0d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   ID    Name Department\n",
      "0  A1    John         HR\n",
      "1  A2   Emily  Marketing\n",
      "2  A3  Martha    Finance\n",
      "3  A4  Samuel         IT\n",
      "\n",
      "DataFrame 2:\n",
      "   ID  Salary  Years_Employed\n",
      "0  A2   60000               3\n",
      "1  A3   80000               7\n",
      "2  A4   70000               4\n",
      "3  A5   90000               2\n",
      "\n",
      "DataFrame 3:\n",
      "   Department  Budget\n",
      "0          HR  100000\n",
      "1   Marketing  200000\n",
      "2     Finance  300000\n",
      "3          IT  250000\n",
      "4  Operations  150000\n"
     ]
    }
   ],
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': ['A1', 'A2', 'A3', 'A4'],\n",
    "    'Name': ['John', 'Emily', 'Martha', 'Samuel'],\n",
    "    'Department': ['HR', 'Marketing', 'Finance', 'IT']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': ['A2', 'A3', 'A4', 'A5'],\n",
    "    'Salary': [60000, 80000, 70000, 90000],\n",
    "    'Years_Employed': [3, 7, 4, 2]\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'Department': ['HR', 'Marketing', 'Finance', 'IT', 'Operations'],\n",
    "    'Budget': [100000, 200000, 300000, 250000, 150000]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "print(\"\\nDataFrame 3:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22ac2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner join:\n",
      "   ID    Name Department  Salary  Years_Employed\n",
      "0  A2   Emily  Marketing   60000               3\n",
      "1  A3  Martha    Finance   80000               7\n",
      "2  A4  Samuel         IT   70000               4\n",
      "\n",
      "Left join:\n",
      "   ID    Name Department   Salary  Years_Employed\n",
      "0  A1    John         HR      NaN             NaN\n",
      "1  A2   Emily  Marketing  60000.0             3.0\n",
      "2  A3  Martha    Finance  80000.0             7.0\n",
      "3  A4  Samuel         IT  70000.0             4.0\n",
      "\n",
      "Right join:\n",
      "   ID    Name Department  Salary  Years_Employed\n",
      "0  A2   Emily  Marketing   60000               3\n",
      "1  A3  Martha    Finance   80000               7\n",
      "2  A4  Samuel         IT   70000               4\n",
      "3  A5     NaN        NaN   90000               2\n",
      "\n",
      "Outer join:\n",
      "   ID    Name Department   Salary  Years_Employed\n",
      "0  A1    John         HR      NaN             NaN\n",
      "1  A2   Emily  Marketing  60000.0             3.0\n",
      "2  A3  Martha    Finance  80000.0             7.0\n",
      "3  A4  Samuel         IT  70000.0             4.0\n",
      "4  A5     NaN        NaN  90000.0             2.0\n"
     ]
    }
   ],
   "source": [
    "# Different join types\n",
    "\n",
    "# Inner join\n",
    "inner_join = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(\"Inner join:\")\n",
    "print(inner_join)\n",
    "\n",
    "# Left join\n",
    "left_join = pd.merge(df1, df2, on='ID', how='left')\n",
    "print(\"\\nLeft join:\")\n",
    "print(left_join)\n",
    "\n",
    "# Right join\n",
    "right_join = pd.merge(df1, df2, on='ID', how='right')\n",
    "print(\"\\nRight join:\")\n",
    "print(right_join)\n",
    "\n",
    "# Outer join\n",
    "outer_join = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(\"\\nOuter join:\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ca9c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining on Department column:\n",
      "   ID    Name Department  Budget\n",
      "0  A1    John         HR  100000\n",
      "1  A2   Emily  Marketing  200000\n",
      "2  A3  Martha    Finance  300000\n",
      "3  A4  Samuel         IT  250000\n"
     ]
    }
   ],
   "source": [
    "# Join on different column names\n",
    "dept_budget = pd.merge(df1, df3, on='Department', how='left')\n",
    "print(\"Joining on Department column:\")\n",
    "print(dept_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5619315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated rows:\n",
      "   ID    Name Department\n",
      "0  A1    John         HR\n",
      "1  A2   Emily  Marketing\n",
      "2  A3  Martha    Finance\n",
      "3  A4  Samuel         IT\n",
      "4  A6    Mark      Legal\n",
      "5  A7    Lisa         HR\n",
      "\n",
      "Concatenated columns:\n",
      "      Name Department  Performance_Score  Bonus\n",
      "A1    John         HR                4.5   2000\n",
      "A2   Emily  Marketing                3.9   1500\n",
      "A3  Martha    Finance                4.2   1800\n",
      "A4  Samuel         IT                4.7   2200\n"
     ]
    }
   ],
   "source": [
    "# Concatenating DataFrames\n",
    "df4 = pd.DataFrame({\n",
    "    'ID': ['A6', 'A7'],\n",
    "    'Name': ['Mark', 'Lisa'],\n",
    "    'Department': ['Legal', 'HR']\n",
    "})\n",
    "\n",
    "# Vertical concatenation (row-wise)\n",
    "df_concat_rows = pd.concat([df1, df4], ignore_index=True)\n",
    "print(\"Concatenated rows:\")\n",
    "print(df_concat_rows)\n",
    "\n",
    "# Horizontal concatenation (column-wise)\n",
    "df5 = pd.DataFrame({\n",
    "    'Performance_Score': [4.5, 3.9, 4.2, 4.7],\n",
    "    'Bonus': [2000, 1500, 1800, 2200]\n",
    "}, index=['A1', 'A2', 'A3', 'A4'])\n",
    "\n",
    "df1_with_index = df1.copy()\n",
    "df1_with_index.set_index('ID', inplace=True)\n",
    "\n",
    "df_concat_cols = pd.concat([df1_with_index, df5], axis=1)\n",
    "print(\"\\nConcatenated columns:\")\n",
    "print(df_concat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d790aa0",
   "metadata": {},
   "source": [
    "## 8. Working with Time Series Data\n",
    "\n",
    "Pandas has excellent support for time series analysis.\n",
    "\n",
    "### Real-Life Use Case: Energy Consumption Forecasting\n",
    "\n",
    "Utility companies need to forecast energy demand to efficiently manage power generation and distribution. Using pandas time series capabilities, data scientists can analyze historical consumption patterns, identify seasonal trends (e.g., higher usage during summer months for cooling), detect daily patterns (peak hours vs. off-peak), and account for special events or holidays. By resampling hourly data to daily or weekly aggregates, calculating rolling averages to smooth out noise, and extracting time-based features (day of week, month, holiday indicators), they can build accurate forecasting models. These forecasts help optimize power generation schedules, reduce costs, and ensure reliable service during peak demand periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c4c5d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series data (first few rows):\n",
      "           Store Product  Units_Sold  Revenue  Customer_Satisfaction  \\\n",
      "Date                                                                   \n",
      "2023-01-01     C    Tool          32     1469                      5   \n",
      "2023-01-02     D  Gadget          39     2086                      1   \n",
      "2023-01-03     A  Gadget          49      246                      3   \n",
      "2023-01-04     C  Device          32     3319                      2   \n",
      "2023-01-05     C  Gadget           4     3011                      1   \n",
      "\n",
      "            Revenue_per_Unit  Is_High_Value Satisfaction_Category  \n",
      "Date                                                               \n",
      "2023-01-01         45.906250          False                  High  \n",
      "2023-01-02         53.487179          False                   Low  \n",
      "2023-01-03          5.020408          False                Medium  \n",
      "2023-01-04        103.718750           True                Medium  \n",
      "2023-01-05        752.750000           True                   Low  \n"
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set Date as index\n",
    "ts_df = df.set_index('Date')\n",
    "print(\"Time series data (first few rows):\")\n",
    "print(ts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92ebcc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date components:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Year  Month  Day    Weekday\n",
       "0 2023-01-01  2023      1    1     Sunday\n",
       "1 2023-01-02  2023      1    2     Monday\n",
       "2 2023-01-03  2023      1    3    Tuesday\n",
       "3 2023-01-04  2023      1    4  Wednesday\n",
       "4 2023-01-05  2023      1    5   Thursday"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting date components\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Weekday'] = df['Date'].dt.day_name()\n",
    "\n",
    "print(\"Date components:\")\n",
    "df[['Date', 'Year', 'Month', 'Day', 'Weekday']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79d6b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly sales:\n",
      "Date\n",
      "2023-01-01     1469\n",
      "2023-01-08    13027\n",
      "2023-01-15    21538\n",
      "2023-01-22    15385\n",
      "2023-01-29    21609\n",
      "Freq: W-SUN, Name: Revenue, dtype: int64\n",
      "\n",
      "Monthly aggregated data:\n",
      "            Revenue  Units_Sold  Customer_Satisfaction\n",
      "Date                                                  \n",
      "2023-01-31    78881         883               2.516129\n",
      "2023-02-28    79362         746               3.178571\n",
      "2023-03-31    85414         695               3.096774\n",
      "2023-04-30    19428         216               3.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mb\\AppData\\Local\\Temp\\ipykernel_4456\\58951012.py:8: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_sales = ts_df.resample('M').agg({\n"
     ]
    }
   ],
   "source": [
    "# Time series resampling\n",
    "# Daily to weekly resampling\n",
    "weekly_sales = ts_df.resample('W')['Revenue'].sum()\n",
    "print(\"Weekly sales:\")\n",
    "print(weekly_sales.head())\n",
    "\n",
    "# Daily to monthly resampling\n",
    "monthly_sales = ts_df.resample('M').agg({\n",
    "    'Revenue': 'sum',\n",
    "    'Units_Sold': 'sum',\n",
    "    'Customer_Satisfaction': 'mean'\n",
    "})\n",
    "print(\"\\nMonthly aggregated data:\")\n",
    "print(monthly_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bffcd4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January data shape: (31, 8)\n",
      "Q1 data shape: (90, 8)\n"
     ]
    }
   ],
   "source": [
    "# Time-based filtering\n",
    "# Filter data for a specific month\n",
    "jan_data = ts_df['2023-01-01':'2023-01-31']\n",
    "print(f\"January data shape: {jan_data.shape}\")\n",
    "\n",
    "# Filter data between two dates\n",
    "q1_data = ts_df['2023-01-01':'2023-03-31']\n",
    "print(f\"Q1 data shape: {q1_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6c867",
   "metadata": {},
   "source": [
    "## 9. Practical Exercises\n",
    "\n",
    "Let's consolidate our knowledge with some practical exercises.\n",
    "\n",
    "### Real-Life Use Case: Business Intelligence Dashboard\n",
    "\n",
    "A business intelligence team needs to create interactive dashboards for company executives. The exercises below mimic the type of data preparation and analysis required to power these dashboards. By practicing these skills, you'll learn how to transform raw data into meaningful business insights that drive decision-making. In real-world scenarios, the output of these analyses would feed into visualization tools like Tableau, Power BI, or custom web dashboards used by stakeholders across the organization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bf5b5",
   "metadata": {},
   "source": [
    "### Exercise 1: Basic Data Analysis\n",
    "\n",
    "1. Load the sales data\n",
    "2. Find the top 5 days with highest revenue\n",
    "3. Calculate the average satisfaction score by product\n",
    "4. Identify which store has the highest average revenue per transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c2e209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 days with highest revenue:\n",
      "Date\n",
      "2023-03-16    4993\n",
      "2023-03-21    4854\n",
      "2023-01-13    4836\n",
      "2023-03-02    4835\n",
      "2023-02-04    4823\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      "Average satisfaction score by product:\n",
      "Product\n",
      "Tool      3.100000\n",
      "Gadget    3.050000\n",
      "Device    3.000000\n",
      "Widget    2.769231\n",
      "Name: Customer_Satisfaction, dtype: float64\n",
      "\n",
      "Average revenue per transaction by store:\n",
      "Store\n",
      "C    3001.833333\n",
      "A    2897.500000\n",
      "D    2436.466667\n",
      "B    2307.576923\n",
      "Name: Revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1 Solution\n",
    "\n",
    "# 1. Load the sales data\n",
    "sales = pd.read_csv('sales_data.csv')\n",
    "sales['Date'] = pd.to_datetime(sales['Date'])\n",
    "\n",
    "# 2. Find the top 5 days with highest revenue\n",
    "top_revenue_days = sales.groupby('Date')['Revenue'].sum().sort_values(ascending=False).head(5)\n",
    "print(\"Top 5 days with highest revenue:\")\n",
    "print(top_revenue_days)\n",
    "\n",
    "# 3. Calculate the average satisfaction score by product\n",
    "product_satisfaction = sales.groupby('Product')['Customer_Satisfaction'].mean().sort_values(ascending=False)\n",
    "print(\"\\nAverage satisfaction score by product:\")\n",
    "print(product_satisfaction)\n",
    "\n",
    "# 4. Identify which store has the highest average revenue per transaction\n",
    "store_avg_revenue = sales.groupby('Store')['Revenue'].mean().sort_values(ascending=False)\n",
    "print(\"\\nAverage revenue per transaction by store:\")\n",
    "print(store_avg_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11a2759",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Transformation Challenge\n",
    "\n",
    "1. Create a new column that categorizes revenue into 'Low', 'Medium', 'High' based on percentiles\n",
    "2. Calculate a 7-day moving average of revenue\n",
    "3. Find the correlation between units sold and customer satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a1321e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue categories count:\n",
      "Revenue_Category\n",
      "Medium    34\n",
      "Low       33\n",
      "High      33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "7-day moving average of revenue (first 10 days):\n",
      "Date\n",
      "2023-01-01            NaN\n",
      "2023-01-02            NaN\n",
      "2023-01-03            NaN\n",
      "2023-01-04            NaN\n",
      "2023-01-05            NaN\n",
      "2023-01-06            NaN\n",
      "2023-01-07    1986.857143\n",
      "2023-01-08    1861.000000\n",
      "2023-01-09    2002.428571\n",
      "2023-01-10    2261.428571\n",
      "Name: Revenue, dtype: float64\n",
      "\n",
      "Correlation matrix:\n",
      "                       Units_Sold  Customer_Satisfaction   Revenue\n",
      "Units_Sold               1.000000               0.131948 -0.112895\n",
      "Customer_Satisfaction    0.131948               1.000000 -0.211610\n",
      "Revenue                 -0.112895              -0.211610  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2 Solution\n",
    "\n",
    "# 1. Create a new column that categorizes revenue into 'Low', 'Medium', 'High' based on percentiles\n",
    "sales['Revenue_Category'] = pd.qcut(\n",
    "    sales['Revenue'], \n",
    "    q=[0, 0.33, 0.67, 1], \n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "print(\"Revenue categories count:\")\n",
    "print(sales['Revenue_Category'].value_counts())\n",
    "\n",
    "# 2. Calculate a 7-day moving average of revenue\n",
    "ts_sales = sales.set_index('Date').sort_index()\n",
    "revenue_ma = ts_sales['Revenue'].rolling(window=7).mean()\n",
    "\n",
    "print(\"\\n7-day moving average of revenue (first 10 days):\")\n",
    "print(revenue_ma.head(10))\n",
    "\n",
    "# 3. Find the correlation between units sold and customer satisfaction\n",
    "correlation = sales[['Units_Sold', 'Customer_Satisfaction', 'Revenue']].corr()\n",
    "print(\"\\nCorrelation matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8446d1",
   "metadata": {},
   "source": [
    "### Exercise 3: Advanced Analysis\n",
    "\n",
    "1. Identify which product-store combination generates the highest total revenue\n",
    "2. Calculate the day of week effect on sales\n",
    "3. Create a pivot table showing total revenue by store and product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d380c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 product-store combinations by revenue:\n",
      "   Store Product  Revenue\n",
      "14     D    Tool    46947\n",
      "11     C  Widget    34917\n",
      "0      A  Device    25735\n",
      "5      B  Gadget    18911\n",
      "10     C    Tool    17091\n",
      "\n",
      "Sales by day of week:\n",
      "             sum         mean\n",
      "Weekday                      \n",
      "Monday     31976  2131.733333\n",
      "Tuesday    35211  2515.071429\n",
      "Wednesday  42994  3071.000000\n",
      "Thursday   40042  2860.142857\n",
      "Friday     34728  2480.571429\n",
      "Saturday   36279  2591.357143\n",
      "Sunday     41855  2790.333333\n",
      "\n",
      "Total revenue by store and product:\n",
      "Product  Device  Gadget   Tool  Widget\n",
      "Store                                 \n",
      "A         25735    3932  14842   13441\n",
      "B         11283   18911  13020   16783\n",
      "C         10993    9043  17091   34917\n",
      "D         12008    6043  46947    8096\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3 Solution\n",
    "\n",
    "# 1. Identify which product-store combination generates the highest total revenue\n",
    "product_store_revenue = sales.groupby(['Store', 'Product'])['Revenue'].sum().reset_index()\n",
    "top_combinations = product_store_revenue.sort_values(by='Revenue', ascending=False).head(5)\n",
    "print(\"Top 5 product-store combinations by revenue:\")\n",
    "print(top_combinations)\n",
    "\n",
    "# 2. Calculate the day of week effect on sales\n",
    "sales['Weekday'] = sales['Date'].dt.day_name()\n",
    "weekday_sales = sales.groupby('Weekday')['Revenue'].agg(['sum', 'mean'])\n",
    "# Reorder days of week\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_sales = weekday_sales.reindex(weekday_order)\n",
    "print(\"\\nSales by day of week:\")\n",
    "print(weekday_sales)\n",
    "\n",
    "# 3. Create a pivot table showing total revenue by store and product\n",
    "pivot = pd.pivot_table(sales, values='Revenue', index='Store', columns='Product', \n",
    "                       aggfunc='sum', fill_value=0)\n",
    "print(\"\\nTotal revenue by store and product:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5788c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've covered key pandas functionalities for data manipulation:\n",
    "\n",
    "- **Creating and working with pandas data structures** (Series, DataFrame) - *essential for organizing any data analysis project*\n",
    "- **Reading and writing data from/to various formats** - *critical for working with diverse data sources in business environments*\n",
    "- **Data inspection and cleaning techniques** - *fundamental for ensuring data quality in any analytics workflow*\n",
    "- **Different ways to select, filter, and index data** - *powerful capabilities for focusing on relevant subsets of your data*\n",
    "- **Data transformation and aggregation methods** - *key for summarizing information and extracting insights*\n",
    "- **Handling missing data effectively** - *essential for maintaining data integrity despite incomplete information*\n",
    "- **Combining datasets through merging, joining, and concatenation** - *important for creating comprehensive unified datasets*\n",
    "- **Working with time series data** - *crucial for analyzing patterns over time and making forecasts*\n",
    "- **Practical exercises to apply these concepts** - *reinforcing learning through hands-on problem-solving*\n",
    "\n",
    "These pandas skills form the backbone of modern data analysis in Python, applicable across industries from finance and healthcare to marketing and environmental science. Mastering these techniques will enable you to efficiently transform raw data into actionable insights in virtually any data-driven role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f40cee",
   "metadata": {},
   "source": [
    "## Additional Real-World Case Studies\n",
    "\n",
    "### 1. Fraud Detection in Banking\n",
    "\n",
    "Banks use pandas to analyze transaction data for suspicious patterns. Data scientists create features like transaction frequency, amount deviations from historical patterns, and geographic anomalies using pandas groupby, rolling window functions, and filtering operations. These derived features feed into machine learning models that flag potentially fraudulent transactions for further investigation.\n",
    "\n",
    "```python\n",
    "# Example of transaction frequency analysis\n",
    "hourly_transactions = df.groupby([df['transaction_date'].dt.date, \n",
    "                                df['customer_id'], \n",
    "                                df['transaction_date'].dt.hour])['amount'].count().reset_index()\n",
    "# Flag unusual transaction frequency\n",
    "customer_hourly_stats = hourly_transactions.groupby('customer_id')['amount'].agg(['mean', 'std'])\n",
    "merged_data = hourly_transactions.merge(customer_hourly_stats, on='customer_id')\n",
    "merged_data['z_score'] = (merged_data['amount'] - merged_data['mean']) / merged_data['std']\n",
    "suspicious = merged_data[merged_data['z_score'] > 3]  # Transactions with unusually high frequency\n",
    "```\n",
    "\n",
    "### 2. Product Recommendation Systems\n",
    "\n",
    "E-commerce companies use pandas to analyze purchase history and build recommendation engines. Data scientists use merge operations to combine user profiles with purchase history, pivot tables to create user-item matrices, and groupby operations to identify frequently co-purchased items. These transformations prepare the data for collaborative filtering algorithms that power \"customers who bought this also bought\" recommendations.\n",
    "\n",
    "### 3. Urban Transportation Planning\n",
    "\n",
    "City planners use pandas to analyze public transit data, including bus/train ridership, traffic patterns, and infrastructure usage. Using time series capabilities, they can identify peak travel times, resampling minute-by-minute data to hourly or daily aggregates. With groupby operations, they can analyze differences between weekdays and weekends, or examine transit usage by neighborhood. These insights help optimize bus routes, traffic light timing, and infrastructure investments.\n",
    "\n",
    "### 4. Clinical Trial Data Analysis\n",
    "\n",
    "Pharmaceutical researchers use pandas to analyze clinical trial results, comparing treatment and control groups across multiple metrics. They use pivot tables to restructure patient visit data from long to wide format, filtering operations to handle inclusion/exclusion criteria, and statistical functions to calculate effect sizes and confidence intervals. Pandas' ability to handle missing values is especially important, as patient data often contains gaps due to missed visits or incomplete tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
