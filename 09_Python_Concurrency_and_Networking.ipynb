{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79547f5c",
   "metadata": {},
   "source": [
    "# Python Concurrency and Networking\n",
    "This notebook covers threading, multiprocessing, async/await, sockets, and HTTP requests with real-life use cases, best practices, and code examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b795c",
   "metadata": {},
   "source": [
    "## 1. Threading\n",
    "**Definition:** Threading allows concurrent execution of code, useful for I/O-bound tasks.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeb455",
   "metadata": {},
   "source": [
    "### Importing Threading and Time Modules\n",
    "\n",
    "**Introduction:**\n",
    "To use threading in Python, you need to import the `threading` and `time` modules.\n",
    "\n",
    "**Real-life use case:**\n",
    "These modules are used for running concurrent tasks and simulating delays in code.\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell imports the required modules for threading examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ac51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be9c19",
   "metadata": {},
   "source": [
    "### Basic Threading Example\n",
    "\n",
    "**Introduction:**\n",
    "A thread allows you to run a function concurrently with the main program.\n",
    "\n",
    "**Real-life use case:**\n",
    "Downloading files in the background while the main program continues.\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell defines a function that prints numbers with a delay, and shows how to run it in a separate thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48caa735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_numbers():\n",
    "    \"\"\"Print numbers with a delay to simulate work.\"\"\"\n",
    "    for i in range(3):\n",
    "        print(f'Thread: {i}')\n",
    "        time.sleep(1)\n",
    "\n",
    "# Create and start a thread\n",
    "thread = threading.Thread(target=print_numbers)\n",
    "thread.start()\n",
    "print(\"Main thread continues while child thread runs\")\n",
    "thread.join()\n",
    "print(\"Thread completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3457a",
   "metadata": {},
   "source": [
    "### Running Multiple Threads in Parallel\n",
    "\n",
    "**Introduction:**\n",
    "You can start several threads to perform tasks in parallel, which is useful for handling multiple I/O operations at once.\n",
    "\n",
    "**Real-life use case:**\n",
    "Processing multiple files or network requests simultaneously.\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell defines a worker function and starts multiple threads to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(name):\n",
    "    \"\"\"Worker function that reports its name and timestamps.\"\"\"\n",
    "    print(f'Worker {name} starting')\n",
    "    time.sleep(2)\n",
    "    print(f'Worker {name} finished')\n",
    "\n",
    "threads = []\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=worker, args=(f'#{i}',))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(\"All workers completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b5cd5",
   "metadata": {},
   "source": [
    "### Running a Background Task with a Daemon Thread\n",
    "\n",
    "**Introduction:**\n",
    "Daemon threads run in the background and automatically exit when the main program finishes.\n",
    "\n",
    "**Real-life use case:**\n",
    "Background monitoring or periodic tasks that should not block program exit.\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell creates a daemon thread for a background task while the main thread continues its work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17144a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_task():\n",
    "    for i in range(5):\n",
    "        print(f\"Background task: step {i}\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "background_thread = threading.Thread(target=background_task)\n",
    "background_thread.daemon = True\n",
    "background_thread.start()\n",
    "for i in range(3):\n",
    "    print(f\"Main thread: step {i}\")\n",
    "    time.sleep(0.7)\n",
    "print(\"Main thread finished (background thread may not have completed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745caa5",
   "metadata": {},
   "source": [
    "### Thread Synchronization with Lock\n",
    "\n",
    "**Introduction:**\n",
    "When multiple threads access shared data, you need synchronization to prevent race conditions.\n",
    "\n",
    "**Real-life use case:**\n",
    "Safely updating a shared counter from multiple threads.\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell demonstrates using a Lock to synchronize access to a shared variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "count_lock = threading.Lock()\n",
    "\n",
    "def increment_counter():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with count_lock:\n",
    "            counter += 1\n",
    "thread1 = threading.Thread(target=increment_counter)\n",
    "thread2 = threading.Thread(target=increment_counter)\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "print(f\"Final counter value with locks: {counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6142a3",
   "metadata": {},
   "source": [
    "### Producer-Consumer Pattern with Queue\n",
    "\n",
    "**Introduction:**\n",
    "The producer-consumer pattern uses a queue to safely pass data between threads.\n",
    "\n",
    "**Real-life use case:**\n",
    "A web crawler where one thread fetches URLs (producer) and another processes the content (consumer).\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell demonstrates a producer thread putting items in a queue and a consumer thread processing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "task_queue = queue.Queue()\n",
    "\n",
    "def producer():\n",
    "    for i in range(5):\n",
    "        item = f\"Item-{i}\"\n",
    "        task_queue.put(item)\n",
    "        print(f\"Produced {item}\")\n",
    "        time.sleep(0.5)\n",
    "    task_queue.put(None)\n",
    "\n",
    "def consumer():\n",
    "    while True:\n",
    "        item = task_queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        print(f\"Consumed {item}\")\n",
    "        task_queue.task_done()\n",
    "        time.sleep(1)\n",
    "prod_thread = threading.Thread(target=producer)\n",
    "cons_thread = threading.Thread(target=consumer)\n",
    "prod_thread.start()\n",
    "cons_thread.start()\n",
    "prod_thread.join()\n",
    "cons_thread.join()\n",
    "print(\"Producer-Consumer demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fbf0d",
   "metadata": {},
   "source": [
    "### Note on Python's Global Interpreter Lock (GIL)\n",
    "\n",
    "**Introduction:**\n",
    "The Global Interpreter Lock (GIL) affects how threads execute Python code.\n",
    "\n",
    "**Real-life use case:**\n",
    "Understanding the GIL helps you choose between threading and multiprocessing for your application.\n",
    "\n",
    "**What the code does:**\n",
    "The next code cell explains the GIL and when to use threading vs. multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The GIL prevents multiple native threads from executing Python bytecode at once.\")\n",
    "print(\"This means threading is most useful for I/O-bound tasks rather than CPU-bound tasks.\")\n",
    "print(\"For CPU-bound tasks, consider multiprocessing instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4d36e",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "Thread: 0\n",
    "Thread: 1\n",
    "Thread: 2\n",
    "\n",
    "**Real-life use case:** Downloading multiple files at the same time.\n",
    "\n",
    "**Common mistakes:** Not using locks for shared data, leading to race conditions.\n",
    "\n",
    "**Best practices:** Use threading for I/O-bound tasks and use locks for shared resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e9393",
   "metadata": {},
   "source": [
    "## 2. Multiprocessing\n",
    "**Definition:** Multiprocessing runs code in separate processes, ideal for CPU-bound tasks.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694421d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic multiprocessing Pool example:\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Basic multiprocessing example with Pool\n",
    "print(\"Basic multiprocessing Pool example:\")\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Simple CPU-bound function that squares a number\"\"\"\n",
    "    # Display process ID to show work happens in different processes\n",
    "    process_id = os.getpid()\n",
    "    print(f\"Process {process_id}: Computing square of {x}\")\n",
    "    # Simulate complex computation\n",
    "    time.sleep(0.5)\n",
    "    return x * x\n",
    "\n",
    "# Using a process pool to execute tasks in parallel\n",
    "if __name__ == '__main__':  # Required for Windows compatibility\n",
    "    # Create a pool with 2 worker processes\n",
    "    with multiprocessing.Pool(processes=2) as pool:\n",
    "        # Map the square function to a list of inputs\n",
    "        results = pool.map(square, [1, 2, 3, 4])\n",
    "        print(f\"Results: {results}\")\n",
    "\n",
    "# Using Process class directly\n",
    "print(\"\\nUsing the Process class directly:\")\n",
    "\n",
    "def worker_function(name):\n",
    "    \"\"\"Function to be executed in a separate process\"\"\"\n",
    "    process_id = os.getpid()\n",
    "    print(f\"Worker {name} (PID: {process_id}) starting\")\n",
    "    time.sleep(1)  # Simulate work\n",
    "    print(f\"Worker {name} (PID: {process_id}) finished\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create multiple processes\n",
    "    processes = []\n",
    "    for i in range(3):\n",
    "        # Create a process that runs worker_function\n",
    "        p = multiprocessing.Process(\n",
    "            target=worker_function, \n",
    "            args=(f'Process-{i}',)\n",
    "        )\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    # Wait for all processes to complete\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(\"All worker processes completed\")\n",
    "\n",
    "# CPU-bound task example - calculating prime numbers\n",
    "print(\"\\nCPU-bound task example - finding prime numbers:\")\n",
    "\n",
    "def is_prime(n):\n",
    "    \"\"\"Check if a number is prime (CPU-intensive)\"\"\"\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n <= 3:\n",
    "        return True\n",
    "    if n % 2 == 0 or n % 3 == 0:\n",
    "        return False\n",
    "    i = 5\n",
    "    while i * i <= n:\n",
    "        if n % i == 0 or n % (i + 2) == 0:\n",
    "            return False\n",
    "        i += 6\n",
    "    return True\n",
    "\n",
    "def count_primes_in_range(start, end):\n",
    "    \"\"\"Count prime numbers in a given range\"\"\"\n",
    "    count = sum(1 for i in range(start, end) if is_prime(i))\n",
    "    return count\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define a large range to search for primes\n",
    "    range_start = 1\n",
    "    range_end = 100000\n",
    "    \n",
    "    # Split the work into chunks for parallel processing\n",
    "    num_processes = multiprocessing.cpu_count()  # Use all available cores\n",
    "    print(f\"Using {num_processes} processes\")\n",
    "    \n",
    "    chunk_size = (range_end - range_start) // num_processes\n",
    "    chunks = [(range_start + i * chunk_size, \n",
    "              range_start + (i + 1) * chunk_size) \n",
    "             for i in range(num_processes)]\n",
    "    \n",
    "    # Measure time with multiprocessing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process chunks in parallel\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results = pool.starmap(count_primes_in_range, chunks)\n",
    "    \n",
    "    total_primes = sum(results)\n",
    "    mp_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Found {total_primes} prime numbers in range {range_start}-{range_end}\")\n",
    "    print(f\"Multiprocessing time: {mp_time:.2f} seconds\")\n",
    "    \n",
    "    # Compare with single-process time (on a small subset for demonstration)\n",
    "    small_end = 10000  # Smaller range for quick single-process demo\n",
    "    start_time = time.time()\n",
    "    single_result = count_primes_in_range(range_start, small_end)\n",
    "    single_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Single process found {single_result} primes in range {range_start}-{small_end}\")\n",
    "    print(f\"Single process time: {single_time:.2f} seconds\")\n",
    "\n",
    "# Shared memory example\n",
    "print(\"\\nShared memory example:\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a shared value\n",
    "    counter = multiprocessing.Value('i', 0)  # 'i' means signed integer\n",
    "    \n",
    "    def increment_counter(count, lock):\n",
    "        for _ in range(count):\n",
    "            with lock:  # Use lock to avoid race conditions\n",
    "                counter.value += 1\n",
    "    \n",
    "    # Create a lock to protect the shared counter\n",
    "    lock = multiprocessing.Lock()\n",
    "    \n",
    "    # Create processes that increment the same counter\n",
    "    processes = []\n",
    "    num_increments = 1000\n",
    "    for _ in range(4):\n",
    "        p = multiprocessing.Process(\n",
    "            target=increment_counter, \n",
    "            args=(num_increments, lock)\n",
    "        )\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    # Wait for all processes to complete\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(f\"Final counter value: {counter.value}\")\n",
    "\n",
    "# Data processing with multiprocessing in numpy (common in data science)\n",
    "print(\"\\nData processing with multiprocessing (numpy example):\")\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"Process a chunk of data\"\"\"\n",
    "    # Simulate complex data processing\n",
    "    result = np.mean(chunk) * np.std(chunk)\n",
    "    time.sleep(0.2)  # Simulate computation time\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a large dataset\n",
    "    data = np.random.rand(1000000)\n",
    "    \n",
    "    # Split data into chunks\n",
    "    chunks = np.array_split(data, 4)\n",
    "    \n",
    "    # Process in parallel\n",
    "    start_time = time.time()\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        results = pool.map(process_chunk, chunks)\n",
    "    \n",
    "    # Combine results\n",
    "    combined_result = np.mean(results)\n",
    "    mp_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Parallel processing result: {combined_result:.6f}\")\n",
    "    print(f\"Processing time: {mp_time:.2f} seconds\")\n",
    "    \n",
    "    # Tips for effective multiprocessing\n",
    "    print(\"\\nTips for effective multiprocessing:\")\n",
    "    print(\"1. Always protect shared memory with locks\")\n",
    "    print(\"2. Minimize data transfer between processes\")\n",
    "    print(\"3. Use multiprocessing for CPU-bound tasks, not I/O-bound tasks\")\n",
    "    print(\"4. Use 'if __name__ == __main__' guard for Windows compatibility\")\n",
    "    print(\"5. Consider process pools for managing worker processes\")\n",
    "    print(\"6. Be aware of overhead - only use multiprocessing when tasks are substantial\")\n",
    "\n",
    "# Expected output will vary by system, but will include:\n",
    "# - Multiple processes executing in parallel with different PIDs\n",
    "# - Results from pool.map operations\n",
    "# - Time comparisons showing parallel processing advantage\n",
    "# - Shared memory counter results\n",
    "# - Data processing results with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c89cac",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "[1, 4, 9, 16]\n",
    "\n",
    "**Real-life use case:** Image processing or data analysis on large datasets.\n",
    "\n",
    "**Common mistakes:** Sharing state between processes (each process has its own memory space).\n",
    "\n",
    "**Best practices:** Use multiprocessing for CPU-bound tasks and avoid sharing state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ed896",
   "metadata": {},
   "source": [
    "## 3. Async/Await\n",
    "**Definition:** Async/await enables asynchronous programming, useful for high-performance I/O-bound code.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import aiohttp\n",
    "import random\n",
    "\n",
    "# Basic async example\n",
    "async def say_hello():\n",
    "    \"\"\"A simple coroutine that waits and then prints a message\"\"\"\n",
    "    await asyncio.sleep(1)  # Non-blocking sleep\n",
    "    print('Hello after 1 second')\n",
    "    return \"Hello returned\"  # Return value from coroutine\n",
    "\n",
    "# Run a single coroutine\n",
    "print(\"Basic async example:\")\n",
    "result = asyncio.run(say_hello())\n",
    "print(f\"Coroutine returned: {result}\")\n",
    "\n",
    "# Multiple coroutines running concurrently\n",
    "print(\"\\nMultiple coroutines running concurrently:\")\n",
    "\n",
    "async def process_item(item):\n",
    "    \"\"\"Process an item asynchronously\"\"\"\n",
    "    # Simulate I/O operation with different durations\n",
    "    delay = random.uniform(0.5, 1.5)\n",
    "    print(f\"Processing {item}, will take {delay:.2f} seconds\")\n",
    "    await asyncio.sleep(delay)  # Non-blocking sleep\n",
    "    return f\"Processed {item}\"\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Run multiple coroutines concurrently\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list of coroutines to run\n",
    "    tasks = [process_item(f\"item-{i}\") for i in range(5)]\n",
    "    \n",
    "    # Wait for all coroutines to complete and gather results\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nAll items processed in {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Results: {results}\")\n",
    "\n",
    "# Run the main coroutine\n",
    "asyncio.run(main())\n",
    "\n",
    "# Comparing async with sequential execution\n",
    "print(\"\\nComparing async with sequential execution:\")\n",
    "\n",
    "async def fetch_data(session, url):\n",
    "    \"\"\"Fetch data from a URL asynchronously\"\"\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    try:\n",
    "        # Asynchronous HTTP request\n",
    "        async with session.get(url, timeout=5) as response:\n",
    "            # Simulate varying response times\n",
    "            delay = random.uniform(1, 3)\n",
    "            await asyncio.sleep(delay)  # Simulate network delay\n",
    "            return f\"Result from {url}: {response.status}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching {url}: {str(e)}\"\n",
    "\n",
    "async def fetch_all_async():\n",
    "    \"\"\"Fetch multiple URLs asynchronously\"\"\"\n",
    "    urls = [\n",
    "        'https://example.com',\n",
    "        'https://python.org',\n",
    "        'https://github.com',\n",
    "        'https://stackoverflow.com'\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a client session\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Create tasks for each URL\n",
    "        tasks = [fetch_data(session, url) for url in urls]\n",
    "        # Wait for all tasks to complete\n",
    "        results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nAsync fetch completed in {end_time - start_time:.2f} seconds\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    return end_time - start_time\n",
    "\n",
    "def fetch_sequential():\n",
    "    \"\"\"Fetch multiple URLs sequentially (for comparison)\"\"\"\n",
    "    urls = [\n",
    "        'https://example.com',\n",
    "        'https://python.org',\n",
    "        'https://github.com',\n",
    "        'https://stackoverflow.com'\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"\\nSequential fetch:\")\n",
    "    results = []\n",
    "    for url in urls:\n",
    "        print(f\"Fetching: {url}\")\n",
    "        # Simulate a blocking request\n",
    "        delay = random.uniform(1, 3)\n",
    "        time.sleep(delay)  # Blocking sleep\n",
    "        results.append(f\"Result from {url}: 200\")  # Simulated status\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nSequential fetch completed in {end_time - start_time:.2f} seconds\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    return end_time - start_time\n",
    "\n",
    "# Run both implementations (comment out for notebook as it requires network)\n",
    "# Note: actual network requests are simulated in this example\n",
    "print(\"\\nSimulated network requests:\")\n",
    "async_time = 0\n",
    "seq_time = 0\n",
    "\n",
    "try:\n",
    "    # Will only work if aiohttp is installed\n",
    "    import aiohttp\n",
    "    print(\"Running async version (simulated):\")\n",
    "    async_time = asyncio.run(fetch_all_async())\n",
    "except ModuleNotFoundError:\n",
    "    print(\"aiohttp not installed, skipping async example\")\n",
    "\n",
    "# Run sequential version\n",
    "print(\"Running sequential version (simulated):\")\n",
    "seq_time = fetch_sequential()\n",
    "\n",
    "if async_time > 0 and seq_time > 0:\n",
    "    print(f\"\\nSpeed comparison: Async is {seq_time / async_time:.1f}x faster\")\n",
    "\n",
    "# Async with timeout handling\n",
    "print(\"\\nAsync with timeout handling:\")\n",
    "\n",
    "async def slow_operation():\n",
    "    \"\"\"A slow operation that will be cancelled\"\"\"\n",
    "    print(\"Slow operation started\")\n",
    "    await asyncio.sleep(10)  # Very long operation\n",
    "    print(\"Slow operation completed\")  # This won't be reached\n",
    "    return \"Slow result\"\n",
    "\n",
    "async def timeout_example():\n",
    "    try:\n",
    "        # Set a timeout of 2 seconds\n",
    "        result = await asyncio.wait_for(slow_operation(), timeout=2.0)\n",
    "        return result\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Operation timed out!\")\n",
    "        return \"Timeout result\"\n",
    "\n",
    "# Run with timeout\n",
    "asyncio.run(timeout_example())\n",
    "\n",
    "# Event loop explanation\n",
    "print(\"\\nAsync concepts:\")\n",
    "print(\"1. Event Loop: The core of async I/O, schedules and runs coroutines\")\n",
    "print(\"2. Coroutine: Function defined with 'async def', can be paused with 'await'\")\n",
    "print(\"3. Task: Wrapper around a coroutine to track its execution\")\n",
    "print(\"4. Future: Object representing a result that will be available later\")\n",
    "print(\"5. await: Pauses a coroutine until the awaited object (coroutine, task, future) completes\")\n",
    "\n",
    "print(\"\\nBest practices for async/await:\")\n",
    "print(\"1. Use for I/O-bound tasks (network, file operations) not CPU-bound tasks\")\n",
    "print(\"2. Avoid blocking calls inside async functions\")\n",
    "print(\"3. Use asyncio.gather() to run multiple coroutines in parallel\")\n",
    "print(\"4. Handle exceptions properly in asynchronous code\")\n",
    "print(\"5. Use async libraries for I/O operations (aiohttp, asyncpg, etc.)\")\n",
    "\n",
    "# Expected output (with some variations due to random delays):\n",
    "# Basic async example:\n",
    "# Hello after 1 second\n",
    "# Coroutine returned: Hello returned\n",
    "#\n",
    "# Multiple coroutines running concurrently:\n",
    "# Processing item-0, will take 0.88 seconds\n",
    "# Processing item-1, will take 1.23 seconds\n",
    "# Processing item-2, will take 0.72 seconds\n",
    "# Processing item-3, will take 1.15 seconds\n",
    "# Processing item-4, will take 1.02 seconds\n",
    "#\n",
    "# All items processed in 1.23 seconds\n",
    "# Results: ['Processed item-0', 'Processed item-1', 'Processed item-2', ...]\n",
    "#\n",
    "# Comparing async with sequential execution:\n",
    "#\n",
    "# Simulated network requests:\n",
    "# Running async version (simulated):\n",
    "# Fetching: https://example.com\n",
    "# Fetching: https://python.org\n",
    "# Fetching: https://github.com\n",
    "# Fetching: https://stackoverflow.com\n",
    "#\n",
    "# Async fetch completed in 3.00 seconds\n",
    "# Result from https://example.com: 200\n",
    "# ...\n",
    "#\n",
    "# Running sequential version (simulated):\n",
    "# Sequential fetch:\n",
    "# Fetching: https://example.com\n",
    "# Fetching: https://python.org\n",
    "# Fetching: https://github.com\n",
    "# Fetching: https://stackoverflow.com\n",
    "#\n",
    "# Sequential fetch completed in 9.50 seconds\n",
    "# Result from https://example.com: 200\n",
    "# ...\n",
    "#\n",
    "# Speed comparison: Async is 3.2x faster\n",
    "#\n",
    "# Async with timeout handling:\n",
    "# Slow operation started\n",
    "# Operation timed out!\n",
    "#\n",
    "# Async concepts:\n",
    "# 1. Event Loop: The core of async I/O, schedules and runs coroutines\n",
    "# ...\n",
    "# Best practices for async/await:\n",
    "# 1. Use for I/O-bound tasks (network, file operations) not CPU-bound tasks\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6682b",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "Hello after 1 second\n",
    "\n",
    "**Real-life use case:** Handling thousands of simultaneous web requests in a web server.\n",
    "\n",
    "**Common mistakes:** Mixing blocking code with async code.\n",
    "\n",
    "**Best practices:** Use async for I/O-bound, high-concurrency tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bef1e3",
   "metadata": {},
   "source": [
    "## 4. Sockets\n",
    "**Definition:** Sockets allow low-level network communication. Useful for building custom network protocols.\n",
    "\n",
    "**Syntax and Example:** (Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Basic socket client example\n",
    "def simple_client():\n",
    "    \"\"\"A simple HTTP client using sockets\"\"\"\n",
    "    # Create a socket object (AF_INET = IPv4, SOCK_STREAM = TCP)\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    \n",
    "    try:\n",
    "        # Connect to a server (example.com on port 80)\n",
    "        print(\"Connecting to example.com:80...\")\n",
    "        s.connect(('example.com', 80))\n",
    "        \n",
    "        # Send an HTTP GET request\n",
    "        request = b'GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n'\n",
    "        print(f\"Sending request: {request}\")\n",
    "        s.sendall(request)\n",
    "        \n",
    "        # Receive the response (up to 4096 bytes)\n",
    "        response = s.recv(4096)\n",
    "        \n",
    "        # Print the first part of the response\n",
    "        print(\"\\nResponse (first 300 bytes):\")\n",
    "        print(response[:300].decode('utf-8'))\n",
    "        \n",
    "    finally:\n",
    "        # Always close the socket when done\n",
    "        s.close()\n",
    "        print(\"Socket closed\")\n",
    "\n",
    "# Uncomment to run (requires internet access)\n",
    "# simple_client()\n",
    "\n",
    "# Instead, let's see a local echo server and client example\n",
    "print(\"Local echo server and client example:\")\n",
    "\n",
    "server_running = False\n",
    "SERVER_HOST = '127.0.0.1'  # localhost\n",
    "SERVER_PORT = 12345        # arbitrary non-privileged port\n",
    "\n",
    "def echo_server():\n",
    "    \"\"\"A simple echo server that repeats back messages\"\"\"\n",
    "    global server_running\n",
    "    \n",
    "    # Create server socket\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    \n",
    "    try:\n",
    "        # Allow reuse of address (prevents \"Address already in use\" errors)\n",
    "        server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        \n",
    "        # Bind to host and port\n",
    "        server_socket.bind((SERVER_HOST, SERVER_PORT))\n",
    "        \n",
    "        # Start listening for connections (5 is the backlog queue size)\n",
    "        server_socket.listen(5)\n",
    "        server_running = True\n",
    "        print(f\"Server listening on {SERVER_HOST}:{SERVER_PORT}\")\n",
    "        \n",
    "        # Set a timeout so the server can be stopped\n",
    "        server_socket.settimeout(10)  # 10 seconds timeout\n",
    "        \n",
    "        while server_running:\n",
    "            try:\n",
    "                # Accept incoming connection\n",
    "                client_socket, client_address = server_socket.accept()\n",
    "                print(f\"Connection from {client_address}\")\n",
    "                \n",
    "                # Handle client in a separate thread\n",
    "                client_handler = threading.Thread(\n",
    "                    target=handle_client,\n",
    "                    args=(client_socket, client_address)\n",
    "                )\n",
    "                client_handler.daemon = True\n",
    "                client_handler.start()\n",
    "                \n",
    "            except socket.timeout:\n",
    "                # Just a timeout, continue the loop\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Server error: {e}\")\n",
    "                break\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        server_socket.close()\n",
    "        server_running = False\n",
    "        print(\"Server stopped\")\n",
    "\n",
    "def handle_client(client_socket, address):\n",
    "    \"\"\"Handle communication with a connected client\"\"\"\n",
    "    try:\n",
    "        # Receive data from client\n",
    "        while True:\n",
    "            data = client_socket.recv(1024)\n",
    "            if not data:\n",
    "                # No more data, client has disconnected\n",
    "                break\n",
    "            \n",
    "            message = data.decode('utf-8')\n",
    "            print(f\"Received from {address}: {message.strip()}\")\n",
    "            \n",
    "            # Echo back the data\n",
    "            response = f\"Echo: {message}\"\n",
    "            client_socket.sendall(response.encode('utf-8'))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error handling client {address}: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close client socket\n",
    "        client_socket.close()\n",
    "        print(f\"Connection with {address} closed\")\n",
    "\n",
    "def echo_client(messages):\n",
    "    \"\"\"A client that sends messages to the echo server\"\"\"\n",
    "    # Create client socket\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    \n",
    "    try:\n",
    "        # Connect to server\n",
    "        print(f\"Connecting to {SERVER_HOST}:{SERVER_PORT}...\")\n",
    "        client_socket.connect((SERVER_HOST, SERVER_PORT))\n",
    "        \n",
    "        # Send messages\n",
    "        for message in messages:\n",
    "            print(f\"Sending: {message}\")\n",
    "            client_socket.sendall(message.encode('utf-8'))\n",
    "            \n",
    "            # Wait for response\n",
    "            response = client_socket.recv(1024).decode('utf-8')\n",
    "            print(f\"Received: {response}\")\n",
    "            \n",
    "            # Short delay between messages\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    except ConnectionRefusedError:\n",
    "        print(\"Connection refused. Is the server running?\")\n",
    "    except Exception as e:\n",
    "        print(f\"Client error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close socket\n",
    "        client_socket.close()\n",
    "        print(\"Client disconnected\")\n",
    "\n",
    "# Start the server in a background thread\n",
    "server_thread = threading.Thread(target=echo_server)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(1)\n",
    "\n",
    "# Run client with messages\n",
    "if server_running:\n",
    "    messages = [\n",
    "        \"Hello, server!\",\n",
    "        \"How are you?\",\n",
    "        \"Goodbye!\"\n",
    "    ]\n",
    "    echo_client(messages)\n",
    "\n",
    "# Stop server\n",
    "server_running = False\n",
    "time.sleep(1)  # Give server time to clean up\n",
    "\n",
    "# Socket concepts and best practices\n",
    "print(\"\\nSocket programming concepts:\")\n",
    "print(\"1. Socket Types:\")\n",
    "print(\"   - SOCK_STREAM (TCP): Reliable, ordered, connection-based\")\n",
    "print(\"   - SOCK_DGRAM (UDP): Unreliable, connectionless datagrams\")\n",
    "\n",
    "print(\"\\n2. Socket Address Families:\")\n",
    "print(\"   - AF_INET: IPv4 addresses\")\n",
    "print(\"   - AF_INET6: IPv6 addresses\")\n",
    "print(\"   - AF_UNIX: Unix domain sockets (local inter-process communication)\")\n",
    "\n",
    "print(\"\\n3. Common Socket Operations:\")\n",
    "print(\"   - socket(): Create a socket\")\n",
    "print(\"   - bind(): Bind socket to an address\")\n",
    "print(\"   - listen(): Set up socket for incoming connections\")\n",
    "print(\"   - accept(): Accept incoming connection\")\n",
    "print(\"   - connect(): Connect to a remote socket\")\n",
    "print(\"   - send()/recv(): Send/receive data\")\n",
    "print(\"   - close(): Close the socket\")\n",
    "\n",
    "print(\"\\n4. Socket Options (with setsockopt):\")\n",
    "print(\"   - SO_REUSEADDR: Allow reusing local addresses\")\n",
    "print(\"   - SO_KEEPALIVE: Keep connection alive\")\n",
    "print(\"   - SO_RCVBUF/SO_SNDBUF: Receive/send buffer size\")\n",
    "\n",
    "print(\"\\n5. Best Practices:\")\n",
    "print(\"   - Always close sockets when done\")\n",
    "print(\"   - Use try-finally blocks to ensure cleanup\")\n",
    "print(\"   - Handle partial sends/receives\")\n",
    "print(\"   - Set appropriate timeouts\")\n",
    "print(\"   - Consider using non-blocking sockets or async I/O for high performance\")\n",
    "print(\"   - Be aware of network errors and handle them gracefully\")\n",
    "\n",
    "# Note about socket vs requests\n",
    "print(\"\\nNote: While sockets provide low-level control, \")\n",
    "print(\"for most HTTP needs, the 'requests' library is easier to use.\")\n",
    "\n",
    "# Expected output:\n",
    "# Local echo server and client example:\n",
    "# Server listening on 127.0.0.1:12345\n",
    "# Connecting to 127.0.0.1:12345...\n",
    "# Sending: Hello, server!\n",
    "# Received: Echo: Hello, server!\n",
    "# Sending: How are you?\n",
    "# Received: Echo: How are you?\n",
    "# Sending: Goodbye!\n",
    "# Received: Echo: Goodbye!\n",
    "# Client disconnected\n",
    "# Server stopped\n",
    "#\n",
    "# Socket programming concepts:\n",
    "# 1. Socket Types:\n",
    "#    - SOCK_STREAM (TCP): Reliable, ordered, connection-based\n",
    "#    - SOCK_DGRAM (UDP): Unreliable, connectionless datagrams\n",
    "# ...etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13c9f5",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "HTTP/1.1 200 OK ... (HTML content)\n",
    "\n",
    "**Real-life use case:** Building a chat application or custom server.\n",
    "\n",
    "**Common mistakes:** Not closing sockets or handling partial data.\n",
    "\n",
    "**Best practices:** Always close sockets and handle exceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7c61d",
   "metadata": {},
   "source": [
    "## 5. HTTP Requests (requests library)\n",
    "**Definition:** The `requests` library is a user-friendly way to make HTTP requests in Python.\n",
    "\n",
    "**Syntax and Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec31dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1561731844.py, line 219)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 219\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"\"\"import requests\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "# Basic GET request\n",
    "print(\"Basic GET request:\")\n",
    "try:\n",
    "    response = requests.get('https://api.github.com')\n",
    "    print(f\"Status code: {response.status_code}\")\n",
    "    print(f\"Response headers: {dict(response.headers)[:3]}...\")\n",
    "    \n",
    "    # Parse JSON response\n",
    "    data = response.json()\n",
    "    print(\"\\nAPI endpoints available:\")\n",
    "    for endpoint, url in list(data.items())[:5]:\n",
    "        print(f\"  {endpoint}: {url}\")\n",
    "    print(\"  ...and more endpoints\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request error: {e}\")\n",
    "\n",
    "# HTTP methods demonstration\n",
    "print(\"\\nHTTP methods with requests:\")\n",
    "crud_operations = [\n",
    "    \"GET: Retrieve data (requests.get())\",\n",
    "    \"POST: Create new data (requests.post())\",\n",
    "    \"PUT: Update existing data (requests.put())\",\n",
    "    \"PATCH: Partially update data (requests.patch())\",\n",
    "    \"DELETE: Remove data (requests.delete())\"\n",
    "]\n",
    "\n",
    "for op in crud_operations:\n",
    "    print(f\"- {op}\")\n",
    "\n",
    "# Request with parameters\n",
    "print(\"\\nGET request with parameters:\")\n",
    "try:\n",
    "    # Search GitHub repositories with query parameters\n",
    "    params = {\n",
    "        'q': 'python data science',\n",
    "        'sort': 'stars',\n",
    "        'order': 'desc',\n",
    "        'per_page': 3\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\n",
    "        'https://api.github.com/search/repositories', \n",
    "        params=params\n",
    "    )\n",
    "    \n",
    "    print(f\"Request URL: {response.url}\")\n",
    "    print(f\"Status code: {response.status_code}\")\n",
    "    \n",
    "    # Parse response (simulated)\n",
    "    print(\"\\nTop repositories for 'python data science' (simulated):\")\n",
    "    mock_results = [\n",
    "        {\"name\": \"pandas\", \"stars\": 36500, \"description\": \"Powerful data analysis toolkit\"},\n",
    "        {\"name\": \"scikit-learn\", \"stars\": 52000, \"description\": \"Machine learning in Python\"},\n",
    "        {\"name\": \"jupyter\", \"stars\": 12000, \"description\": \"Interactive computing\"}\n",
    "    ]\n",
    "    \n",
    "    for repo in mock_results:\n",
    "        print(f\"Repository: {repo['name']}\")\n",
    "        print(f\"  Stars: {repo['stars']}\")\n",
    "        print(f\"  Description: {repo['description']}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request error: {e}\")\n",
    "\n",
    "# POST request example\n",
    "print(\"\\nPOST request example:\")\n",
    "\n",
    "# Data to send\n",
    "user_data = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"job\": \"Data Scientist\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Making a POST request to create a user (using JSONPlaceholder API)\n",
    "    response = requests.post(\n",
    "        'https://reqres.in/api/users',\n",
    "        json=user_data  # Automatically serializes to JSON\n",
    "    )\n",
    "    \n",
    "    print(f\"Status code: {response.status_code}\")\n",
    "    \n",
    "    # Parse the response\n",
    "    data = response.json()\n",
    "    print(\"\\nCreated user (response):\")\n",
    "    pprint(data)\n",
    "    \n",
    "    # Show the added ID and creation timestamp\n",
    "    print(f\"\\nUser ID: {data.get('id')}\")\n",
    "    print(f\"Created at: {data.get('createdAt')}\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request error: {e}\")\n",
    "\n",
    "# Working with headers and authentication\n",
    "print(\"\\nHeaders and authentication:\")\n",
    "\n",
    "def print_headers_example():\n",
    "    # Custom headers\n",
    "    headers = {\n",
    "        'User-Agent': 'Python Requests Tutorial',\n",
    "        'Accept': 'application/json',\n",
    "        'X-Custom-Header': 'CustomValue'\n",
    "    }\n",
    "    \n",
    "    # Basic authentication\n",
    "    auth = ('username', 'password')  # Replace with actual credentials\n",
    "    \n",
    "    print(\"Example Headers:\")\n",
    "    for key, value in headers.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\nAuthentication Methods:\")\n",
    "    print(\"  - Basic Auth: requests.get(url, auth=('username', 'password'))\")\n",
    "    print(\"  - Bearer Token: headers = {'Authorization': 'Bearer YOUR_TOKEN'}\")\n",
    "    print(\"  - API Key: params = {'api_key': 'YOUR_API_KEY'}\")\n",
    "    print(\"  - OAuth: Use requests-oauthlib library\")\n",
    "\n",
    "print_headers_example()\n",
    "\n",
    "# Handling errors and exceptions\n",
    "print(\"\\nHandling errors and exceptions:\")\n",
    "\n",
    "def demonstrate_error_handling():\n",
    "    print(\"Common status codes:\")\n",
    "    status_codes = {\n",
    "        200: \"OK - Request successful\",\n",
    "        201: \"Created - Resource created successfully\",\n",
    "        204: \"No Content - Request successful, no content returned\",\n",
    "        400: \"Bad Request - Invalid syntax or parameters\",\n",
    "        401: \"Unauthorized - Authentication required\",\n",
    "        403: \"Forbidden - Server refuses the request\",\n",
    "        404: \"Not Found - Resource not found\",\n",
    "        500: \"Internal Server Error - Server error occurred\"\n",
    "    }\n",
    "    \n",
    "    for code, desc in status_codes.items():\n",
    "        print(f\"  {code}: {desc}\")\n",
    "    \n",
    "    print(\"\\nException handling example:\")\n",
    "    print(\"\"\"try:\n",
    "    response = requests.get('https://api.example.com/data', timeout=5)\n",
    "    response.raise_for_status()  # Raises an exception for 4XX/5XX responses\n",
    "    data = response.json()\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error: {e}\")\n",
    "except requests.exceptions.ConnectionError as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "except requests.exceptions.Timeout as e:\n",
    "    print(f\"Timeout error: {e}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"General error: {e}\")\n",
    "\"\"\")\n",
    "\n",
    "demonstrate_error_handling()\n",
    "\n",
    "# Sessions and connection pooling\n",
    "print(\"\\nSessions and connection pooling:\")\n",
    "\n",
    "def session_example():\n",
    "    # Create a session\n",
    "    print(\"Using a session for multiple requests:\")\n",
    "    print(\"\"\"session = requests.Session()\n",
    "\n",
    "# Session will maintain cookies and connection pool\n",
    "session.headers.update({'User-Agent': 'MyApp/1.0'})\n",
    "\n",
    "# First request\n",
    "response1 = session.get('https://api.example.com/data1')\n",
    "\n",
    "# Second request (reuses connection and includes cookies from first request)\n",
    "response2 = session.get('https://api.example.com/data2')\n",
    "\n",
    "# Close the session when done\n",
    "session.close()\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nBenefits of using Sessions:\")\n",
    "    print(\"  - Connection pooling (faster subsequent requests)\")\n",
    "    print(\"  - Automatic cookie persistence\")\n",
    "    print(\"  - Common configuration for multiple requests\")\n",
    "\n",
    "session_example()\n",
    "\n",
    "# Best practices\n",
    "print(\"\\nRequests library best practices:\")\n",
    "best_practices = [\n",
    "    \"Always set timeouts to prevent hanging requests\",\n",
    "    \"Use sessions for multiple requests to the same site\",\n",
    "    \"Handle exceptions and check status codes\",\n",
    "    \"Close response bodies and sessions when done\",\n",
    "    \"Respect API rate limits\",\n",
    "    \"Validate SSL certificates (don't use verify=False)\",\n",
    "    \"Use connection pooling for performance\",\n",
    "    \"Consider async alternatives (aiohttp, httpx) for high concurrency\"\n",
    "]\n",
    "\n",
    "for i, practice in enumerate(best_practices, 1):\n",
    "    print(f\"{i}. {practice}\")\n",
    "\n",
    "# Data science specific examples\n",
    "print(\"\\nRequests in data science workflows:\")\n",
    "print(\"1. API data collection for analysis\")\n",
    "print(\"2. Downloading datasets from repositories\")\n",
    "print(\"3. Loading data into pandas from web services\")\n",
    "print(\"4. Web scraping for data gathering\")\n",
    "print(\"5. Publishing results to web services\")\n",
    "\n",
    "# Code example for downloading data with progress\n",
    "print(\"\\nExample: Downloading a dataset with progress tracking:\")\n",
    "\n",
    "def download_with_progress_example():\n",
    "    print(\"\"\"import requests\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, filename):\n",
    "    # Download a file with progress bar\n",
    "    # Make request with stream=True to download in chunks\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Get total file size\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "    \n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    \n",
    "    # Download and write file\n",
    "    with open(filename, 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    if total_size != 0 and progress_bar.n != total_size:\n",
    "        print(\"Download incomplete\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "download_file(url, \"wine_dataset.csv\")\n",
    "\"\"\")\n",
    "\n",
    "download_with_progress_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
